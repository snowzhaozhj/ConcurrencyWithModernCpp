<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>ConcurrencyWithModernCpp</title>
                <meta name="robots" content="noindex" />
                

        <!-- Custom HTML head -->
        

        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

                <link rel="icon" href="favicon.svg">
                        <link rel="shortcut icon" href="favicon.png">
                <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
                <link rel="stylesheet" href="css/print.css" media="print">
        
        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
                <link rel="stylesheet" href="fonts/fonts.css">
        
        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        
            </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="content/Reader-Testimonials.html"><strong aria-hidden="true">1.</strong> 读者推荐</a></li><li class="chapter-item expanded "><a href="content/Source-Code.html"><strong aria-hidden="true">2.</strong> 代码说明</a></li><li class="chapter-item expanded "><a href="content/How-you-should-read-the-book.html"><strong aria-hidden="true">3.</strong> 如何阅读</a></li><li class="chapter-item expanded "><a href="content/History-Quick-Overview.html"><strong aria-hidden="true">4.</strong> C++并发历史概述</a></li><li class="chapter-item expanded "><div><strong aria-hidden="true">5.</strong> 详细介绍</div></li><li><ol class="section"><li class="chapter-item expanded "><a href="content/The-Details/Memory-Model/1.0-chinese.html"><strong aria-hidden="true">5.1.</strong> 内存模型</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="content/The-Details/Memory-Model/1.1-chinese.html"><strong aria-hidden="true">5.1.1.</strong> 内存模型的基础知识</a></li><li class="chapter-item expanded "><a href="content/The-Details/Memory-Model/1.2-chinese.html"><strong aria-hidden="true">5.1.2.</strong> 编程协议</a></li><li class="chapter-item expanded "><a href="content/The-Details/Memory-Model/1.3-chinese.html"><strong aria-hidden="true">5.1.3.</strong> 原子操作</a></li><li class="chapter-item expanded "><a href="content/The-Details/Memory-Model/1.4-chinese.html"><strong aria-hidden="true">5.1.4.</strong> 同步和顺序</a></li><li class="chapter-item expanded "><a href="content/The-Details/Memory-Model/1.5-chinese.html"><strong aria-hidden="true">5.1.5.</strong> 栅栏(Fences)</a></li></ol></li><li class="chapter-item expanded "><a href="content/The-Details/Multithreading/2.0-chinese.html"><strong aria-hidden="true">5.2.</strong> 多线程</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="content/The-Details/Multithreading/2.1-chinese.html"><strong aria-hidden="true">5.2.1.</strong> 线程</a></li><li class="chapter-item expanded "><a href="content/The-Details/Multithreading/2.2-chinese.html"><strong aria-hidden="true">5.2.2.</strong> 共享数据</a></li><li class="chapter-item expanded "><a href="content/The-Details/Multithreading/2.3-chinese.html"><strong aria-hidden="true">5.2.3.</strong> 线程-本地数据</a></li><li class="chapter-item expanded "><a href="content/The-Details/Multithreading/2.4-chinese.html"><strong aria-hidden="true">5.2.4.</strong> 条件变量</a></li><li class="chapter-item expanded "><a href="content/The-Details/Multithreading/2.5-chinese.html"><strong aria-hidden="true">5.2.5.</strong> 任务</a></li></ol></li><li class="chapter-item expanded "><a href="content/The-Details/Parallel-Algorithms-of-the-Standard/3.0-chinese.html"><strong aria-hidden="true">5.3.</strong> 标准库的并行算法</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="content/The-Details/Parallel-Algorithms-of-the-Standard/3.1-chinese.html"><strong aria-hidden="true">5.3.1.</strong> 执行策略</a></li><li class="chapter-item expanded "><a href="content/The-Details/Parallel-Algorithms-of-the-Standard/3.2-chinese.html"><strong aria-hidden="true">5.3.2.</strong> 算法</a></li><li class="chapter-item expanded "><a href="content/The-Details/Parallel-Algorithms-of-the-Standard/3.3-chinese.html"><strong aria-hidden="true">5.3.3.</strong> 新算法</a></li><li class="chapter-item expanded "><a href="content/The-Details/Parallel-Algorithms-of-the-Standard/3.4-chinese.html"><strong aria-hidden="true">5.3.4.</strong> 性能概况</a></li></ol></li><li class="chapter-item expanded "><a href="content/The-Details/Case-Studies/4.0-chinese.html"><strong aria-hidden="true">5.4.</strong> 案例研究</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="content/The-Details/Case-Studies/4.1-chinese.html"><strong aria-hidden="true">5.4.1.</strong> 求向量元素的加和</a></li><li class="chapter-item expanded "><a href="content/The-Details/Case-Studies/4.2-chinese.html"><strong aria-hidden="true">5.4.2.</strong> 单例模式：线程安全的初始化</a></li><li class="chapter-item expanded "><a href="content/The-Details/Case-Studies/4.3-chinese.html"><strong aria-hidden="true">5.4.3.</strong> 使用CppMem进行优化</a></li><li class="chapter-item expanded "><a href="content/The-Details/Case-Studies/4.4-chinese.html"><strong aria-hidden="true">5.4.4.</strong> 总结</a></li></ol></li><li class="chapter-item expanded "><a href="content/The-Details/The-Future-CPP-20-23/5.0-chinese.html"><strong aria-hidden="true">5.5.</strong> C++20/23的特性</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="content/The-Details/The-Future-CPP-20-23/5.1-chinese.html"><strong aria-hidden="true">5.5.1.</strong> 关于执行</a></li><li class="chapter-item expanded "><a href="content/The-Details/The-Future-CPP-20-23/5.2-chinese.html"><strong aria-hidden="true">5.5.2.</strong> 可协作中断的线程</a></li><li class="chapter-item expanded "><a href="content/The-Details/The-Future-CPP-20-23/5.3-chinese.html"><strong aria-hidden="true">5.5.3.</strong> 原子智能指针</a></li><li class="chapter-item expanded "><a href="content/The-Details/The-Future-CPP-20-23/5.4-chinese.html"><strong aria-hidden="true">5.5.4.</strong> 扩展特性</a></li><li class="chapter-item expanded "><a href="content/The-Details/The-Future-CPP-20-23/5.5-chinese.html"><strong aria-hidden="true">5.5.5.</strong> 门闩和栅栏</a></li><li class="chapter-item expanded "><a href="content/The-Details/The-Future-CPP-20-23/5.6-chinese.html"><strong aria-hidden="true">5.5.6.</strong> 协程</a></li><li class="chapter-item expanded "><a href="content/The-Details/The-Future-CPP-20-23/5.7-chinese.html"><strong aria-hidden="true">5.5.7.</strong> 事务性内存</a></li><li class="chapter-item expanded "><a href="content/The-Details/The-Future-CPP-20-23/5.8-chinese.html"><strong aria-hidden="true">5.5.8.</strong> 任务块</a></li></ol></li></ol></li><li class="chapter-item expanded "><div><strong aria-hidden="true">6.</strong> 模式</div></li><li><ol class="section"><li class="chapter-item expanded "><a href="content/Pattrns/Patterns-and-Best-Practices/6.0-chinese.html"><strong aria-hidden="true">6.1.</strong> 模式和最佳实践</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="content/Pattrns/Patterns-and-Best-Practices/6.1-chinese.html"><strong aria-hidden="true">6.1.1.</strong> 相关历史</a></li><li class="chapter-item expanded "><a href="content/Pattrns/Patterns-and-Best-Practices/6.2-chinese.html"><strong aria-hidden="true">6.1.2.</strong> 价值所在</a></li><li class="chapter-item expanded "><a href="content/Pattrns/Patterns-and-Best-Practices/6.3-chinese.html"><strong aria-hidden="true">6.1.3.</strong> 模式与最佳实践</a></li><li class="chapter-item expanded "><a href="content/Pattrns/Patterns-and-Best-Practices/6.4-chinese.html"><strong aria-hidden="true">6.1.4.</strong> 反模式</a></li></ol></li><li class="chapter-item expanded "><a href="content/Pattrns/Synchronisation-Patterns/7.0-chinese.html"><strong aria-hidden="true">6.2.</strong> 同步模式</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="content/Pattrns/Synchronisation-Patterns/7.1-chinese.html"><strong aria-hidden="true">6.2.1.</strong> 处理共享</a></li><li class="chapter-item expanded "><a href="content/Pattrns/Synchronisation-Patterns/7.2-chinese.html"><strong aria-hidden="true">6.2.2.</strong> 处理突变</a></li></ol></li><li class="chapter-item expanded "><a href="content/Pattrns/Concurrent-Architecture/8.0-chinese.html"><strong aria-hidden="true">6.3.</strong> 并发架构</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="content/Pattrns/Concurrent-Architecture/8.1-chinese.html"><strong aria-hidden="true">6.3.1.</strong> 活动对象</a></li><li class="chapter-item expanded "><a href="content/Pattrns/Concurrent-Architecture/8.2-chinese.html"><strong aria-hidden="true">6.3.2.</strong> 监控对象</a></li><li class="chapter-item expanded "><a href="content/Pattrns/Concurrent-Architecture/8.3-chinese.html"><strong aria-hidden="true">6.3.3.</strong> 半同步/半异步</a></li></ol></li><li class="chapter-item expanded "><a href="content/Pattrns/Best-Practices/9.0-chinese.html"><strong aria-hidden="true">6.4.</strong> 最佳实践</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="content/Pattrns/Best-Practices/9.1-chinese.html"><strong aria-hidden="true">6.4.1.</strong> 通常情况</a></li><li class="chapter-item expanded "><a href="content/Pattrns/Best-Practices/9.2-chinese.html"><strong aria-hidden="true">6.4.2.</strong> 多线程</a></li><li class="chapter-item expanded "><a href="content/Pattrns/Best-Practices/9.3-chinese.html"><strong aria-hidden="true">6.4.3.</strong> 内存模型</a></li></ol></li></ol></li><li class="chapter-item expanded "><div><strong aria-hidden="true">7.</strong> 数据结构</div></li><li><ol class="section"><li class="chapter-item expanded "><a href="content/Data-Structures/10.1-chinese.html"><strong aria-hidden="true">7.1.</strong> 有锁结构</a></li><li class="chapter-item expanded "><a href="content/Data-Structures/10.2-chinese.html"><strong aria-hidden="true">7.2.</strong> 无锁结构</a></li></ol></li><li class="chapter-item expanded "><div><strong aria-hidden="true">8.</strong> 更多信息</div></li><li><ol class="section"><li class="chapter-item expanded "><a href="content/Further-Information/11.1-chinese.html"><strong aria-hidden="true">8.1.</strong> 挑战</a></li><li class="chapter-item expanded "><a href="content/Further-Information/11.2-chinese.html"><strong aria-hidden="true">8.2.</strong> 时间库</a></li><li class="chapter-item expanded "><a href="content/Further-Information/11.3-chinese.html"><strong aria-hidden="true">8.3.</strong> CppMem-概述</a></li><li class="chapter-item expanded "><a href="content/Further-Information/11.4-chinese.html"><strong aria-hidden="true">8.4.</strong> 术语表</a></li></ol></li></ol>            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                                                <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                                            </div>

                    <h1 class="menu-title">ConcurrencyWithModernCpp</h1>

                    <div class="right-buttons">
                                                <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                                                                        
                    </div>
                </div>

                                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                
                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h2 id="读者推荐"><a class="header" href="#读者推荐">读者推荐</a></h2>
<p>“《Concurrency with Modern C++》是C++并发编程的指南。本书从C++内存模型开始，有很多经典案例的研究，大量的多线程技巧。将使您更了解并发的特性，甚至满足您的好奇心!”</p>
<p align="right"> — Bart Vandewoestyne：Esterline高级研发工程师</p>
”Rainer Grimm的《Concurrency with Modern C++》是一本好书，涵盖了并发性的理论和实践，以及C++20标准的(可能)变化。并提供了关于并发实践的讨论，提供了示例代码，以加强每个主题的细节。内容丰富，值得一读!”
<p align="right"> — Ian Reeve：戴尔软件存储高级工程师。</p>
”阅读《Concurrency with Modern C++》是成为多线程专家最简单的方法。这本书既有简单的内容，也有进阶的主题。它包含了研发人员所需的一切：大量的理论内容和代码示例，以及出色的解释，还有易错点介绍。我很喜欢它，并强烈推荐所有人阅读。”
<p align="right"> — Robert Badea：技术带头人</p>
## <div style="break-before: page; page-break-before: always;"></div><h1 id="代码说明"><a class="header" href="#代码说明">代码说明</a></h1>
<p>只要有合适的编译器，就可以编译并运行所有示例源码。这里要说明一下，只有在必要时，我才在源文件中使用<code>using namespace std</code>。</p>
<h2 id="运行程序"><a class="header" href="#运行程序">运行程序</a></h2>
<p>编译和运行本书中C++11和C++14的例子并不难。任何支持新标准的C++编译器都可以编译这些例子。<a href="https://gcc.gnu.org/">GCC</a> 和<a href="https://clang.llvm.org/">clang</a> 编译器，必须指定C++标准，以及要链接的线程库。 例如，GCC的g++编译器使用以下命令行创建一个名为thread的可执行程序:</p>
<blockquote>
<p>g++ -std=c++14 -pthread thread.cpp -o thread.</p>
</blockquote>
<ul>
<li>-std=c++14: 使用C++14标准。</li>
<li>-pthread: 使用pthread库作为后端，对多线程进行支持。</li>
<li>thread.cpp: 源码文件。</li>
<li>-o thread: 可执行程序名。</li>
</ul>
<p>同样的命令行也适用于clang++编译器。Microsoft Visual Studio 17 C++编译器也支持C++ 14。</p>
<p>如果没有合适的C++编译器使用，那么可以使用在线编译器。比如：Arne Mertz博客提供的<a href="https://arne-mertz.de/2017/05/online-compilers">C++ Online Compiler</a>。</p>
<p>C++ 17和C++ 20/23的故事比较复杂。我安装了<a href="http://stellar.cct.lsu.edu/projects/hpx/">HPX (High Performance ParalleX)</a>框架，这是个C++通用运行时系统，适用于任何规模的并行和分布式应用。HPX已经实现了C++ 17并行的STL和C++ 20/23的许多并发特性。可参考“未来：C++ 20/23”一章中相应的内容和代码。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="如何阅读"><a class="header" href="#如何阅读">如何阅读</a></h1>
<p>如果对C++的并发性不是很熟悉，可以从最开始的部分开始，先快速地了解一下。</p>
<p>当有了大概的了解，就可以着手处理细节。第一遍阅读可以先跳过内存模型，不过在案例研究章节将之前的理论进行实践，因为需要对内存模型所有理解，所以非常有挑战性。</p>
<p>&quot;未来：C++20/23&quot;是可选择性阅读章节。我对未来非常好奇，希望你和我一样!</p>
<p>最后，为了更好地理解书中的内容，并充分利用这些知识，本书还提供了额外的应用指导。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="c并行历史概述"><a class="header" href="#c并行历史概述">C++并行历史概述</a></h1>
<p>随着C++11的发布，C++标准添加了多线程和内存模型。这样，标准库有了基本的构建块，比如：原子变量、线程、锁和条件变量。C++11提供了比引用更抽象的构建块，这是未来C++标准(C++20/23)能建立更高抽象的基础。</p>
<p><img src="content/../images/History-Quick-Overview/0.png" alt="" /></p>
<p>粗略地说，可以将C++并发分为三个演化过程。</p>
<h2 id="c11和c14-铺垫"><a class="header" href="#c11和c14-铺垫">C++11和C++14: 铺垫</a></h2>
<p>C++11引入多线程，包括两个部分：良好的内存模型和标准化的线程接口。C++14为C++的多线程功能增加了读写锁。</p>
<h3 id="内存模型"><a class="header" href="#内存模型">内存模型</a></h3>
<p>多线程的基础，是定义良好的内存模型。内存模型需要处理以下几个方面的内容:</p>
<ul>
<li>原子操作: 不受中断地操作。</li>
<li>部分排序运算: 不能重排序的操作序列。</li>
<li>操作的可见效果: 保证其他线程可以看到对共享变量的操作。</li>
</ul>
<p>C++内存模型的灵感来自于Java。然而，与Java的内存模型不同，C++允许打破顺序一致性的约束(原子操作的默认方式)。</p>
<p>顺序一致性提供了两个保证：</p>
<ol>
<li>程序指令按源码顺序执行。</li>
<li>线程上的所有操作都遵循一个全局顺序。</li>
</ol>
<p>内存模型基于原子数据类型(短原子)的原子操作。</p>
<h3 id="原子类型"><a class="header" href="#原子类型">原子类型</a></h3>
<p>C++有一组基本的原子数据类型，分别是布尔值、字符、数字和指针的变体。可以使用类模板<code>std::atomic</code>来定义原子数据类型。原子类型可以建立同步和排序约束，也适用于非原子类型。</p>
<p>标准化线程接口是C++并发的核心。</p>
<h3 id="多线程"><a class="header" href="#多线程">多线程</a></h3>
<p>C++中的多线程由线程、(共享数据的)同步语义、线程本地数据和任务组成。</p>
<h3 id="线程"><a class="header" href="#线程">线程</a></h3>
<p><code>std::thread</code>表示一个独立的程序执行单元。执行单元，表示可接受调用的单元。可调用单元可以是函数名、函数对象或Lambda函数。</p>
<p>新线程的可执行单元结束时，要么进行等待主线程完成(<code>t.join()</code>)，要么从主线程中分离出来(<code>t.detach()</code>)。如果没有对线程<code>t</code>执行<code>t.join()</code>或<code>t.detach()</code>操作，则线程<code>t</code>是可汇入的(joinable)。如果可汇入线程进行销毁时，会在其析构函数中调用<code>std::terminate</code>，则程序终止。</p>
<p>分离的线程在后台运行，通常称为<strong>守护线程</strong>。</p>
<p><code>std::thread</code>是一个可变参数模板，它可以接收任意数量的参数。</p>
<h4 id="共享数据"><a class="header" href="#共享数据">共享数据</a></h4>
<p>如果多个线程同时使用共享变量，并且该变量是可变的(非const)，则需要协调对该变量的访问。同时读写共享变量是一种数据竞争，也是一种未定义的行为。在C++中，可以通过锁(或互斥锁)来协调对共享变量的访问。</p>
<h4 id="互斥锁"><a class="header" href="#互斥锁">互斥锁</a></h4>
<p>互斥锁(互斥量)保证在任何给定时间内，只有一个线程可以访问共享变量。互斥锁锁定/解锁共享变量所属的临界区(C++有5个不同的互斥对象)。即使互斥锁同时共享一个锁，也可以递归地、试探性地、有或没有时间限制地进行锁定。</p>
<h4 id="锁"><a class="header" href="#锁">锁</a></h4>
<p>应该将互斥锁封装在锁中，从而自动释放互斥锁。锁通过将互斥锁的生命周期绑定到自己的生命周期来实现RAII。C++中<code>std::lock_guard</code>/<code>std::scoped_lock</code>可用于简单场景，<code>std::unique_lock</code>/<code>std::shared_lock</code>用于高级场景，例如：显式锁定或解锁互斥锁。</p>
<h3 id="线程本地数据"><a class="header" href="#线程本地数据">线程本地数据</a></h3>
<p>将变量声明为<code>thread-local</code>可以确保每个线程都有变量的副本。线程本地数据的生存周期，与线程的生存周期相同。</p>
<h3 id="条件变量"><a class="header" href="#条件变量">条件变量</a></h3>
<p>条件变量允许通过消息机制对线程进行同步。一个线程为发送方，而另一个线程为接收方，其中接收方阻塞等待来自发送方的消息。条件变量的典型用例是&quot;生产者-消费者&quot;模式。条件变量可以是发送方，也可以是接收方。正确使用条件变量非常具有挑战性。所以，这样的任务通常有更简单的解决方案。</p>
<h3 id="任务"><a class="header" href="#任务">任务</a></h3>
<p>任务与线程有很多共同之处。虽然显式地创建了一个线程，但任务只是工作的开始。C++运行时会自动处理任务的生存期，比如：<code>std::async</code>。</p>
<p>任务就像两个通信端点之间的数据通道。支持线程之间的安全通信，当一个端点将数据放入数据通道时，另一个端点将在未来某个时刻获取该值。数据可以是值、异常或通知。除了<code>std::async</code>, C++还有<code>std::promise</code>和<code>std::future</code>，这两个类模板可以对任务有更多的控制。</p>
<h2 id="c17-标准模板库算法的并行"><a class="header" href="#c17-标准模板库算法的并行">C++17: 标准模板库算法的并行</a></h2>
<p><img src="content/../images/History-Quick-Overview/1.png" alt="" /></p>
<p>C++17的并发性发生了巨大的变化，特别是标准模板库(STL)的并行算法。C++11和C++14只提供了并发性的基础构建块。这些工具适合库或框架开发人员，但不适合应用程序开发人员。C++11和C++14中的多线程，在C++ 17中的并发性面前，相当于汇编语言!</p>
<h3 id="执行策略"><a class="header" href="#执行策略">执行策略</a></h3>
<p>C++17中，大多数STL算法都有并行实现，这样就可以使用执行策略来调用算法。该策略指定算法是串行执行(<code>std::execution::seq</code>)、并行执行(<code>std::execution::par</code>)，还是与向量化的并行执行(<code>std::execution::par_unseq</code>)。</p>
<h3 id="新算法"><a class="header" href="#新算法">新算法</a></h3>
<p>除了在重载，并行了原始的69种算法，还添加了8种新算法。这些新算法非常适合并行归约、扫描或转换。</p>
<h2 id="案例研究"><a class="header" href="#案例研究">案例研究</a></h2>
<p>介绍了内存模型和多线程接口的理论知识之后，会将这些知识应用到一些案例中。</p>
<h3 id="求向量元素的加和"><a class="header" href="#求向量元素的加和">求向量元素的加和</a></h3>
<p>计算一个向量的加和有多种方法。可以串行执行，也可以通过数据共享并发执行，不同的实现方式，性能上有很大的差别。</p>
<h3 id="单例线程安全的初始化"><a class="header" href="#单例线程安全的初始化">单例：线程安全的初始化</a></h3>
<p>单例对象的初始化是线程安全的，是共享变量线程安全初始化的经典案例。有许多实现方法可以做到这一点，不过在性能上有一定的差异。</p>
<h3 id="使用cppmem进行优化"><a class="header" href="#使用cppmem进行优化">使用CppMem进行优化</a></h3>
<p>我会从一个小程序开始，然后不断地改进它，并用CppMem验证优化过程的每个步骤。 <a href="http://svr-pes20-cppmem.cl.cam.ac.uk/cppmem">CppMem</a>是一个交互式工具，用于研究小代码段的C++内存模型行为。</p>
<h2 id="c2023-并发的未来"><a class="header" href="#c2023-并发的未来">C++20/23: 并发的未来</a></h2>
<p><img src="content/../images/History-Quick-Overview/2.png" alt="" /></p>
<p>对未来的标准预测非常难(<a href="https://en.wikipedia.org/wiki/Niels_Bohr">Niels Bohr</a>)，这里描述了C++20/23的并发特性。</p>
<h3 id="executors"><a class="header" href="#executors">Executors</a></h3>
<p>Executor由一组如何运行可调用单元的规则组成。它们指定执行是否应该在线程、线程池，甚至单线程(无并发)上运行(可调用的)基础构建块上进行。提案<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/n4734.pdf">N4734</a>的扩展依赖于扩展的future，也依赖于STL的并行算法，以及C++20/23中新的并发特性，如：门闩和栅栏、协程、事务性内存和任务块(最终都会使用它们)。</p>
<h4 id="stdjthread"><a class="header" href="#stdjthread">std::jthread</a></h4>
<p><code>std::jthread</code>是<code>std::thread</code>的增强版。除了<code>std::thread</code>外，<code>std::jthread</code>还可以发出中断信号，并自动并入启动的线程。</p>
<h4 id="原子智能指针"><a class="header" href="#原子智能指针">原子智能指针</a></h4>
<p>智能指针<a href="http://en.cppreference.com/w/cpp/memory/shared_ptr"><code>std::shared_ptr</code></a>和<a href="http://en.cppreference.com/w/cpp/memory/weak_ptr"><code>std::weak_ptr</code></a>在并发程序中存在概念问题。它们的本质上是共享的，这就使得状态可变，所以容易出现数据竞争，从而导致未定义的行为。<code>std::shared_ptr</code>和<code>std::weak_ptr</code>保证引用计数器的递增或递减是一个原子操作。资源只被删除一次，但不能保证对资源访问的原子性。新的原子智能指针<code>std::atomic&lt;std::shared_ptr&lt;T&gt;&gt;</code>和<code>std::atomic&lt;std::weak_ptr&lt;T&gt;&gt;</code>解决了这个问题。两者都是<code>std::atomic</code>的偏特化版本。</p>
<h4 id="扩展版future"><a class="header" href="#扩展版future">扩展版future</a></h4>
<p>C++11引入了promise和future，其有很多优点，但也有一个缺点：不能组合成强大的工作流。在C++20/23中，future应该会消弭这个缺点。</p>
<h4 id="门闩和栅栏"><a class="header" href="#门闩和栅栏">门闩和栅栏</a></h4>
<p>C++14没有信号量，而信号量是用于限制访问资源的利器。因为C++20/23提出了门闩和屏障，就不用担心没有信号量可用的问题了。可以使用门闩和栅栏在异步点进行等待，直到计数器变为零。门闩和栅栏的区别在于，<code>std::latch</code>只能使用一次，而<code>std::barrier</code>和<code>std::flex_barrier</code>可以使用多次。与<code>std::barrier</code>不同，<code>std::flex_barrier</code>可以在每次迭代之后调整它的计数器。</p>
<h4 id="协程"><a class="header" href="#协程">协程</a></h4>
<p>协程是可以挂起，并保持执行函数的状态。协程通常在操作系统、事件循环、无限列表或管道中使用，用于实现需要协作才能完成的任务。</p>
<h4 id="事务内存"><a class="header" href="#事务内存">事务内存</a></h4>
<p>事务内存基于数据库理论中事务的基本思想。事务是一种操作，它提供了ACID数据库事务的前三个属性：原子性、一致性和隔离性。数据库特有的持久性不适用C++的事务内存。新标准有两种类型的事务内存：同步块和原子块。它们都按总顺序执行的，表现得好像有一个全局锁在保护它们。与同步块相比，原子块不能执行事务不安全的代码。</p>
<h4 id="任务块"><a class="header" href="#任务块">任务块</a></h4>
<p>任务块在C++中实现了fork-join范式。下图说明了任务块的关键思想：启动任务的fork阶段和同步任务的join阶段。</p>
<p><img src="content/../images/History-Quick-Overview/3.png" alt="" /></p>
<h3 id="模式和最佳实践"><a class="header" href="#模式和最佳实践">模式和最佳实践</a></h3>
<p>模式是从实践中记录下来的最佳方式。<a href="https://en.wikipedia.org/wiki/Christopher_Alexander">Christopher Alexander</a>说，“模式表达了特定环境、问题和解决方案之间的关系“。从更概念化的角度看待并发编程，会得到更多解决问题的方式。与更概念化的并发模式相比，本章提供了面对并发挑战的实用技巧。</p>
<h4 id="同步"><a class="header" href="#同步">同步</a></h4>
<p>数据竞争的必要前提是数据处于共享的、可变状态。同步模式可以归结为两个问题：处理共享和处理可变。</p>
<h4 id="并行架构"><a class="header" href="#并行架构">并行架构</a></h4>
<p>并发架构章节中介绍了三种模式。前两种模式是活动对象和监视器对象的同步，以及调度器方法的使用。第三种半同步/半异步模式关注体系结构，并在并发系统中解耦异步和同步(服务)的处理。</p>
<h4 id="最佳实践"><a class="header" href="#最佳实践">最佳实践</a></h4>
<p>并发编程比较复杂，因此通过最佳实践，可以更多的了解多线程和内存模型。</p>
<p>###数据结构</p>
<h4 id="挑战项目"><a class="header" href="#挑战项目">挑战项目</a></h4>
<p>编写并发程序本来就很复杂，使用C++11和C++14的特性也是如此。因此，我将详细描述具挑战性的问题。希望用一整章的篇幅来讨论并发编程的挑战，会让你更清楚其中的陷阱。这里有竞争条件、数据竞争和死锁等挑战项目。</p>
<h4 id="计时库"><a class="header" href="#计时库">计时库</a></h4>
<p>计时库是C++并发工具的重要组成部分。通常，可以让线程在特定的时间内处于休眠状态，或者一直休眠到特定的时间点。计时库包括：时间点、时间段和时钟。</p>
<h4 id="cppmem"><a class="header" href="#cppmem">CppMem</a></h4>
<p>CppMem是一个交互式工具，用于深入了解内存模型。它提供了两项非常有价值的服务：可以验证无锁代码，可以分析无锁代码，并且能得到对代码的鲁棒性有更多的理解。本书会经常使用CppMem。由于CppMem的配置选项和见解非常具有挑战性，也会提供相应章节，以便对CppMem有一些基本的了解。</p>
<h4 id="术语表"><a class="header" href="#术语表">术语表</a></h4>
<p>术语表对最基本的术语作了简单的解释。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="内存模型-1"><a class="header" href="#内存模型-1">内存模型</a></h1>
<p>(定义良好的)内存模型是多线程的基础件，包括两个方面的内容：一方面，它非常复杂，经常与我们的想法相矛盾。另一方面，它有助于我们更深入地了解多线程。</p>
<p>那么，”内存模型“是什么呢?</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="内存模型的基础知识"><a class="header" href="#内存模型的基础知识">内存模型的基础知识</a></h1>
<p>从并发的角度来看，内存模型要解答两个问题：</p>
<ul>
<li>什么是内存位置?</li>
<li>如果两个线程访问相同的内存位置，会发生什么?</li>
</ul>
<h2 id="内存位置是什么"><a class="header" href="#内存位置是什么">内存位置是什么？</a></h2>
<p>引用<a href="http://en.cppreference.com/w/cpp/language/memory_model">cppreference.com</a>中对内存位置的定义：</p>
<ul>
<li>标量对象(算术类型、指针类型、枚举类型或<code>std::nullptr_t</code>)，</li>
<li>或非零长度的连续序列。</li>
</ul>
<p>下面是内存位置的例子:</p>
<pre><code class="language-c++">struct S {
  char a;         // memory location #1
  int b : 5;      // memory location #2
  int c : 11,     // memory location #2 (continued)
        : 0,
      d : 8;      // memory location #3
  int e;          // memory location #4
  double f;       // memory location #5
  std::string g;  // several memory locations
};
</code></pre>
<p>首先，对象<code>obj</code>由七个子对象组成，其中b、c两个位字段共享内存位置。</p>
<p>观察上述结构体定义，可以得到如下结论:</p>
<ul>
<li>每个变量都是一个对象。</li>
<li>标量类型占用一个内存位置。</li>
<li>相邻的位字段(b和c)具有相同的内存位置。</li>
<li>变量至少占用一个内存位置。</li>
</ul>
<p>那么，到了多线程的关键部分。</p>
<p>##两个线程访问相同的内存位置，会发生什么呢?</p>
<p>如果两个线程访问相同的内存位置(相邻位字段共享内存位置)，并且至少有一个线程想要修改它，那么程序就会产生数据竞争，除非：</p>
<ol>
<li>修改操作为原子操作。</li>
<li>访问按照某种先行(happens-before)顺序进行。</li>
</ol>
<p>第二种情况非常有趣，同步语义(如互斥锁)可以建立了先行关系。这些先行关系基于原子建立，当然也适用于非原子操作。内存序(memory-ordering)是内存模型的关键部分，其定义了先行关系的细节。</p>
<p>对内存模型有了初步的认识后，再来看看C++内存模型中定义的“编程协议”。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="编程协议"><a class="header" href="#编程协议">编程协议</a></h1>
<p>协议约定的双方为：开发者和系统。系统由生成机器码的编译器、执行机器码的处理器和存储程序状态的缓存组成。每个部分可以进行优化，例如：编译器可以使用寄存器或修改循环，处理器可以乱序执行或分支预测，缓存指令可以预取或缓冲。生成的(在好的情况下)可执行文件，可以针对硬件平台进行了优化。确切地说，这里不只有一个协议，而是一组(细粒度的)协议。换句话说：遵循越弱的规则，程序的优化潜力越大。</p>
<p>有一个经验法则是：协议越强，优化的空间越少。当程序开发者使用弱协议或弱内存模型时，相应就会有许多优化选择。结果是，这个项目只能由少数专家来维护，而你我可能都不属于专家的范畴。</p>
<p>粗略地说，C++11中有三个协议级别。</p>
<p><img src="content/The-Details/Memory-Model/../../../images/detail/memory-model/1.png" alt="" /></p>
<p>C++11之前，C++不包括多线程或原子。系统只遵循控制流，因此优化的潜力非常有限。该系统的关键是，保证程序开发者所观察到的程序行为，与源代码中指令的顺序一致。当然，这就意味着没有内存模型，只有序列点。序列点是程序中的点，在这些点上的所有指令的效果是可见的，函数执行的开始或结束都是序列点。当使用两个参数调用一个函数时，C++并不保证先计算哪个参数，因此其行为是未指定的，原因很简单——逗号操作符不是序列点。</p>
<p>C++11中，这些都发生了变化。C++11是C++第一个支持多线程的标准。C++内存模型深受<a href="https://en.wikipedia.org/wiki/Java_memory_model">Java内存模型</a>的影响，不过C++内存模型做了很多改进。为了得到定义良好的程序，程序开发者在处理共享变量时必须遵守规则。如果存在数据竞争，则程序的行为是未定义的。如前所述，如果线程共享可变数据，必须注意数据竞争。</p>
<p>在使用原子操作的时候，经常会讨论无锁编程。我在本节中谈到了弱规则和强规则，其中原子操作的顺序一致语义被称为<strong>强内存模型</strong>，原子操作的自由语义被称为<strong>弱内存模型</strong>。</p>
<h2 id="基础"><a class="header" href="#基础">基础</a></h2>
<p>C++内存模型需要保证以下操作：</p>
<ul>
<li>原子操作：不受中断地执行。</li>
<li>部分排序操作：操作序列的顺序不能重排。</li>
<li>可见操作：保证共享变量上的操作对其他线程可见。</li>
</ul>
<p>协议基础是针对原子操作的，其特点是原子的、不可分割的，并且在执行上会创建同步和约束顺序。当然，同步和约束顺序也适用于非原子的操作。一方面，原子类型上的操作总是原子的；另一方面，可以根据需要定制同步和约束顺序。</p>
<h2 id="挑战"><a class="header" href="#挑战">挑战</a></h2>
<p>内存模型越弱，就能把越多的注意力转放到其他事情上，比如：</p>
<ul>
<li>优化潜力。</li>
<li>控制流数量。</li>
<li>了解更多底层的知识。</li>
<li>程序行为与我们的预期是否一致。</li>
<li>更加微观的优化。</li>
</ul>
<p>我们应该是处理多线程的专家。如果想要处理原子(顺序一致)操作，我们应该打开通向下一个专业级别的大门。想要知道使用获得-释放语义或自由语义时会发生什么，就得向下一个境界迈进了。</p>
<p><img src="content/The-Details/Memory-Model/../../../images/detail/memory-model/2.png" alt="" /></p>
<p>我们从无锁编程开始，深入研究C++内存模型。当完成了基础知识的了解后，就要开始真正接触内存模型了。我们的起点是顺序一致语义，接着是获得-释放语义，而自由语义则作为旅程的终章。</p>
<p>现在，开启我们的原子操作之旅吧！</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="原子操作"><a class="header" href="#原子操作">原子操作</a></h1>
<p>原子操作是C++内存模型的基础。默认情况下，原子操作基于强内存模型的支持，所以理解强内存模型很有意义。</p>
<p>##强/弱内存模型</p>
<p>您可能已经从编程协议的章节中了解到：顺序一致语义是强内存模型，自由语义是弱内存模型。</p>
<p>###强内存模型</p>
<p>2004年，Java 5.0有了内存模型。2011年，C++添加了内存模型。在此之前，Java有个错误的内存模型，而C++则没有内存模型，而多线程编程已经有40~50年的历史了。在1979年时，<a href="https://en.wikipedia.org/wiki/Leslie_Lamport">Leslie Lamport</a> 就定义了顺序一致的概念。</p>
<p>顺序一致有两个特点:</p>
<ul>
<li>指令按源码顺序执行。</li>
<li>线程上的所有操作都遵循一个全局顺序。</li>
</ul>
<p>深入研究这两个特点之前，我想强调一下，这些声明只适用于原子操作，但影响并不仅对原子操作而言。</p>
<p>下面图形显示了两个线程。每个线程分别将值存储到变量<code>x</code>或<code>y</code>中，获取另一个变量<code>y</code>或<code>x</code>，并存储在变量<code>res1</code>或<code>res2</code>中。</p>
<p><img src="content/The-Details/Memory-Model/../../../images/detail/memory-model/3.png" alt="" /></p>
<p>通常，原子操作是顺序一致的。问题是：这些语句以什么顺序执行?</p>
<p>顺序一致的第一个特点：指令按照源码中的顺序执行。任何存储操作都无法在获取操作之前进行。</p>
<p>顺序一致的第二个特点：所有线程的指令必须遵循全局顺序。上图中的情况，线程2看到线程1的操作的顺序与线程1执行它们的顺序相同。线程2按照线程1的源码顺序查看线程1的所有操作，从线程1的角度来看也是如此。可以将这个特性，想象成一个所有线程都必须遵循的全局时钟(全局时钟就是全局顺序)。时钟每发出一次滴答声，就会发生一个原子操作，但永远不知道执行的是哪个。</p>
<p>解谜还没有结束。我们仍然需要观察，两个线程交错运行的方式。两个线程有以下六种交替运行的方式。</p>
<p><img src="content/The-Details/Memory-Model/../../../images/detail/memory-model/4.png" alt="" /></p>
<p>很简单，对吧？这就是顺序一致语义，也称为<strong>强内存模型</strong>。</p>
<h3 id="弱内存模型"><a class="header" href="#弱内存模型">弱内存模型</a></h3>
<p>我们再参考一下开发者和系统之间的协议。</p>
<p>这个特殊的例子中，开发者使用了原子操作(开发者遵循协议)。系统保证了程序的行为，从而不会存在数据竞争。另外，系统可以在每个组合中执行四个操作。如果开发者使用自由语义，协议的基础部分就会发生巨大的变化。一方面，开发者可能很难理解两个线程之间的交错；另一方面，系统有更大的优化空间。</p>
<p>使用自由语义(也称为弱内存模型)，可使这四种操作有更多的组合。有种很难理解的行为是，线程1可以以不同的顺序查看线程2的操作，这样全局顺序就不存在了。从线程1的角度来看，操作<code>res2= x.load()</code>可能在<code>y.store(1)</code>之前执行。甚至是，线程1或线程2没有按照源代码中的顺序执行。例如，线程2可以先执行<code>res2= x.load()</code>，再执行<code>y.store(1)</code>。</p>
<p>“序列一致语义”和“自由语义”之间还有存在其他内存模型，其中最重要的是“获取-释放语义“。“获取-释放语义”中，开发人员需要遵守比“顺序一致语义”弱的规则。这样，系统有了更多优化空间。因为线程在特定同步点上进行同步，所以“获取-释放语义“是理解多线程编程中，同步和部分排序的关键。没有同步点，就不可能有(定义良好的)线程、任务或条件变量。</p>
<p>上一节中，介绍了原子操作的默认行为——顺序一致(为每个原子操作指定内存顺序)。如果没有指定内存顺序，则应用保持顺序一致，这意味着<code>std::memory_order_seq_cst</code>将默认应用于每个原子操作。</p>
<p>下面两端段代码是等价的：</p>
<pre><code class="language-c++">x.store(1);
res = x.load();
</code></pre>
<pre><code class="language-c++">x.store(1, std::memory_order_seq_cst);
res = x.load(std::memory_order_seq_cst);
</code></pre>
<p>简单起见，本书使用第一种形式。现在，来深入了解C++内存模型原子性，先从<code>std::atomic_flag</code>开始吧。</p>
<h2 id="原子标志"><a class="header" href="#原子标志">原子标志</a></h2>
<p><code>std::atomic_flag</code>是原子布尔类型，可以对其状态进行设置和清除。为了简化说明，我将<code>clear</code>状态称为<code>false</code>，将<code>set</code>状态称为<code>true</code>。<code>clear</code>方法可将其状态设置为<code>false</code>。<code>test_and_set</code>方法，可以将状态设置回<code>true</code>，并返回先前的值。这里，没有方法获取当前值。使用<code>std::atomic_flag</code>时，必须使用常量<code>ATOMIC_FLAG_INIT</code>将<code>std::atomic_flag</code>初始化为<code>false</code>。</p>
<blockquote>
<p><strong>ATOMIC_FLAG_INIT</strong></p>
<p><code>std::atomic_flag</code>需要初始化时，可以是这样：<code>std::atomic_flag flag = ATOMIC_FLAG_INIT</code>。</p>
<p>不过，不能这样进行初始化：<code>std::atomic_flag flag(ATOMIC_FLAG_INIT) </code>。</p>
</blockquote>
<p><code>std::atomic_flag</code>有两个特点：</p>
<ul>
<li>无锁原子类型。程序是系统级别进程的话，执行的非阻塞算法就是无锁的。</li>
<li>更高级别的线程构建块。</li>
</ul>
<p>除了<code>std::atomic_flag</code>之外，C++标准中的原子内部都会使用互斥锁。这些原子类型有一个<code>is_lock_free</code>成员函数，可用来检查原子内部是否使用了互斥锁。时下主流的微处理器架构上，都能得到“使用了互斥锁”的结果。如果想要无锁编程，那么就要使用该成员函数进行检查，确定是否使用了锁。</p>
<blockquote>
<p><strong><code>std::is_always_lock_free</code></strong></p>
<p>可以使用<code>obj.is_lock_free()</code>，在运行时检查原子类型的实例<code>obj</code>是否无锁。在C++17中，可以通过<code>constexpr</code>(常量)<a href="https://zh.cppreference.com/w/cpp/atomic/atomic/is_always_lock_free"><code>atomic&lt;type&gt;::is_always_lock_free</code></a>，在编译时对每个原子类型进行检查，支持该操作的所有硬件实现都无锁时，才返回true。</p>
</blockquote>
<p><code>std::atomic_flag</code>的接口非常强大，能够构建自旋锁。自旋锁可以像使用互斥锁一样保护临界区。</p>
<blockquote>
<p><strong>自旋锁</strong></p>
<p>自旋锁与互斥锁不同，它并不获取锁。而是，通过频繁地请求锁来获取临界区的访问权。不过，这会导致上下文频繁切换(从用户空间到内核空间)，虽然充分使用了CPU，但也浪费了非常多的时钟周期。线程短时间阻塞时，自旋锁非常有效。通常，会将自旋锁和互斥锁组合着使用。首先，在有限的时间内使用自旋锁；如果不成功，则将线程置于等待(休眠)状态。</p>
<p>自旋锁不应该在单处理器系统上使用。否则，自旋锁就不仅浪费了资源，而且还会减慢程序处理的速度(最好的情况)，或出现死锁(最坏的情况)。</p>
</blockquote>
<p>下面的代码，使用<code>std::atomic_flag</code>实现了自旋锁。</p>
<pre><code class="language-c++">// spinLock.cpp

#include &lt;atomic&gt;
#include &lt;thread&gt;

class Spinlock{
  std::atomic_flag flag = ATOMIC_FLAG_INIT;
public:
  
  void lock(){
    while(flag.test_and_set());
  }
  
  void unlock(){
    flag.clear();
  }
  
};

Spinlock spin;

void workOnResource(){
  spin.lock();
  // shared resource
  spin.unlock();
}


int main(){
  
  std::thread t(workOnResource);
  std::thread t2(workOnResource);
  
  t.join();
  t2.join();
  
}
</code></pre>
<p>线程<code>t</code>和<code>t2</code>(第31行和第32行)在争夺临界区的访问权。这里的自旋锁是如何工作的呢？自旋锁也有锁定和解锁的阶段。</p>
<p>当线程<code>t</code>执行函数<code>workOnResource</code>时，可能会发生以下情况：</p>
<ol>
<li>线程<code>t</code>获取锁，若第11行的标志初始值为false，则锁调用成功。这种情况下，线程<code>t</code>的原子操作将其设置为true。所以，当<code>t</code>线程获取锁后，true将会让while陷入死循环，使得线程<code>t2</code>陷入了激烈的竞争当中。线程<code>t2</code>不能将标志设置为false，因此<code>t2</code>必须等待，直到线程<code>t1</code>执行<code>unlock</code>(解锁)并将标志设置为false(第14 - 16行)时，才能获取锁。</li>
<li>线程<code>t</code>没有得到锁时，情况1中的<code>t2</code>一样，需要等待。</li>
</ol>
<p>我们将注意力放在<code>std::atomic_flag</code>的<code>test_and_set</code>成员函数上。<code>test_and_set</code>函数包含两个操作：读和写。原子操作就是对这两种操作进行限制。如果没有限制，线程将对共享资源同时进行读和写(第24行)，根据定义，这就属于“数据竞争”，程序还会有未定义行为发生。</p>
<p>将自旋锁的主动等待和互斥锁的被动等待做一下比较。</p>
<h3 id="自旋锁-vs-互斥锁"><a class="header" href="#自旋锁-vs-互斥锁">自旋锁 vs. 互斥锁</a></h3>
<p>如果函数<code>workOnResource</code>在第24行停顿2秒，那CPU负载会发生怎样的变化?</p>
<pre><code class="language-c++">// spinLockSleep.cpp

#include &lt;atomic&gt;
#include &lt;thread&gt;

class Spinlock{
  std::atomic_flag flag = ATOMIC_FLAG_INIT;
public:
  
  void lock(){
    while(flag.test_and_set());
  }
  
  void unlock(){
    flag.clear();
  }
  
};

Spinlock spin;

void workOnResource(){
  spin.lock();
  std::this_thread::sleep_for(std::chrono::milliseconds(2000));
  spin.unlock();
}

int main(){
  
  std::thread t(workOnResource);
  std::thread t2(workOnResource);
  
  t.join();
  t2.join();
  
}
</code></pre>
<p>如下图所示，四个核中每次有一个是跑满了的。</p>
<p><img src="content/The-Details/Memory-Model/../../../images/detail/memory-model/5.png" alt="" /></p>
<p>我的PC上有一个核的负载达到100%，每次不同的核芯执行”忙等待“。</p>
<p>我现在用互斥锁来替换自旋锁。让我们看下会发生什么。</p>
<pre><code class="language-c++">// mutex.cpp

#include &lt;mutex&gt;
#include &lt;thread&gt;

std::mutex mut;

void workOnResource(){
  mut.lock();
  std::this_thread::sleep_for(std::chrono::milliseconds(5000));
  mut.unlock();
}

int main(){
  
  std::thread t(workOnResource);
  std::thread t2(workOnResource);
  
  t.join();
  t2.join();
  
}
</code></pre>
<p>虽然执行了好几次，但是并没有观察到任何一个核上有显著的负载。</p>
<p>这样就能看出二者的区别了吧。</p>
<p><img src="content/The-Details/Memory-Model/../../../images/detail/memory-model/6.png" alt="" /></p>
<p>接下来，了解下<code>std::atomic</code>模板。</p>
<h2 id="stdatomic模板"><a class="header" href="#stdatomic模板"><code>std::atomic</code>模板</a></h2>
<p><code>std::atomic</code>有各种变体。</p>
<p>直接使用模板类：<code>std::atomic&lt;bool&gt;</code>和<code>std::atomic&lt;user-defined type&gt;</code>。</p>
<p>部分特化可用于指针类：<code>std::atomic&lt;T*&gt;</code>。</p>
<p>完全特化只能用于整型：<code>std::atomic&lt;integral type&gt;</code>。</p>
<p>布尔原子类型和用户定义原子类型具有相同的接口，原子指针扩展了布尔原子类型，以及整数原子类型的接口。因其扩展了原子指针的接口，所以同样适用于整数原子类型。</p>
<p>不过，不保证<code>std::atomic</code>的各种变体都是无锁的。</p>
<p>先从最简单的<code>std::atomic&lt;bool&gt;</code>开始吧。</p>
<h3 id="stdatomicbool"><a class="header" href="#stdatomicbool"><code>std::atomic&lt;bool&gt;</code></a></h3>
<p><code>std::atomic&lt;bool&gt;</code>的功能比<code>std::atomic_flag</code>强大很多。并且，可以显式地将其设置为true或false。</p>
<blockquote>
<p><strong>原子类型不可为volatile</strong></p>
<p>C#和Java中的<code>volatile</code>与C++中的<code>volatile</code>不同，这也是<code>volatile</code>和<code>std::atomic</code>之间的区别。</p>
<ul>
<li><code>volatile</code>：表示不允许对特定的对象进行读写优化。</li>
<li><code>std::atomic</code>：用来定义线程安全的原子变量。</li>
</ul>
<p><code>volatile</code>在Java和C#中，与<code>std::atomic</code>在C++中的含义相同。另外，在C++多线程语义中，没有<code>volatile</code>。</p>
<p><code>volatile</code>多应用于嵌入式编程中，表示可以(独立于常规程序流)进行更改的对象，例如：表示外部设备的对象(内存映射I/O)。由于这些对象可以更改，并且会直接写入主存中，因此不会在缓存中进行优化存储。</p>
</blockquote>
<p>这对于同步两个线程已经足够了，可以用<code>std::atomic&lt;bool&gt;</code>实现条件变量。</p>
<p>因此，先使用条件变量。</p>
<pre><code class="language-c++">// conditionVariable.cpp

#include &lt;condition_variable&gt;
#include &lt;iostream&gt;
#include &lt;thread&gt;
#include &lt;vector&gt;

std::vector&lt;int&gt; mySharedWork;
std::mutex mutex_;
std::condition_variable condVar;

bool dataReady{false};

void waitingForWork(){
  std::cout &lt;&lt; &quot;Waiting &quot; &lt;&lt; std::endl;
  std::unique_lock&lt;std::mutex&gt; lck(mutex_);
  condVar.wait(lck, []{return dataReady;});
  mySharedWork[1] = 2;
  std::cout &lt;&lt; &quot;Work done &quot; &lt;&lt; std::endl;
}

void setDataReady(){
  mySharedWork = {1, 0, 3};
  {
    std::lock_guard&lt;std::mutex&gt; lck(mutex_);
    dataReady = true;
  }
  std::cout &lt;&lt; &quot;Data prepared&quot; &lt;&lt; std::endl;
  condVar.notify_one();
}

int main(){
  std:cout &lt;&lt; std::endl;
  
  std::thread t1(waitingForWork);
  std::thread t2(setDataReady);
  
  t1.join();
  t2.join();
  
  for (auto v : mySharedWork){
    std::cout &lt;&lt; v &lt;&lt; &quot; &quot;;
  }
  
  std::cout &lt;&lt; &quot;\n\n&quot;;
}
</code></pre>
<p>简单说一下这段代码。线程<code>t1</code>在(第17行)等待线程<code>t2</code>的通知。两个线程使用相同的条件变量<code>condVar</code>，并在同一个互斥锁上进行同步。工作流如下所示：</p>
<ul>
<li>
<p>线程t1</p>
<ul>
<li>获取锁<code>lck</code>时，等待数据准备好的通知 <code>condVar.wait(lck, []{ return dataReady; })</code> 。</li>
<li>得到通知后，执行<code>mySharedWork[1] = 2</code>。</li>
</ul>
</li>
<li>
<p>线程t2</p>
<ul>
<li>准备数据<code>mySharedWork = {1, 0, 3}</code></li>
<li>将非原子布尔类型的<code>dataReady</code>置为true。</li>
<li>通过<code>condVar.notify_one</code>发布通知。</li>
</ul>
</li>
</ul>
<p>线程<code>t2</code>将<code>dataReady</code>设置为true，线程<code>t1</code>使用Lambda表达式对<code>dataReady</code>进行检查。不过，条件变量可能会出现两种不好的情况:</p>
<ol>
<li>伪唤醒：接受者在没有收到通知时被唤醒。</li>
<li>未唤醒：接收方在未处于等待状态时获得通知。</li>
</ol>
<p>使用<code>std::atomic&lt;bool&gt; </code>进行实现：</p>
<pre><code class="language-c++">// atomicCondition.cpp

#include &lt;atomic&gt;
#include &lt;chrono&gt;
#include &lt;iostream&gt;
#include &lt;thread&gt;
#include &lt;vector&gt;

std::vector&lt;int&gt; mySharedWork;
std::atomic&lt;bool&gt; dataReady(false);

void waitingForWork(){
  std::cout &lt;&lt; &quot;Waiting &quot; &lt;&lt; std::endl;
  while(!dataReady.load()){
    std::this_thread::sleep_for(std::chrono::milliseconds(5)); 
  }
  mySharedWork[1] = 2;
  std::cout &lt;&lt; &quot;Work done &quot; &lt;&lt; std::endl;
}

void setDataReady(){
  mySharedWork = {1,0,3};
  dataReady = true;
  std::cout &lt;&lt; &quot;Data prepared&quot; &lt;&lt; std::endl;
}

int main(){
  
  std::cout &lt;&lt; std::endl;
  
  std::thread t1(waitingForWork);
  std::thread t2(setDataReady);
  
  t1.join();
  t2.join();
  
  for (auto v : mySharedWork){
    std::cout &lt;&lt; v &lt;&lt; &quot; &quot;; 
  }
  
  std::cout &lt;&lt; &quot;\n\n&quot;;
}
</code></pre>
<p>如何保证第17行在第14行之后执行？或者说，线程<code>t1</code>在线程<code>t2</code>执行<code>mySharedWork ={1,0,3}</code>(第22行)后，执行<code>mySharedWork[1] = 2</code>(第17行)。</p>
<ul>
<li>第22行先于第23行执行。</li>
<li>第14行先于第17行执行。</li>
<li>第14、23行与第14行同步</li>
<li>因为同步建立了先行关系，并且先行关系可以传递，所以<code>mySharedWork = {1,0,3}</code>先于<code>mySharedWork[1] = 2</code>执行。</li>
</ul>
<p>很容易理解，对吧？简单起见，忽略同步创建的线程间先行关系，以及线程间已建立的先行关系。如果对这里的细节感兴趣，可以参考这里：<a href="http://en.cppreference.com/w/cpp/atomic/memory_order">内存序(memory_order)</a>。</p>
<p>两段程序产生了相同的结果。</p>
<p><img src="content/The-Details/Memory-Model/../../../images/detail/memory-model/7.png" alt="" /></p>
<blockquote>
<p><strong>推拉原理</strong></p>
<p>条件变量的同步与<code>std::atomic&lt;bool&gt;</code>之间有一个关键性的区别。条件变量会让线程等待通知(<code>condVar.notify()</code>)。检查<code>std::atomic&lt;bool&gt;</code>的线程，只是为了确定发送方是否完成了其工作(<code>dataRead = true</code>)。</p>
<p>条件变量通知等待线程对应为&quot;推原则(push principle)&quot;，而原子布尔值的重复轮询对应为&quot;拉原则(pull principle)&quot;。</p>
</blockquote>
<p><code>std::atomic&lt;bool&gt;</code>和<code>std::atomic</code>的其他全/偏特化都支持的原子操作：<code>compare_exchange_strong</code>和<code>compare_exchange_strong</code>。</p>
<blockquote>
<p><strong>compare_exchange_strong和compare_exchange_weak</strong> </p>
<p>compare_exchange_strong的声明为<code>bool compare_exchange_strong(T&amp; expected, T&amp; desired)</code>。此操作为比较和交换，因此也称为比较-交换(compare and swap，CAS)操作。这种操作在许多编程语言中都有用到，并且是非阻塞算法的基础。当然，C++中的行为可能会与其他语言不同。<code>atomicValue.compare_exchange_strong(expected, desired)</code>具有以下行为。</p>
<ul>
<li>如果<code>atomicValue</code>的值与期望值(expected)的比较返回true，则将<code>atomicValue</code>设置为所需值(desired)。</li>
<li>如果比较返回false，则将expected值设置为<code>atomicValue</code>的值。</li>
</ul>
<p>compare_exchange_strong称为<strong>strong</strong>的原因显而易见。当然，还有一个compare_exchange_weak，<strong>weak</strong>版本可能会伪失败。这意味着，虽然<code>*atomicValue == expected</code>成立，但<code>atomicValue</code>没有被设置成<code>desired</code>，函数返回<code>false</code>，因此必须在循环中进行检查：<code>while (!atomicValue.compare_exchange_weak(expected, desired))</code>。弱形式的存在原因是，因为一些处理器(硬件)不支持原子比较交换指令。循环调用时，也应该首选弱形式。在某些平台上，弱形式运行得更快。</p>
<p>CAS操作对于<a href="https://lumian2015.github.io/lockFreeProgramming/aba-problem.html">ABA问题</a>，解决方式是开放的。先描述一下这个问题：读取一个值两次，每次都返回相同的值A；因此得出结论，在这两者之间没有变化。但是，两次读取过程中数值可能已经更改为B了。</p>
</blockquote>
<p>弱版本允许伪失败，也就是说，即使它们是相等的，结果也和<code>*this !=expected</code>一样。当比较-交换操作处于循环中时，弱版本可能在某些平台上具有更好的性能。</p>
<p>除了布尔值之外，还有指针、整型和用户定义类型的原子操作。</p>
<p>所有<code>std::atomic</code>的变种类型都支持CAS操作。</p>
<h3 id="用户定义类型的原子操作stdatomicuser-defined-type"><a class="header" href="#用户定义类型的原子操作stdatomicuser-defined-type">用户定义类型的原子操作<code>std::atomic&lt;user-defined type&gt;</code></a></h3>
<p>因为<code>std::atomic</code>是模板类，所以可以使用自定义的原子类型。</p>
<p>使用自定义类型用于原子类型<code>std::atomic&lt;user-defined type&gt;</code>时，有很多限制。原子类型<code>std::atomic&lt;user-defined type</code>&gt;与<code>std::atomic&lt;bool&gt;</code>具有相同的接口。</p>
<p>以下是自定义类型成为原子类型的限制：</p>
<ul>
<li>自定义类型对所有基类和有非静态成员的复制赋值操作必须非常简单。这意味着不能定义复制赋值操作符，但是可以使用<a href="http://en.cppreference.com/w/cpp/keyword/default">default</a>让编译器来完成这个操作符的定义。</li>
<li>自定义的类型不能有虚方法或虚基类</li>
<li>自定义的类型必须可按位比较，这样才能使用C函数<a href="http://en.cppreference.com/w/cpp/string/byte/memcpy">memcpy</a>或<a href="http://en.cppreference.com/w/cpp/string/byte/memcmp">memcmp</a>。</li>
</ul>
<p>主流平台都可以对<code>std::atomic&lt;user-defined type&gt;</code>进行原子操作，前提是用户定义类型的大小不大于<code>int</code>。</p>
<blockquote>
<p><strong>编译时检查类型属性</strong></p>
<p>可以使用以下函数在编译时，检查自定义类型的类型属性：<code>std::is_trivially_copy_constructible</code>, <code>std:: is_polymorphic</code>和<code>std::is_trivial</code>。这些函数都是类型特征库(<a href="http://en.cppreference.com/w/cpp/header/type_traits">type-traits library</a>)的一部分。</p>
</blockquote>
<p><strong><code>std::atomic&lt;T*&gt;</code></strong></p>
<p><code>std::atomic&lt;T*&gt;</code>是<code>std::atomic</code>类模板的偏特化类型。原子指针<code>std::atomic&lt;T*&gt;</code>支持与<code>std::atomic&lt;bool&gt;</code> 或<code>std::atomic&lt;user-defined type&gt;</code>相同的成员函数。它的行为就像一个普通的指针<code>T*</code>。<code>std::atomic&lt;T*&gt; </code>支持指针运算和前后递增或前后递减操作。</p>
<p>看个简单的例子。</p>
<pre><code class="language-c++">int intArray[5];
std::atomic&lt;int*&gt; p(intArray);
p++;
assert(p.load() == &amp;intArray[1]);
p+=1;
assert(p.load() == &amp;intArray[2]);
--p;
assert(p.load() == &amp;intArray[1]);
</code></pre>
<p>在C++11中，有原子整型。</p>
<p><strong><code>std::atomic&lt;integral type&gt;</code></strong></p>
<p>对于每个整数类型，都有相应的全特化<code>std::atomic&lt;integral type&gt;</code>版本。</p>
<p>对于哪些整型存做了全特化？让我们来看一下:</p>
<ul>
<li>字符类型: char , char16_t , char32_t 和 wchar_t</li>
<li>标准有符号整型: signed char , short , int , long 和 long long</li>
<li>标准无符号整型: unsigned char , unsigned short , unsigned int , unsigned long 和 unsigned long long</li>
<li>还有很多整型，都定义在<a href="http://en.cppreference.com/w/cpp/header/cstdint"><code>&lt;cstdint&gt;</code></a>中</li>
<li>int8_t , int16_t , int32_t 和 int64_t (8, 16, 32 和 64位的有符号整型)</li>
<li>uint8_t , uint16_t , uint32_t 和 uint64_t (8, 16, 32 和 64位的无符号整型)</li>
<li>int_fast8_t , int_fast16_t , int_fast32_t 和 int_fast64_t (8, 16, 32 和 64位的高速有符号整型)</li>
<li>uint_fast8_t , uint_fast16_t , uint_fast32_t 和 uint_fast64_t (8, 16, 32 和 64 位的高速无符号整型)</li>
<li>int_least8_t , int_least16_t , int_least32_t 和 int_least64_t (8, 16, 32 和 64 位的最小有符号整型)</li>
<li>uint_least8_t , uint_least16_t , uint_least32_t 和 uint_least64_t (8, 16, 32 和 64 位的最小无符号整型)</li>
<li>intmax_t 和 uintmax_t (最大有符号整数和无符号整数)</li>
<li>intptr_t 和 uintptr_t (用于存放有符号整数和无符号整数指针)</li>
</ul>
<p><code>std::atomic&lt;integral type&gt;</code>支持复合赋值运算符<code>+=</code>、<code>-=</code>、<code>&amp;=</code>、<code>|=</code>和<code>^=</code>，以及相应操作的方法：<code>fetch_add</code>、<code>fetch_sub</code>、<code>fetch_and</code>、<code>fetch_or</code>和<code>fetch_xor</code>。复合赋值运算符返回新值，而fetch操作返回旧值。此外，复合赋值运算符还支持前增量和后增量，以及前减量和后减量(++x, x++，--x和x--)。</p>
<p>更深入的研究前需要了解一些前提：原子操作没有原子乘法、原子除法，也没有移位操作。这不是重要的限制，因为这些操作很少需要，并且很容易实现。下面就是是实现原子<code>fetch_mult</code>的例子。</p>
<pre><code class="language-c++">// fetch_mult.cpp

#include &lt;atomic&gt;
#include &lt;iostream&gt;

template &lt;typename T&gt;
T fetch_mult(std::atomic&lt;T&gt;&amp; shared, T mult){
  T oldValue = shared.load();
  while(!shared.compare_exchange_strong(oldValue, oldValue * mult));
  return oldValue;
}

int main(){
  std::atomic&lt;int&gt; myInt{5};
  std::cout &lt;&lt; myInt &lt;&lt; std::endl;
  fetch_mult(myInt, 5);
  std::cout &lt;&lt; myInt &lt;&lt; std::endl;
}
</code></pre>
<p>值得一提的是，第9行的乘法只在<code>oldValue == shared</code>成立时才会发生。因为在第8行中有两条读取<code>oldValue</code>的指令，我将乘法放在<code>while</code>循环中，以确保乘法能顺利执行。</p>
<p><img src="content/The-Details/Memory-Model/../../../images/detail/memory-model/8.png" alt="" /></p>
<blockquote>
<p><strong>fetch_mult无锁</strong></p>
<p><code>fetch_mult</code>(第6行)将<code>std::atomic</code>变量与<code>mult</code>相乘。关键在读取旧值<code>T oldValue = shared Load</code>(第8行)和比较第9行中的新值之间，有一个窗口时间。因此，其他线程总是可以介入并更改<code>oldValue</code>。如果线程间有糟糕的交错，就会发现每个线程可能都有自己的结果。</p>
<p>该算法是无锁的，但不是无等待的。</p>
</blockquote>
<h3 id="类型别名"><a class="header" href="#类型别名">类型别名</a></h3>
<p>对于所有<code>std::atomic&lt;bool&gt;</code>和<code>std::atomic&lt;integral type&gt;</code>(如果integral类型可用)，C++标准提供类型别名。</p>
<p><code>std::atomic&lt;bool&gt;</code>和<code>std::atomic&lt;integral type&gt;</code>的类型别名如下：</p>
<table><thead><tr><th align="center">类型别名</th><th align="center">具体定义</th></tr></thead><tbody>
<tr><td align="center"><code>std::atomic_bool</code></td><td align="center"><code>std::atomic&lt;bool&gt;</code></td></tr>
<tr><td align="center"><code>std::atomic_char</code></td><td align="center"><code>std::atomic&lt;char&gt;</code></td></tr>
<tr><td align="center"><code>std::atomic_schar</code></td><td align="center"><code>std::atomic&lt;signed char&gt;</code></td></tr>
<tr><td align="center"><code>std::atomic_uchar</code></td><td align="center"><code>std::atomic&lt;unsigned char&gt;</code></td></tr>
<tr><td align="center"><code>std::atomic_short</code></td><td align="center"><code>std::atomic&lt;short&gt;</code></td></tr>
<tr><td align="center"><code>std::atomic_ushort</code></td><td align="center"><code>std::atomic&lt;unsigned short&gt;</code></td></tr>
<tr><td align="center"><code>std::atomic_int</code></td><td align="center"><code>std::atomic&lt;int&gt;</code></td></tr>
<tr><td align="center"><code>std::atomic_uint</code></td><td align="center"><code>std::atomic&lt;unsigned int&gt;</code></td></tr>
<tr><td align="center"><code>std::atomic_long</code></td><td align="center"><code>std::atomic&lt;long&gt;</code></td></tr>
<tr><td align="center"><code>std::atomic_ulong</code></td><td align="center"><code>std::atomic&lt;unsigned long&gt;</code></td></tr>
<tr><td align="center"><code>std::atomic_llong</code></td><td align="center"><code>std::atomic&lt;long long&gt;</code></td></tr>
<tr><td align="center"><code>std::atomic_ullong</code></td><td align="center"><code>std::atomic&lt;unsigned long long&gt;</code></td></tr>
<tr><td align="center"><code>std::atomic_char16_t</code></td><td align="center"><code>std::atomic&lt;char16_t&gt;</code></td></tr>
<tr><td align="center"><code>std::atomic_char32_t</code></td><td align="center"><code>std::atomic&lt;char32_t&gt;</code></td></tr>
<tr><td align="center"><code>std::atomic_wchar_t</code></td><td align="center"><code>std::atomic&lt;wchar_t&gt;</code></td></tr>
<tr><td align="center"><code>std::atomic_int8_t</code></td><td align="center"><code>std::atomic&lt;std::int8_t&gt;</code></td></tr>
<tr><td align="center"><code>std::atomic_uint8_t</code></td><td align="center"><code>std::atomic&lt;std::uint8_t&gt;</code></td></tr>
<tr><td align="center"><code>std::atomic_int16_t</code></td><td align="center"><code>std::atomic&lt;std::int16_t</code>&gt;</td></tr>
<tr><td align="center"><code>std::atomic_uint16_t</code></td><td align="center"><code>std::atomic&lt;std::uint16_t</code>&gt;</td></tr>
<tr><td align="center"><code>std::atomic_int32_t</code></td><td align="center"><code>std::atomic&lt;std::int32_t&gt;</code></td></tr>
<tr><td align="center"><code>std::atomic_uint32_t</code></td><td align="center"><code>std::atomic&lt;std::uint32_t&gt;</code></td></tr>
<tr><td align="center"><code>std::atomic_int64_t</code></td><td align="center"><code>std::atomic&lt;std::int64_t&gt;</code></td></tr>
<tr><td align="center"><code>std::atomic_uint64_t</code></td><td align="center"><code>std::atomic&lt;std::uint64_t&gt;</code></td></tr>
<tr><td align="center"><code>std::atomic_int_least8_t</code></td><td align="center"><code>std::atomic&lt;std::int_least8_t&gt;</code></td></tr>
<tr><td align="center"><code>std::atomic_uint_least8_t</code></td><td align="center"><code>std::atomic&lt;std::uint_least8_t&gt;</code></td></tr>
<tr><td align="center"><code>std::atomic_int_least16_t</code></td><td align="center"><code>std::atomic&lt;std::int_least16_t&gt;</code></td></tr>
<tr><td align="center"><code>std::atomic_uint_least16_t</code></td><td align="center"><code>std::atomic&lt;std::uint_least16_t&gt;</code></td></tr>
<tr><td align="center"><code>std::atomic_int_least32_t</code></td><td align="center"><code>std::atomic&lt;std::int_least32_t&gt;</code></td></tr>
<tr><td align="center"><code>std::atomic_uint_least32_t</code></td><td align="center"><code>std::atomic&lt;std::uint_least32_t&gt;</code></td></tr>
<tr><td align="center"><code>std::atomic_int_least64_t</code></td><td align="center"><code>std::atomic&lt;std::int_least64_t&gt;</code></td></tr>
<tr><td align="center"><code>std::atomic_uint_least64_t</code></td><td align="center"><code>std::atomic&lt;std::uint_least64_t&gt;</code></td></tr>
<tr><td align="center"><code>std::atomic_int_fast8_t</code></td><td align="center"><code>std::atomic&lt;std::int_fast8_t&gt;</code></td></tr>
<tr><td align="center"><code>std::atomic_uint_fast8_t</code></td><td align="center"><code>std::atomic&lt;std::uint_fast8_t&gt;</code></td></tr>
<tr><td align="center"><code>std::atomic_int_fast16_t</code></td><td align="center"><code>std::atomic&lt;std::int_fast16_t&gt;</code></td></tr>
<tr><td align="center"><code>std::atomic_uint_fast16_t</code></td><td align="center"><code>std::atomic&lt;std::uint_fast16_t&gt;</code></td></tr>
<tr><td align="center"><code>std::atomic_int_fast32_t</code></td><td align="center"><code>std::atomic&lt;std::int_fast32_t&gt;</code></td></tr>
<tr><td align="center"><code>std::atomic_uint_fast32_t</code></td><td align="center"><code>std::atomic&lt;std::uint_fast32_t&gt;</code></td></tr>
<tr><td align="center"><code>std::atomic_int_fast64_t</code></td><td align="center"><code>std::atomic&lt;std::int_fast64_t&gt;</code></td></tr>
<tr><td align="center"><code>std::atomic_uint_fast64_t</code></td><td align="center"><code>std::atomic&lt;std::uint_fast64_t&gt;</code></td></tr>
<tr><td align="center"><code>std::atomic_intptr_t</code></td><td align="center"><code>std::atomic&lt;std::intptr_t&gt;</code></td></tr>
<tr><td align="center"><code>std::atomic_uintptr_t</code></td><td align="center"><code>std::atomic&lt;std::uintptr_t&gt;</code></td></tr>
<tr><td align="center"><code>std::atomic_size_t</code></td><td align="center"><code>std::atomic&lt;std::size_t&gt;</code></td></tr>
<tr><td align="center"><code>std::atomic_ptrdiff_t</code></td><td align="center"><code>std::atomic&lt;std::ptrdiff_t&gt;</code></td></tr>
<tr><td align="center"><code>std::atomic_intmax_t</code></td><td align="center"><code>std::atomic&lt;std::intmax_t&gt;</code></td></tr>
<tr><td align="center"><code>std::atomic_uintmax_t</code></td><td align="center"><code>std::atomic&lt;std::uintmax_t&gt;</code></td></tr>
</tbody></table>
<h3 id="所有原子操作"><a class="header" href="#所有原子操作">所有原子操作</a></h3>
<p>这是关于所有原子操作的列表。</p>
<table><thead><tr><th align="center">成员函数</th><th align="center">描述</th></tr></thead><tbody>
<tr><td align="center">test_and_set</td><td align="center">(原子性地)将标记设置为true，并返回旧值</td></tr>
<tr><td align="center">clear</td><td align="center">(原子性地)将标记设置为false</td></tr>
<tr><td align="center">is_lock_free</td><td align="center">检查原子是否无锁</td></tr>
<tr><td align="center">load</td><td align="center">(原子性地)返回原子变量的值</td></tr>
<tr><td align="center">store</td><td align="center">(原子性地)将原子变量的值替换为非原子值</td></tr>
<tr><td align="center">exchange</td><td align="center">(原子性地)用新值替换值，返回旧值</td></tr>
<tr><td align="center">compare_exchange_strong</td><td align="center">(原子性地)比较并交换值</td></tr>
<tr><td align="center">compare_exchange_weak</td><td align="center">(原子性地)比较并交换值</td></tr>
<tr><td align="center">fetch_add , +=</td><td align="center">(原子性地)加法</td></tr>
<tr><td align="center">fetch_sub , -=</td><td align="center">(原子性地)减法</td></tr>
<tr><td align="center">fetch_or , |=</td><td align="center">(原子性地)逻辑或</td></tr>
<tr><td align="center">fetch_and , &amp;=</td><td align="center">(原子性地)逻辑与</td></tr>
<tr><td align="center">fetch_xor , ^=</td><td align="center">(原子性地)逻辑异或</td></tr>
<tr><td align="center">++ , --</td><td align="center">(原子性地)自加和自减</td></tr>
</tbody></table>
<p>原子类型没有复制构造函数或复制赋值操作符，但支持从内置类型进行赋值和隐式转换。复合赋值运算符返回新值，fetch操作返回旧值。复合赋值运算符返回值，而不是所赋值对象的引用。</p>
<p>隐式转换为基础类型</p>
<pre><code class="language-c++">std::atomic&lt;long long&gt; atomOb(2011);
atomObj = 2014;
long long nonAtomObj = atomObj;
</code></pre>
<p>每个方法都支持内存序参数。默认的内存序是<code>std::memory_order_seq_cst</code>，也可以使用<code>std::memory_order_relaxed</code>, <code>std::memory_order_consume</code>, <code>std::memory_order_acquire</code>, <code>std::memory_order_release</code>或<code>std::memory_order_acq_rel</code>。<code>compare_exchange_strong</code>和 <code>compare_exchange_weak</code>可以传入两个内存序，一个是在比较成功的情况下所使用的内存序，另一个是在比较失败的情况下使用的。</p>
<p>如果只显式地提供一个内存序，那么成功和失败的情况都会使用该内存序。</p>
<p>当然，并不是所有操作对所有原子类型都可用。下表显示了所有原子类型支持的原子操作。</p>
<table><thead><tr><th align="center">函数名</th><th align="center">atomic_flag</th><th align="center"><code>atomic&lt;bool&gt;</code></th><th align="center"><code>atomic&lt;user&gt;</code></th><th align="center"><code>atomic&lt;T*&gt;</code></th><th align="center"><code>atomic&lt;integral&gt;</code></th></tr></thead><tbody>
<tr><td align="center">test_and_set</td><td align="center">yes</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td></tr>
<tr><td align="center">clear</td><td align="center">yes</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td></tr>
<tr><td align="center">is_lock_free</td><td align="center"></td><td align="center">yes</td><td align="center">yes</td><td align="center">yes</td><td align="center">yes</td></tr>
<tr><td align="center">load</td><td align="center"></td><td align="center">yes</td><td align="center">yes</td><td align="center">yes</td><td align="center">yes</td></tr>
<tr><td align="center">store</td><td align="center"></td><td align="center">yes</td><td align="center">yes</td><td align="center">yes</td><td align="center">yes</td></tr>
<tr><td align="center">exchange</td><td align="center"></td><td align="center">yes</td><td align="center">yes</td><td align="center">yes</td><td align="center">yes</td></tr>
<tr><td align="center">compare_exchange_strong</td><td align="center"></td><td align="center">yes</td><td align="center">yes</td><td align="center">yes</td><td align="center">yes</td></tr>
<tr><td align="center">compare_exchange_weak</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td></tr>
<tr><td align="center">fetch_add, +=</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center">yes</td><td align="center">yes</td></tr>
<tr><td align="center">fetch_sub, -=</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td></tr>
<tr><td align="center">fetch_or, |=</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center">yes</td></tr>
<tr><td align="center">fetch_and, &amp;=</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td></tr>
<tr><td align="center">fetch_xor, ^=</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td></tr>
<tr><td align="center">++, --</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center">yes</td><td align="center">yes</td></tr>
</tbody></table>
<h3 id="原子函数"><a class="header" href="#原子函数">原子函数</a></h3>
<p>为了与C语言兼容，这些函数使用的是指针而不是引用。所以，<code>std::atomic_flag</code>和类模板<code>std::atomic</code>的功能也可以与原子函数一起使用。</p>
<p><code>std::atomic_flag</code>的原子函数有：<code>std::atomic_flag_clear()</code>、<code>std::atomic_flag_clear_explicit</code>、<code>std::atomic_flag_test_and_set()</code>和<code>std::atomic_flag_test_set_explicit()</code>。所有函数的第一个参数都是指向<code>std::atomic_flag</code>的指针。另外，以<code>_explicit</code>为后缀的函数需要传入内存序。</p>
<p>对于每个<code>std::atomic</code>类型，都有相应的原子函数。原子函数遵循一个简单的命名约定：只在前面添加前缀<code>atomic_</code>。例如，<code>std::atomic</code>上的方法调用<code>at.store()</code>变成<code>std::atomic_store()</code>， <code>std::atomic_store_explicit()</code>。</p>
<p>可以在<a href="http://en.cppreference.com/w/cpp/atomic">atomic</a>了解所有的重载。</p>
<p><code>std::shared_ptr</code>算是个例外，其原子函数只能在原子类型上使用。</p>
<h3 id="stdshared_ptr"><a class="header" href="#stdshared_ptr">std::shared_ptr</a></h3>
<p><code>std::shared_ptr </code>是唯一可以使用原子操作的非原子数据类型。说明一下这样设计的动机。</p>
<p>C++委员会了解到，智能指针需要在多线程中提供最小原子性保证的必要性，所以做出了这样的设计。先来解释“最小原子性保证”，也就是<code>std::shared_ptr</code>的控制块是线程安全的，这意味着增加和减少引用计数器的是原子操作，也就能保证资源只被销毁一次了。</p>
<p><code>std::shared_ptr</code>的声明由<a href="http://www.boost.org/doc/libs/1_57_0/libs/smart_ptr/shared_ptr.htm#ThreadSafety">Boost</a>提供：</p>
<ol>
<li><code>shared_ptr</code>实例可以被多个线程同时“读”(仅<code>const</code>方式访问)。</li>
<li>不同的<code>shared_ptr</code>实例可以被多个线程同时“写”(通过操作符<code>=</code>或<code>reset</code>等操作访问)(即使这些实例是副本，但在底层共享引用计数)。</li>
</ol>
<p>为了使这两个表述更清楚，举一个简单的例子。当在一个线程中复制<code>std::shared_ptr</code>时，一切正常。</p>
<pre><code class="language-c++">std::shared_ptr&lt;int&gt; ptr = std::make_shared&lt;int&gt;(2011);

for (auto i = 0; i &lt; 10; i++){
  std::thread([ptr]{
    std::shared_ptr&lt;int&gt; localPtr(ptr);
    localPtr = std::make_shared&lt;int&gt;(2014);
  }).detach();
}
</code></pre>
<p>先看第5行，通过对<code>std::shared_ptr localPtr</code>使用复制构造，只使用控制块，这是线程安全的。第6行更有趣一些，为<code>localPtr</code>设置了一个新的<code>std::shared_ptr</code>。从多线程的角度来看，这不是问题：Lambda函数(第4行)通过复制绑定<code>ptr</code>。因此，对<code>localPtr</code>的修改在副本上进行。</p>
<p>如果通过引用获得<code>std::shared_ptr</code>，情况会发生巨变。</p>
<pre><code class="language-c++">std::shared_ptr&lt;int&gt; ptr = std::make_shared&lt;int&gt;(2011);

for (auto i = 0; i &lt; 10; i++){
  std::thread([&amp;ptr]{
    ptr = std::make_shared&lt;int&gt;(2014);
  }).detach();
}
</code></pre>
<p>Lambda函数通过引用，绑定了第4行中的<code>std::shared_ptr ptr</code>。这意味着，赋值(第5行)可能触发底层的并发读写，所以该段程序具有未定义行为(数据竞争)。</p>
<p>诚然，最后一个例子并不容易实现，但在多线程环境下使用<code>std::shared_ptr</code>也需要特别注意。同样需要注意的是，<code>std::shared_ptr</code>是C++中唯一存在原子操作的非原子数据类型。</p>
<h3 id="stdshared_ptr的原子操作"><a class="header" href="#stdshared_ptr的原子操作">std::shared_ptr的原子操作</a></h3>
<p><code>std::shared_ptr</code>的原子操作<code>load</code>、<code>store</code>、<code>compare_and_exchange</code>有专用的方法，甚至可以指定内存序。下面是<code>std::shared_ptr</code>的原子函数。</p>
<p><code>std::shared_ptr</code>的原子函数列表</p>
<hr />
<p><code>std::atomic_is_lock_free(std::shared_ptr)</code>
<code>std::atomic_load(std::shared_ptr)</code>
<code>std::atomic_load_explicit(std::shared_ptr)</code>
<code>std::atomic_store(std::shared_ptr)</code>
<code>std::atomic_store_explicit(std::shared_ptr)</code>
<code>std::atomic_exchange(std::shared_ptr)</code>
<code>std::atomic_exchange_explicit(std::shared_ptr)</code>
<code>std::atomic_compare_exchange_weak(std::shared_ptr)</code>
<code>std::atomic_compare_exchange_strong(std::shared_ptr)</code>
<code>std::atomic_compare_exchange_weak_explicit(std::shared_ptr)</code>
<code>std::atomic_compare_exchange_strong_explicit(std::shared_ptr)</code></p>
<hr />
<p>更多详情信息，请访问<a href="http://en.cppreference.com/w/cpp/memory/shared_ptr">cppreference.com</a>。现在，可以非常容易以线程安全的方式，修改引用绑定的共享指针了。</p>
<p><code>std::shared_ptr</code>数据竞争的解决实现</p>
<pre><code class="language-c++">std::shared_ptr&lt;int&gt; ptr = std::make_shared&lt;int&gt;(2011);

for (auto i = 0; i &lt; 10; i++){
  std::thread([&amp;ptr]{
    auto localPtr = std::make_shared&lt;int&gt;(2014);
    std::atomic_store(&amp;ptr, localPtr);
  }).detach();
}
</code></pre>
<p><code>auto localPtr = std::make_shared&lt;int&gt;(2014)</code>对<code>std::shared_ptr ptr</code>的更新是线程安全的。这样就完了吗？不！最后，我们需要了解下原子智能指针。</p>
<blockquote>
<p><strong>原子智能指针(Atomic Smart Pointers)</strong></p>
<p>原子智能指针的故事还没有结束。C++20中，我们很有可能看到两个新的智能指针:<code>std::atomic&lt;std::shared_ptr&gt;</code>和<code>std::atomic&lt;std::weak_ptr&gt;</code>。想要了解的读者可以翻到本书的原子智能指针章节，了解更多的细节。</p>
</blockquote>
<p>原子变量及其原子操作是内存模型的基础件，它们为原子和非原子建立同步和顺序约束。下面，让我们更深入地了解同步和顺序约束。</p>
<div style="break-before: page; page-break-before: always;"></div><p>#同步和顺序</p>
<p>虽然不能配置原子数据，但可以调整原子操作的同步和顺序。这在C#或Java的内存模型中是不可能的。</p>
<p>C++中有六种不同的内存模型，那这些内存模型分别是什么呢?</p>
<h2 id="c的六种内存序"><a class="header" href="#c的六种内存序">C++的六种内存序</a></h2>
<p>我们已经知道C++有六种不同的内存序。原子操作默认的内存序是<code>std::memory_order_seq_cst</code>，这表示顺序一致。此外，也可以显式地指定其他五个中的一个。那么剩余几个是什么呢?</p>
<p>C++中定义的内存序</p>
<pre><code class="language-c++">enum memory_order{
  memory_order_relaxed,
  memory_order_consume,
  memory_order_acquire,
  memory_order_release,
  memory_order_acq_rel,
  memory_order_seq_cst
}
</code></pre>
<p>对这六种内存序进行分类，需要回答两个问题:</p>
<ol>
<li>不同的原子操作应该使用哪种内存模型?</li>
<li>6个内存序定义了哪些同步和顺序?</li>
</ol>
<p>接下来的内容就是回答这两个问题。</p>
<h2 id="原子操作的种类"><a class="header" href="#原子操作的种类">原子操作的种类</a></h2>
<p>这里有三种不同类型的原子操作：</p>
<ul>
<li>读(read)操作: <code>memory_order_acquire</code>和<code>memory_order_consume</code></li>
<li>写(write)操作: <code>memory_order_release</code></li>
<li>读改写(read-modify-write)操作: <code>memory_order_acq_rel</code>和<code>memory_order_seq_cst</code></li>
</ul>
<p><code>memory_order_relaxed</code>无同步和操作顺序，所以它不适用于这种分类方式。</p>
<p>下表根据原子操作的读写特性对它们进行排序。</p>
<table><thead><tr><th align="center">操作名称</th><th align="center">read</th><th align="center">write</th><th align="center">read-modify-write</th></tr></thead><tbody>
<tr><td align="center">test_and_set</td><td align="center"></td><td align="center"></td><td align="center">yes</td></tr>
<tr><td align="center">clear</td><td align="center"></td><td align="center">yes</td><td align="center"></td></tr>
<tr><td align="center">is_lock_free</td><td align="center">yes</td><td align="center"></td><td align="center"></td></tr>
<tr><td align="center">load</td><td align="center">yes</td><td align="center"></td><td align="center"></td></tr>
<tr><td align="center">store</td><td align="center"></td><td align="center">yes</td><td align="center"></td></tr>
<tr><td align="center">exchange</td><td align="center"></td><td align="center"></td><td align="center">yes</td></tr>
<tr><td align="center">compare_exchange_strong</td><td align="center"></td><td align="center"></td><td align="center">yes</td></tr>
<tr><td align="center">compare_exchange_weak</td><td align="center"></td><td align="center"></td><td align="center"></td></tr>
<tr><td align="center">fetch_add, +=</td><td align="center"></td><td align="center"></td><td align="center">yes</td></tr>
<tr><td align="center">fetch_sub, -=</td><td align="center"></td><td align="center"></td><td align="center"></td></tr>
<tr><td align="center">fetch_or, |=</td><td align="center"></td><td align="center"></td><td align="center">yes</td></tr>
<tr><td align="center">fetch_and, &amp;=</td><td align="center"></td><td align="center"></td><td align="center"></td></tr>
<tr><td align="center">fetch_xor, ^=</td><td align="center"></td><td align="center"></td><td align="center"></td></tr>
<tr><td align="center">++, --</td><td align="center"></td><td align="center"></td><td align="center">yes</td></tr>
</tbody></table>
<p>“读改写”操作还需要提供最新的值，不同线程上的<code>atomVar.fetch_sub(1)</code>操作序列一个接一个地无缝衔接或进行重复的计数。</p>
<p>如果将原子操作<code>atomVar.load()</code>与“写”或“读改写”操作一起使用，那么“写”的部分将不起作用。结果就是：<code>atomVar.load(std::memory_order_acq_rel)</code>等价于<code>atomVar.load(std::memory_order_acquire)</code>，<code>atomVar.load(std::memory_order_release)</code>等价于<code>atomVar.load(std::memory_order_relax)</code>。</p>
<h2 id="同步与顺序的不同"><a class="header" href="#同步与顺序的不同">同步与顺序的不同</a></h2>
<p>大致说来，C++中有三种不同类型的同步和顺序:</p>
<ul>
<li>顺序一致: <code>memory_order_seq_cst</code></li>
<li>获取-释放(Acquire-release)：<code>memory_order_consume</code> , <code>memory_order_acquire</code> ,<code> memory_order_release</code>和<code>memory_order_acq_rel</code></li>
<li>自由序(Relaxed): <code>memory_order_relaxed</code></li>
</ul>
<p>顺序一致在线程之间建立全局顺序。获取-释放语义为不同线程之间，对同一原子变量进行读写操作时建立顺序。自由语序只保证了原子变量的修改顺序，修改顺序是指对一个特定原子变量的所有修改都以某种特定的顺序发生。因此，由特定线程读取原子对象时，不会看到“更旧”的值。</p>
<p>不同的内存模型，及其对原子和非原子操作的影响，也使得C++内存模型好玩但又有挑战性。下面我们来讨论顺序一致、获得-释放语义和自由语义的同步和顺序。</p>
<h3 id="顺序一致"><a class="header" href="#顺序一致">顺序一致</a></h3>
<p>让我们深入地研究一下顺序一致，其关键是所有线程上的所有操作都遵从一个通用时钟。这个全球时钟让我们可以很直观的想象它的存在。</p>
<p>顺序一致的直观性是有代价的，缺点是系统必须对线程进行同步。</p>
<p>下面的程序在顺序一致性的帮助下，同步生产者和消费者线程。</p>
<pre><code class="language-c++">// producerConsumer.cpp

#include &lt;atomic&gt;
#include &lt;iostream&gt;
#include &lt;string&gt;
#include &lt;thread&gt;

std::string work;
std::atomic&lt;bool&gt; ready(false);

void consumer(){
  while(!ready.load()){}
  std::cout &lt;&lt; work &lt;&lt; std::endl;
}

void producer(){
  work = &quot;done&quot;;
  ready = true;
}

int main(){
  std::thread prod(producer);
  std::thread con(consumer);
  prod.join();
  con.join();
}
</code></pre>
<p>这个程序的输出：</p>
<p><img src="content/The-Details/Memory-Model/../../../images/detail/memory-model/9.png" alt="" /></p>
<p>由于顺序一致，程序执行结果是确定的，所以总是输出“done”。</p>
<p>下图描述了操作的顺序。消费者线程在<code>while</code>循环中等待，等待原子变量<code>ready</code>被生产者线程设置为<code>true</code>。当这种情况发生时，消费者线程将继续其工作。</p>
<p><img src="content/The-Details/Memory-Model/../../../images/detail/memory-model/10.png" alt="" /></p>
<p>理解程序总是返回“done”并不难，只需要使用顺序一致的两个特点：一方面，两个线程以源码顺序执行指令；另一方面，每个线程以相同的顺序查看另一个线程的操作。也就是，两个线程遵循相同的时钟。<code>while(!ready.load()){}</code>循环中，这种同步也可以保持下去——用于同步生产者线程和消费者线程。</p>
<p>通过使用内存序，可以更正式地解释这个过程。以下是正式版本:</p>
<ol>
<li><code>work= &quot;done&quot;</code>在序列中，位于<code>ready = true</code>之前
⇒ <code>work= &quot;done&quot;</code>先行与<code>ready = true</code></li>
<li><code>while(!ready.load()){}</code>序列位于<code>std::cout &lt;&lt; work &lt;&lt; std::endl</code>之前
⇒ <code>while(!ready.load()){}</code>先行与<code>std::cout&lt;&lt; work &lt;&lt; std::endl</code></li>
<li><code>ready= true</code>与<code>while(!ready.load()){}</code>同步
⇒ <code>ready= true</code>(线程间)先行于<code>while (!ready.load()){}</code>
⇒ <code>ready= true</code>先行于<code>while (!ready.load()){}</code></li>
</ol>
<p>最终的结论：因为先行关系是可以传递的，所以<code>work = &quot;done&quot;</code>先行于<code>ready= true</code>，且先行于<code>while(!ready.load()){}</code>，更先行于<code>std::cout&lt;&lt; work &lt;&lt; std::endl</code>。</p>
<p>顺序一致中，一个线程可以看到另一个线程的操作，因此也可以看到所有其他线程的操作。如果使用原子操作的获取-释放语义，那么顺序一致就不成立了。这是与C#和Java不同的地方，也是容易产生疑惑的地方。</p>
<h3 id="获取-释放语义"><a class="header" href="#获取-释放语义">获取-释放语义</a></h3>
<p>获取-释放语义中，线程间不存在全局同步：只有同一原子变量上的原子操作才进行同步。比如：一个线程上的写操作与另一个线程上的读操作，只有作用于同一个原子变量时才进行同步。</p>
<p>获取-释放语义的基本思想：释放操作与获取操作在同一原子上同步，并建立一个顺序。这意味着，在释放操作之后不能进行所有的读写操作，在获取操作之前不能进行所有的读写操作。</p>
<p>什么是获取/释放操作？使用<code>load</code>或<code>test_and_set</code>读取原子变量是一个获取操作。还有，锁或互斥锁的释放与获取是同步的，线程的构造与调用间是同步的，线程的完成与汇入调用间的操作是同步的，任务可调用的完成与等待或获取future的调用操作是同步的。所以，获取和释放操作是成对的。</p>
<p>下面这张图有助于对获取-释放语义的理解：</p>
<p><img src="content/The-Details/Memory-Model/../../../images/detail/memory-model/11.png" alt="" /></p>
<blockquote>
<p><strong>内存模型——更深入地理解多线程</strong></p>
<p>这应该是了解内存模型的主要原因。特别是，获取-释放语义可以更好地理解高级同步原语，比如互斥锁。同样的原理也适用于线程的启动和汇入。这两种操作都是获取-释放操作。接下来是<code>wait</code>和<code>notify_one</code>对条件变量的调用；<code>wait</code>是获取操作，<code>notify_one</code>是释放操作。那<code>notify_all</code>呢？当然，也是一个释放操作。</p>
</blockquote>
<p>现在，再看<code>std::atomic_flag</code>小节中的自旋锁。因为同步是使用<code>atomic_flag flag</code>完成的，所以可以使用获取-释放语义，进行更高效的实现。</p>
<pre><code class="language-c++">// spinlockAcquireRelease.cpp

#include &lt;atomic&gt;
#include &lt;thread&gt;

class Spinlock{
  std::atomic_flag flag;
public:
  Spinlock():flag(ATOMIC_FLAG_INIT){}
  
  void lock(){
    while(flag.test_and_set(std::memory_order_acquire));
  }
  
  void unlock(){
    flag.clear(std::memory_order_release);
  }
};

Spinlock spin;

void workOnResource(){
	spin.lock();
  // shared resource
  spin.unlock();
}

int main(){
  
  std::thread t(workOnResource);
  std::thread t2(workOnResource);
  
  t.join();
  t2.join();
}
</code></pre>
<p>第16行<code>flag.clear</code>清除标志，<code>test_and_set</code>在第12行调用一个获取操作，获取操作与释放操作同步。具有顺序一致的两个线程的同步(重量级同步)(<code>std::memory_order_seq_cst</code>)被更轻量级的和性能更强的获取-释放语义(<code>std::memory_order_acquire</code>和<code>std::memory_order_release</code>)所取代，且程序行为不受影响。</p>
<p>虽然<code>flag.test_and_set(std::memory_order_acquire)</code>调用是一个&quot;读改写&quot;操作，但是获取语义已经足够了。因为<code>flag</code>是原子的，可以保证修改顺序。这也就意味着，对<code>flag</code>的所有修改，都可以某种特定的顺序进行。</p>
<p>获得-释放语义是可传递的。如果两个线程(a,b)之间遵循获取-释放语义，且线程(b,c)之间也遵循获取-释放语义，那么在线程(a, c)之间也遵循获取-释放语义。</p>
<h4 id="传递性"><a class="header" href="#传递性">传递性</a></h4>
<p>释放与获取操作在同一个原子变量上同步，并建立顺序。如果它们作用于相同的原子变量，这些组件将以最高效的方式同步线程。如果两个线程没有共享的原子变量，会如何工作呢？不想使用顺序一致语义，因为代价过高，我们想要更轻量级的获取-释放语义。</p>
<p>解决方式很简单，就是利用获取-释放语义的传递性，可以同步独立线程。</p>
<p>下面的示例中，线程<code>t2</code>及其工作包<code>deliveryBoy</code>是两个独立线程<code>t1</code>和<code>t3</code>之间的连接线程。</p>
<pre><code class="language-c++">// transitivity.cpp

#include &lt;atomic&gt;
#include &lt;iostream&gt;
#include &lt;thread&gt;
#include &lt;vector&gt;

std::vector&lt;int&gt; mySharedWork;
std::atomic&lt;bool&gt; dataProduced(false);
std::atomic&lt;bool&gt; dataConsumed(false);

void dataProducer(){
  mySharedWork = {1,0,3};
  dataProduced.store(true, std::memory_order_release);
}

void deliverBoy(){
  while(!dataProduced.load(std::memory_order_acquire));
  dataConsumed.store(true, std::memory_order_release);
}

void dataConsumer(){
  while(!dataConsumed.load(std::memory_order_acquire));
  mySharedWork[1] = 2;
}

int main(){
  std::cout &lt;&lt; std::endl;
  
  std::thread t1(dataConsumer);
  std::thread t2(deliverBoy);
  std::thread t3(dataProducer);
  
  t1.join();
  t2.join();
  t3.join();
  
  for (auto v : mySharedWork){
    std::cout &lt;&lt; v &lt;&lt; &quot; &quot;;
  }
  
  std::cout &lt;&lt; &quot;\n\n&quot;;
  
}
</code></pre>
<p>程序的输出是唯一的，<code>mySharedWork</code>的值为<code>1, 2, 3</code>。</p>
<p><img src="content/The-Details/Memory-Model/../../../images/detail/memory-model/12.png" alt="" /></p>
<p>通过观察，得出两个结论：</p>
<ol>
<li>线程<code>t2</code>在第18行等待，直到线程<code>t3</code>将<code>dataProduced</code>设置为<code>true</code>(第14行)。</li>
<li>线程<code>t1</code>在第23行等待，直到线程<code>t2</code>将<code>dataConsumed</code>设置为<code>true</code>(第19行)。</li>
</ol>
<p>用图来解释下：</p>
<p><img src="content/The-Details/Memory-Model/../../../images/detail/memory-model/13.png" alt="" /></p>
<p>图中主要部分是箭头。</p>
<ul>
<li>蓝色箭头是顺序关系，线程中的所有操作都是按源码顺序执行。</li>
<li>红色的箭头是同步关系。原因是对同一原子变量的原子操作遵循的获取-释放语义。原子变量之间，以及线程同步发生在特定的点上。</li>
<li>顺序关系建立了先行关系，再使用线程间的先行关系建立同步关系。</li>
</ul>
<p>剩下的部分就好理解了，线程间的先行指令顺序对应于箭头的方向。最后，能够保证<code>mySharedWork[1] == 2</code>。</p>
<p>释放-获取操作是同步的(同一个原子变量)，所以可以很容易地同步线程，不过…… 我们还要看几个误解。</p>
<h4 id="典型的误解"><a class="header" href="#典型的误解">典型的误解</a></h4>
<p>写关于获取-释放语义误解的原因是什么?我的许多读者和学生已经发现了这些陷阱。让我们来看一个简单的例子。</p>
<h5 id="等待"><a class="header" href="#等待">等待</a></h5>
<p>以一个简单的程序作为基点。</p>
<pre><code class="language-c++">// acquireReleaseWithWaiting.cpp

#include &lt;atomic&gt;
#include &lt;iostream&gt;
#include &lt;thread&gt;
#include &lt;vector&gt;

std::vector&lt;int&gt; mySharedWork;
std::atomic&lt;bool&gt; dataProduced(false);

void dataProducer(){
  mySharedWork = {1,0,3};
  dataProduced.store(true, std::memory_order_release);
}

void dataConsumer(){
  while(!dataProduced.load(std::memory_order_acquire));
  mySharedWork[1] = 2;
}

int main(){
  
  std::cout &lt;&lt; std::endl;
  
  std::thread t1(dataConsumer);
  std::thread t2(dataProducer);
  
  t1.join();
  t2.join();
  
  for (auto v: mySharedWork){
    std::cout &lt;&lt; v &lt;&lt; &quot; &quot;;
  }
    
  std::cout &lt;&lt; &quot;\n\n&quot;;
  
}
</code></pre>
<p>第17行的消费者线程<code>t1</code>持续等待，直到第13行的消费者线程<code>t2</code>将数据设置为true。非原子变量<code>mySharedWork</code>受<code>dataProduced</code>的保护，访问是同步的。这意味着生产者线程<code>t2</code>初始化<code>mySharedWork</code>，然后消费者线程<code>t2</code>通过设置<code>mySharedWork[1]</code>为2来完成工作，是没有问题的。</p>
<p><img src="content/The-Details/Memory-Model/../../../images/detail/memory-model/14.png" alt="" /></p>
<p>下图显示了线程中的先行关系和线程之间的同步关系。同步在线程间建立了先行关系，其余顺序可以根据先行关系的传递性推理得出。</p>
<p>最后，让<code>mySharedWork = {1, 0, 3} </code>先行于<code>mySharedWork[1] = 2 </code>。</p>
<p><img src="content/The-Details/Memory-Model/../../../images/detail/memory-model/15.png" alt="" /></p>
<p>有没有感觉这个推理过程中经常缺少什么？</p>
<h5 id="如果"><a class="header" href="#如果">如果……</a></h5>
<p>如果第17行中的消费者线程<code>t1</code>没有等待生产者线程<code>t2</code>，会发生什么?</p>
<pre><code class="language-c++">// acquireReleaseWithoutWaiting.cpp

#include &lt;atomic&gt;
#include &lt;iostream&gt;
#include &lt;thread&gt;
#include &lt;vector&gt;

std::vector&lt;int&gt; mySharedWork;
std::atomic&lt;bool&gt; dataProduced(false);

void dataProducer(){
  mySharedWork = {1,0,3};
  dataProduced.store(true, std::memory_order_release);
}

void dataConsumer(){
 	dataProduced.load(std::memory_order_acquire);
  myShraedWork[1] = 2;
}

int main(){
  
  std::cout &lt;&lt; std::endl;
  
  std::thread t1(dataConsumer);
  std::thread t2(dataProducer);
  
  t1.join();
  t2.join();
  
  for (auto v : mySharedWork){
    std::cout &lt;&lt; v &lt;&lt; &quot; &quot;;
  }
  
  std::cout &lt;&lt; &quot;\n\n&quot;;
  
}
</code></pre>
<p>因为变量<code>mySharedWork</code>上存在数据竞争，所以该程序具有未定义行为。当程序运行时，将得到以下结果。</p>
<p><img src="content/The-Details/Memory-Model/../../../images/detail/memory-model/16.png" alt="" /></p>
<p>问题在哪里呢？<code>dataProduced.store(true, std::memory_order_release)</code>与<code>dataProduced.load(std::memory_order_acquire)</code>同步。不过，并不意味着获取操作要对释操作进行等待，而这正是下图中的内容。图中，<code>dataProduced.load(std::memory_order_acquire)</code>在指令<code>dataProduced.store(true, std::memory_order_release)</code>之前，所以这里没有同步关系。</p>
<p><img src="content/The-Details/Memory-Model/../../../images/detail/memory-model/17.png" alt="" /></p>
<h4 id="解决办法"><a class="header" href="#解决办法">解决办法</a></h4>
<p>同步意味着：当<code>dataProduced.store(true, std::memory_order_release) </code>先行于<code>dataProduced.load(std::memory_order_acquire)</code>，那么<code>dataProduced.store(true, std::memory_order_release)</code>之前和<code>dataProduced.load(std::memory_order_acquire)</code>之后执行的操作是所有线程可见的。第一个程序中使用<code>while(! dataproduct .load(std::memory_order_acquire))</code>来保证同步关系。</p>
<p>再描述一次，使用正式方式。</p>
<p>当满足条件：<code>dataProduced.store(true, std::memory_order_release)</code>先行于<code>dataProduced.load(std::memory_order_acquire) </code>时，<code>dataProduced.store(true, std::memory_order_release)</code>之前执行的操作先行于所有<code>dataProduced.load(std::memory_order_acquire)</code>之后执行的操作。</p>
<h4 id="释放顺序"><a class="header" href="#释放顺序">释放顺序</a></h4>
<p>处理获取-释放语义时，释放顺序是一个相当高级的概念。因此，我们首先从以下的获取-释放语义示例开始说起。</p>
<pre><code class="language-c++">// releaseSequence.cpp

#include &lt;atomic&gt;
#include &lt;thread&gt;
#include &lt;iostream&gt;
#include &lt;mutex&gt;

std::atomic&lt;int&gt; atom{0};
int somethingShared{0};

using namespace std::chrono_literals;

void writeShared(){
  somethingShared = 2011;
  atom.store(2, std::memory_order_release);
}

void readShared(){
  while(!(atom.fetch_sub(1, std::memory_order_acquire) &gt; 0)){
    std::this_thread::sleep_for(100ms);
  }
  std::cout &lt;&lt; &quot;somethingShared: &quot; &lt;&lt; somethingShared &lt;&lt; std::endl;
}

int main(){
  
  std::cout &lt;&lt; std::endl;
  
  std::thread t1(writeShared);
  std::thread t2(readShared);
  // std::thread t3(readShared);
  
  t1.join();
  t2.join();
  // t3.join();
  
  std::cout &lt;&lt; &quot;atom: &quot; &lt;&lt; atom &lt;&lt; std::endl;
  
  std::cout &lt;&lt; std::endl;
  
}
</code></pre>
<p>先看看没有线程<code>t3</code>的例子。第15行对原子进行存储操作，第19行对原子获取并同步线程，这里对非原子变量<code>somethingShared</code>的访问不存在数据竞争。</p>
<p>如果打开<code>t3</code>线程的注释，会发生什么变化？现在就有可能出现“数据竞争”了。如前所述，<code>atom.fetch_sub(1, std::memory_order_acquire) </code>(第19行)与<code> atom.store(2, std::memory_order_release)</code>(第15行)间，<code>atom</code>变量遵循获取-释放语序；因此，在<code>somethingShared </code>变量的访问上没有数据竞争。</p>
<p>但对于第二次调用<code>atom.fetch_sub(1, std::memory_order_acquire)</code>，获取-释放语序则不起作用了。第二次调用则是一个读改写操作，因为已经没有在对<code>std::memory_order_release</code>进行标记了。这也就时第二次调用与第一次调用并没有同步关系，所以会发生对共享变量的数据竞争。也许，释放顺序可能不会让数据竞争发生。这里，释放序列扩展到对<code>atom.fetch_sub(1, std::memory_order_acquire) </code>的第二次调用；因此，第二次调用<code>atom.fetch_sub(1, std::memory_order_acquire)</code>先行于第一次调用。</p>
<p>最终，我们可能会得到如下的结果：</p>
<p><img src="content/The-Details/Memory-Model/../../../images/detail/memory-model/18.png" alt="" /></p>
<p>更正式的释放顺序的由N4659定义(<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/n4659.pdf">N4659: Working Draft, Standard for Programming Language C++</a>)。</p>
<blockquote>
<p><strong>释放顺序</strong></p>
<p>释放顺序由一个释放操作A和一个原子对象M构成，修改M顺序会对最大连续子操作序列有所影响，也就是A的第一次调用和随后由相同线程执行的的<code>*</code>操作。这里<code>*</code>指的是对源子的读改写操作。</p>
</blockquote>
<p>如果仔细看了我的解释，可能会期待接下来出现自由语义；不过，我们还是来看下内存模型<code>std:: memory_order_consumption</code>，它与<code>std::memory_order_acquire</code>非常相似</p>
<h4 id="stdmemory_order_consume"><a class="header" href="#stdmemory_order_consume">std::memory_order_consume</a></h4>
<p><code>std::memory_order_consume </code>是六种内存序中最传奇的一个。原因有二：一，<code>std:: memory_order_consumption</code>非常难理解；二，因为目前没有编译器支持它，所以这个内存序可能在未来会进行修改。C++17中的情况更糟，官方的说法是：“释放-消费序的规范正在修改，暂不推荐使用<code>memory_order_consumption</code>。”</p>
<p>为什么不支持<code>std:: memory_order_consumption</code>呢？答案是，编译器会将<code>std:: memory_order_consumption</code>映射为<code>std::memory_order_acquire</code>。这没毛病，因为两者都是加载或获取操作。<code>std::memory_order_consume</code>比<code>std::memory_order_acquire</code>需要的同步和顺序更弱。因此，释放-获排序可能比释放-消费序慢，但关键是内存序有良好的定义。</p>
<p>将释放-消费序与释放-获取序进行比较，可以对其进行更好的了解。下一小节中，将讨论释放-获取序，以了解<code>std::memory_order_consume</code>和<code>std::memory_order_acquire</code>之间的关系。</p>
<h4 id="释放-获取序"><a class="header" href="#释放-获取序">释放-获取序</a></h4>
<p>首先，让使用下面的程序和两个线程<code>t1</code>和<code>t2</code>。<code>t1</code>扮演生产者的角色，<code>t2</code>扮演消费者的角色。原子变量<code>ptr</code>用于同步生产者和消费者。</p>
<pre><code class="language-c++">// acquireRelease.cpp

#include &lt;atomic&gt;
#include &lt;thread&gt;
#include &lt;iostream&gt;
#include &lt;string&gt;

using namespace std;

atomic&lt;string*&gt; ptr;
int data;
atomic&lt;int&gt; atoData;

void producer(){
  string *p = new string(&quot;C++11&quot;);
  data = 2011;
  atoData.store(2014, memory_order_relaxed);
  ptr.store(p, memory_order_release);
}

void consumer(){
  string *p2;
  while(!(p2 = ptr.load(memory_order_acquire)));
  cout &lt;&lt; &quot;*p2: &quot; &lt;&lt; *p2 &lt;&lt; endl;
  cout &lt;&lt; &quot;data: &quot; &lt;&lt; data &lt;&lt; endl;
  cout &lt;&lt; &quot;atoData: &quot; &lt;&lt; atoData.load(memory_order_relaxed) &lt;&lt; endl;
}

int main(){
  
  cout &lt;&lt; endl;
  
  thread t1(producer);
  thread t2(consumer);
  
  t1.join();
  t2.join();
  
  cout &lt;&lt; endl;
  
}
</code></pre>
<p>分析程序之前，进行一些修改。</p>
<h4 id="释放-消费序"><a class="header" href="#释放-消费序">释放-消费序</a></h4>
<p>将第21行中的内存顺序<code>std::memory_order_acquire</code>替换为<code>std:: memory_order_consumption</code>。</p>
<pre><code class="language-c++">// acquireConsume.cpp

#include &lt;atomic&gt;
#include &lt;thread&gt;
#include &lt;iostream&gt;
#include &lt;string&gt;

using namespace std;

atomic&lt;string*&gt; ptr;
int data;
atomic&lt;int&gt; atoData;

void producer(){
  string *p = new string(&quot;C++11&quot;);
  data = 2011;
  atoData.store(2014, memory_order_relaxed);
  ptr.store(p, memory_order_release);
}

void consumer(){
  string *p2;
  while(!(p2 = ptr.load(memory_order_acquire)));
  cout &lt;&lt; &quot;*p2: &quot; &lt;&lt; *p2 &lt;&lt; endl;
  cout &lt;&lt; &quot;data: &quot; &lt;&lt; data &lt;&lt; endl;
  cout &lt;&lt; &quot;atoData: &quot; &lt;&lt; atoData.load(memory_order_relaxed) &lt;&lt; endl;
}

int main(){
  
  cout &lt;&lt; endl;
  
  thread t1(producer);
  thread t2(consumer);
  
  t1.join();
  t2.join();
  
  cout &lt;&lt; endl;
  
}
</code></pre>
<p>现在程序存在有未定义的行为。不过这种情况只能是一种猜测，因为GCC 5.4编译器使用<code>std::memory_order_acquire</code>实现了<code> std::memory_order_consume</code> ，所以程序改动前和改动后是相同的。</p>
<p>程序输出结果是相同的。</p>
<p><img src="content/The-Details/Memory-Model/../../../images/detail/memory-model/19.png" alt="" /></p>
<h4 id="释放-获取-vs-释放-消费"><a class="header" href="#释放-获取-vs-释放-消费">释放-获取 Vs. 释放-消费</a></h4>
<p>解释一下，为什么第一个程序(acquireRelease.cpp)没有问题(定义良好)。</p>
<p>因为存储操作使用<code>std::memory_order_release</code>，而加载操作使用<code>std::memory_order_acquire</code>，所以第16行上的存储操作与第21行中的加载操作同步。释放-获取序的约束是什么呢？释放-获取序确保在存储操作(第16行)前，所有操作的结果在加载操作(第21行)之后可用。同样，释放-获取操作对非原子变量(第14行)和原子变量<code>atoData</code>(第15行)的访问进行排序。虽然，<code>atoData</code>使用<code>std::memory_order_relax</code>排序，但这也没问题。</p>
<p>关键的问题是：如果用<code>std::memory_order_consumption</code>替换<code>std::memory_order_acquire</code>会发生什么?</p>
<h4 id="stdmemory_order_consume的数据依赖"><a class="header" href="#stdmemory_order_consume的数据依赖">std::memory_order_consume的数据依赖</a></h4>
<p><code>std::memory_order_consume</code>需要处理原子上的数据依赖关系，数据依赖性以两种方式存在。首先，让我们看看线程中的携依赖和两个线程之间的依赖关系。两个依赖都引入了一个先行关系。“携依赖(carries-a-dependency-to)”和“先依赖序(dependency-order-before)”是什么意思？</p>
<ul>
<li>携依赖: 如果操作A的结果在操作B中作为操作数，则：A携依赖于B。</li>
<li>先依赖序：存储操作(使用<code>std::memory_order_release</code>、<code>std::memory_order_acq_rel</code>或<code>std:: memory_seq_cst</code>)是按依赖序进行排序的——如果同一个线程中的后续操作C中加载了操作B的结果，则需要在加载操作B之前使用<code>std::memory_order_consume</code>。需要注意的是，操作B和C必须在同一个线程中。</li>
</ul>
<p>以我的经验，这两个定义不是很好懂，有用图可能会更直观一些。</p>
<p><img src="content/The-Details/Memory-Model/../../../images/detail/memory-model/20.png" alt="" /></p>
<p><code>ptr.store(p, std::memory_order_release)</code>是按先依赖序排列在<code>while (!(p2 = ptr.load(std::memory_order_consume))) </code>之前的，因为下行<code>std::cout &lt;&lt; &quot;*p2: &quot; &lt;&lt; p2 &lt;&lt; std::endl</code>可看作为加载操作的结果输出。此外，<code>while (!(p2 = ptr.load(std::memory_order_consume))</code>携依赖于<code>cout &lt;&lt; &quot;p2: &quot; &lt;&lt; *p2 &lt;&lt; &lt; std::endl</code>，因为<code>*p2</code>使用了<code>ptr</code>的结果进行输出。</p>
<p>我们无法保证<code>data </code>和<code>atoData</code>的输出。这是因为两者与<code>ptr.load</code>操作没有携依赖关系。更糟糕的是：由于数据是非原子变量，因此存在竞争条件。原因是两个线程可以同时访问数据，并且线程<code>t1</code>要对数据进行修改。因此，程序具有未定义行为。</p>
<p>最后，我们来了解自由语义。</p>
<h3 id="自由语义"><a class="header" href="#自由语义">自由语义</a></h3>
<p>自由语义是另一个极端。自由语义是所有内存模型中最弱的，只能保证原子的修改顺序，这意味着对原子的修改了，会以某种特定的顺序发生。</p>
<h4 id="无同步和顺序"><a class="header" href="#无同步和顺序">无同步和顺序</a></h4>
<p>这很容易理解。若没有规则，就无所谓违规。不过，程序应该具有定义良好的行为。这意味着，通常使用更强的内存序的同步和顺序可以控制自由语义的操作。这是怎么做到的呢？一个线程可以以任意顺序看到另一个线程的效果，因此必须确保程序中有一些点，在所有线程上的所有操作都是同步的。</p>
<p>原子操作是一个计数器，其中操作序列无关紧要。计数器遵守的不是不同线程增加计数器的顺序；对计数器的关键观察是，所有增量都是原子性的，所有线程的任务都在最后完成。请看下面的例子：</p>
<pre><code class="language-c++">// relaxed.cpp

#include &lt;vector&gt;
#include &lt;iostream&gt;
#include &lt;thread&gt;
#include &lt;atomic&gt;

std::atomic&lt;int&gt; count = {0};

void add(){
  for (int n = 0; n &lt; 1000; ++n){
    count.fetch_add(1, std::memory_order_relaxed);
  }
}

int main(){
  std::vector&lt;std::thread&gt; v;
  
  for (int n = 0; n &lt; 10; ++n){
    v.emplace_back(add);
  }
  for (auto&amp; t : v){
    t.join();
  }
  std::cout &lt;&lt; &quot;Final Counter value is &quot; &lt;&lt; count &lt;&lt; '\n';
}
</code></pre>
<p>最重要的三行分别是13、24和26行。</p>
<p>第13行，原子数计数使用自由语义进行递增，因此可以保证操作是原子的。<code>fetch_add</code>操作建立计数排序，<code>add</code>函数(第10-15行)是线程的任务包。在第21行，为每个线程分配任务包。</p>
<p>线程创建是一个同步点，另一个同步点是第24行的<code>t.join()</code>。</p>
<p>主线程在第24行与所有子线程同步，使用<code>t.join()</code>进行等待，直到它的所有子节点都完成。</p>
<p>总之，第13行中的增量操作与第26行中计数器的读取之间存在先行关系。</p>
<p>结果是程序总是返回10000。有些无聊吗？不，这才是令人放心的！</p>
<p><img src="content/The-Details/Memory-Model/../../../images/detail/memory-model/21.png" alt="" /></p>
<p>使用自由语义的原子计数器的另一个典型示例是<code>std::shared_ptr</code>的引用计数器。这只适用于增量操作，增加引用计数器的关键属性是操作是原子的。并且，增量操作的顺序并不重要，但这不适用于引用计数器的递减。这些操作需要遵循获取-释放语义的析构函数。</p>
<blockquote>
<p><strong>无等待的累加计算</strong></p>
<p>仔细看下第10行中的add函数。增量操作中不涉及同步(第13行)，值1被添加到原子变量<code>count</code>中。</p>
<p>因此，该算法不仅是无锁的，而且是无等待的。</p>
</blockquote>
<p><code>std::atomic_thread_fence</code>的基本思想是，没有原子操作的情况下，在线程之间建立同步和顺序。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="栅栏"><a class="header" href="#栅栏">栅栏</a></h1>
<p>C++支持两种栅栏类型：<code>std::atomic_thread_fence</code>和<code>std::atomic_signal_fence</code>。</p>
<ul>
<li><code>std::atomic_thread_fence</code> : 同步线程间的内存访问。</li>
<li><code>std::atomic_signal_fence</code> : 线程内信号之间的同步。</li>
</ul>
<p><strong><code>std::atomic_thread_fence</code></strong></p>
<p><code>std::atomic_thread_fence</code>可以阻止特定的操作翻过栅栏。</p>
<p><code>std::atomic_thread_fence</code>不需要原子变量，通常称为栅栏或内存屏障。那就先来了解一下<code>std::atomic_thread_fence</code>。</p>
<h2 id="栅栏当做内存屏障"><a class="header" href="#栅栏当做内存屏障">栅栏当做内存屏障</a></h2>
<p>这个小节的标题什么意思呢？特定的操作不能翻过内存屏障。那什么样的操作属于“特殊操作”呢？现在有两种操作：读写操作或加载/存储操作。<code>if(resultRead) return result</code>就是一个加载操作后跟一个存储操作。</p>
<p>有四种不同的方式来组合加载和存储操作：</p>
<ul>
<li>加载-加载：一个加载操作后跟一个加载操作。</li>
<li>加载-存储：一个加载操作后跟一个存储操作。</li>
<li>存储-加载：一个存储操作后跟一个加载操作。</li>
<li>存储-存储：一个存储操作后跟一个存储操作。</li>
</ul>
<p>当然，还有由多个加载和存储(<code>count++</code>)组成的更复杂的操作，这些操作都可由以上四个操作组成。</p>
<p>那么内存屏障是什么呢？如果在加载-加载、加载-存储、存储-加载或存储-存储等操作之间设置内存屏障，则可以保证不会对特定的操作进行重新排序。如果使用非原子或具有自由语义的原子操作，则存在重新排序的风险。</p>
<h2 id="三种栅栏类型"><a class="header" href="#三种栅栏类型">三种栅栏类型</a></h2>
<p>通常，栅栏有三种：全栅(full fence)、获取栅栏(acquire fence)和释放栅栏(release fence)。提醒一下，获取是一个加载操作， 释放是一个存储操作。如果在加载和存储操作的四种组合之间，放一个内存屏障中会发生什么情况呢?</p>
<ul>
<li>全栅: 任意两个操作之间使用完整的栅栏<code>std::atomic_thread_fence()</code>，可以避免这些操作的重新排序。不过，对于存储-加载操作来说，它们可能会被重新排序。</li>
<li>获取栅栏: <code>std::atomic_thread_fence(std::memory_order_acquire)</code>避免在获取栅栏之前的读操作，被获取栅栏之后的读或写操作重新排序。</li>
<li>释放栅栏: <code>std::atomic_thread_fence(std::memory_order_release)</code>避免释放栅栏之后的写操作，在释放栅栏之前通过读或写操作重新排序。</li>
</ul>
<p>为了获得和释放栅栏的定义，以及对无锁编程的影响，我们花费了大量精力对其进行整理。特别难以理解的是，这种栅栏与原子操作获取-释放语义之间的差别。先用图来说明一些上面的定义。</p>
<p>哪种操作可以翻过内存屏障？先瞧瞧下面的三张图。如果箭头与红色横杠交叉，意味着栅栏会阻止这种操作。</p>
<p><strong>全栅</strong></p>
<p><img src="content/The-Details/Memory-Model/../../../images/detail/memory-model/22.png" alt="" /></p>
<p>当然，可以显式地调用<code>std::atomic_thread_fence(std::memory_order_seq_cst)</code>，而不是<code>std::atomic_thread_fence()</code>。默认情况下，栅栏使用内存序为顺序一致性。如果对全栏使用顺序一致性，那么<code>std::atomic_thread_fence</code>也将遵循全局序。</p>
<p><strong>获取栅栏</strong></p>
<p><img src="content/The-Details/Memory-Model/../../../images/detail/memory-model/23.png" alt="" /></p>
<p><strong>释放栅栏</strong></p>
<p><img src="content/The-Details/Memory-Model/../../../images/detail/memory-model/24.png" alt="" /></p>
<p>三种内存屏障可以描述得更简单。</p>
<p><strong>所有栅栏一览图</strong></p>
<p><img src="content/The-Details/Memory-Model/../../../images/detail/memory-model/25.png" alt="" /></p>
<p>获取-释放栅栏与原子获取-释放语义有着相似的同步方式和顺序。</p>
<h2 id="获取-释放栅栏"><a class="header" href="#获取-释放栅栏">获取-释放栅栏</a></h2>
<p>获取-释放栅栏与原子类的获取-释放语义最明显的区别是，栅栏不需要原子操作。还有一个更微妙的区别：获取-释放栅栏比原子操作更重量级。</p>
<h3 id="原子操作-vs-栅栏"><a class="header" href="#原子操作-vs-栅栏">原子操作 vs. 栅栏</a></h3>
<p>简单起见，现在使用栅栏或带有获取语义的原子操作时引用获取操作，释放操作也是如此。</p>
<p>获取-释放操作的主要思想是，在线程间建立同步和排序约束，这些同步和顺序约束也适用于使用自由语义的原子操作或非原子操作。注意，获取-释放操作是成对出现的。此外，对获取-释放语义的原子变量的操作，必须作用在相同的原子变量上。不过，我现在是将这些操作分开来看待的。</p>
<p>让我们从获取操作开始对比。</p>
<h3 id="获取操作"><a class="header" href="#获取操作">获取操作</a></h3>
<p>在原子变量(内存序为<code>std::memory_order_acquire</code>)上进行的加载 (读取)操作是一个获取操作。</p>
<p><img src="content/The-Details/Memory-Model/../../../images/detail/memory-model/26.png" alt="" /></p>
<p>将<code>std::atomic_thread_fence</code>内存序设置为<code>std::memory_order_acquire</code>，这对内存访问重排添加了更严格的约束:</p>
<p><img src="content/The-Details/Memory-Model/../../../images/detail/memory-model/27.png" alt="" /></p>
<p>比较中可以总结了两点:</p>
<ol>
<li>具有获取语义的栅栏会建立更强的顺序约束。虽然，原子变量和栅栏的获取操作，要求在获取操作之前不能进行任何读或写操作。但是对获取栅栏有另一种方式，获取栅栏后不能进行读操作。</li>
<li>自由语义足以读取原子变量<code>var</code>。由于<code>std::atomc_thread_fence(std::memory_order_acquire)</code>，所以这个操作在获取栅栏之后不能进行读取。</li>
</ol>
<p>对于释放栅栏也可以进行类似的试验。</p>
<h3 id="释放操作"><a class="header" href="#释放操作">释放操作</a></h3>
<p>对内存序为<code>std::memory_order_release</code>的原子变量，进行存储(写)操作时，这些操作属于释放操作。</p>
<p><img src="content/The-Details/Memory-Model/../../../images/detail/memory-model/28.png" alt="" /></p>
<p>还有，释放栅栏。</p>
<p><img src="content/The-Details/Memory-Model/../../../images/detail/memory-model/29.png" alt="" /></p>
<p>除了释放操作对原子变量<code>var</code>的约束外，释放栅栏有两个属性:</p>
<ol>
<li>存储的操作不能在栅栏前进行。</li>
<li>变量<code>var</code>使用自由语义。</li>
</ol>
<p>现在，就使用栅栏写一段程序。</p>
<h2 id="使用原子变量或栅栏进行同步"><a class="header" href="#使用原子变量或栅栏进行同步">使用原子变量或栅栏进行同步</a></h2>
<p>之前，我们已经用获取-释放语义，实现了一个典型的消费者-生产者工作流。先使用原子的是原子操作，再切换到栅栏。</p>
<h3 id="原子操作-1"><a class="header" href="#原子操作-1">原子操作</a></h3>
<p>我们从原子操作开始，大家对它们应该都很熟悉。</p>
<pre><code class="language-c++">// acquireRelease.cpp

#include &lt;atomic&gt;
#include &lt;thread&gt;
#include &lt;iostream&gt;
#include &lt;string&gt;

using namespace std;

atomic&lt;string*&gt; ptr;
int data;
atomic&lt;int&gt; atoData;

void producer(){
  string *p = new string(&quot;C++11&quot;);
  data = 2011;
  atoData.store(2014, memory_order_relaxed);
  ptr.store(p, memory_order_release);
}

void consumer(){
  string* p2;
  while(!(p2 = ptr.load(memory_order_acquire)));
  cout &lt;&lt; &quot;*p2: &quot; &lt;&lt; *p2 &lt;&lt; endl;
  cout &lt;&lt; &quot;data: &quot; &lt;&lt; data &lt;&lt; endl;
  cout &lt;&lt; &quot;atoData: &quot; &lt;&lt; atoData.load(memory_order_relaxed) &lt;&lt; endl;
}

int main(){
  
  cout &lt;&lt; endl;
  
  thread t1(producer);
  thread t2(consumer);
  
  t1.join();
  t2.join();
  
  cout &lt;&lt; endl;
  
}
</code></pre>
<p>这个程序应该很熟悉，这是我们在<code>std:: memory_order_consumption</code>小节中使用的示例。下图强调了消费者线程t2看到来自生产者线程t1的所有值。</p>
<p><img src="content/The-Details/Memory-Model/../../../images/detail/memory-model/30.png" alt="" /></p>
<p>这段程序定义良好，因为先行关系是可传递的。只需要把三种发生前关系结合起来:</p>
<ol>
<li>第15-17行先行于第18行<code>ptr.store(p, std:: memory_order_release)</code>。</li>
<li>第23行<code>while(!(p2= ptrl.load(std::memory_order_acquire)))</code> 先行于第24-26行。</li>
<li>第18行与第23行同步⇒第18行线程内先行于第23行。</li>
</ol>
<p>现在，事情变得更有趣了，我们要来聊聊栅栏了。有关C++内存模型的文献中，栅栏几乎完全被忽略了。</p>
<h3 id="栅栏-1"><a class="header" href="#栅栏-1">栅栏</a></h3>
<p>将程序改成到使用栅栏。</p>
<pre><code class="language-c++">// acquireReleaseFences.cpp

#include &lt;atomic&gt;
#include &lt;thread&gt;
#include &lt;iostream&gt;
#include &lt;string&gt;

using namespace std;

atomic&lt;string*&gt; ptr;
int data;
atomic&lt;int&gt; atoData;

void producer() {
  string* p = new string(&quot;C++11&quot;);
  data_ = 2011;
  atoData.store(2014, memory_order_relaxed);
  atomic_thread_fence(memory_order_release);
  ptr.store(p, memory_order_release);
}

void consumer() {
  string* p2;
  while (!(p2 = ptr.load(memory_order_relaxed)));
  atomic_thread_fence(memory_order_acquire);
  cout &lt;&lt; &quot;*p2: &quot; &lt;&lt; *p2 &lt;&lt; endl;
  cout &lt;&lt; &quot;data: &quot; &lt;&lt; data_ &lt;&lt; endl;
  cout &lt;&lt; &quot;atoData: &quot; &lt;&lt; atoData.load(memory_order_relaxed) &lt;&lt; endl;
}

int main() {

  cout &lt;&lt; endl;

  thread t1(producer);
  thread t2(consumer);

  t1.join();
  t2.join();
  
  delete ptr;

  cout &lt;&lt; endl;

}
</code></pre>
<p>第一步是添加栅栏(使用释放和获取语义，第18行和第25行)。接下来，将原子操作从获取或释放语义很容易的改为自由语义(第19和24行)。当然，只能用相应的栅栏替换获取或释放操作。释放栅栏建立了与获取栅栏的同步，因此线程间的也有了先行关系。</p>
<p>下图是程序的输出：</p>
<p><img src="content/The-Details/Memory-Model/../../../images/detail/memory-model/31.png" alt="" /></p>
<p>为了更直观的呈现给读者，下图是描述了整个关系。</p>
<p><img src="content/The-Details/Memory-Model/../../../images/detail/memory-model/32.png" alt="" /></p>
<p>关键问题是：为什么获取栅栏之后的操作，会看到释放栅栏之前的操作呢？因为数据是一个非原子变量<code>atoData.store</code>，并且以自由语义使用，这意味着它们可以重新排序；不过，因为<code>std::atomic_thread_fence(std::memory_order_release)</code>与<code>std::atomic_thread_fence(std::memory_order_acquire)</code>相结合，所以两个操作都不能重新排序。</p>
<p>用更简洁的形式进行解释：</p>
<ol>
<li>获取-释放栅栏阻止了原子和非原子操作跨栅栏的重排序。</li>
<li>消费者线程<code>t2</code>正在等待<code>while (!(p2= ptr.load(std::memory_order_relaxed)))</code>循环跳出，直到在生产者线程<code>t1</code>中设置对指针进行设置<code>ptr.store(p,std::memory_order_relaxed) </code>。</li>
<li>释放栅栏与获取栅栏同步。</li>
<li>自由操作或非原子操作的所有结果(在释放栅栏之前)，在获得栅栏之后都是可见的。</li>
</ol>
<blockquote>
<p><strong>释放栅栏和获取栅栏之间的同步</strong></p>
<p>这两个定义来自于<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/n4659.pdf">N4659: Working Draft, Standard for Programming Language C++</a> ，并且标准文档的文字比较难懂：“如果操作X和操作Y对原子对象M的操作存在有原子操作，释放栅栏A同步于获取栅栏B；那么A的操作顺序位于X之前，X对M进行修改，Y位于B之前，并且Y读取X写入的值，或在进行释放操作时，释放序列X中的任何操作所写的值将被读取。”</p>
<p>让我借由acquireReleaseFence.cpp解释一下这段话：</p>
<ul>
<li><code>atomic_thread_fence(memory_order_release)</code> (第18行)是一个释放栅栏A。</li>
<li><code>atomic_thread_fence(memory_order_acquire)</code> (第25行)是一个获取栅栏B。</li>
<li><code>ptr</code>(第10行)是一个原子对象M。</li>
<li><code>ptr.store(p, memory_order_relaxed)</code> (第19行) 是一个原子存储操作X。</li>
<li><code>while (!(p2 = ptr.load(memory_order_relaxed)))</code> (第24行)是一个原子加载操作Y。</li>
</ul>
</blockquote>
<p>可以在acquireRelease.cpp程序中的原子变量上，混合获取和释放操作(使用获取和释放栅栏)，而不影响同步关系。</p>
<h4 id="stdatomic_signal_fence"><a class="header" href="#stdatomic_signal_fence">std::atomic_signal_fence</a></h4>
<p><code>std::atomic_signal_fence</code>在线程和信号句柄间，建立了非原子和自由原子访问的内存同步序。下面的程序展示了<code>std::atomic_signal_fence</code>的用法。</p>
<pre><code class="language-c++">// atomicSignal.cpp

#include &lt;atomic&gt;
#include &lt;cassert&gt;
#include &lt;csignal&gt;

std::atomic&lt;bool&gt; a{false};
std::atomic&lt;bool&gt; b{false};

extern &quot;C&quot; void handler(int){
  if (a.load(std::memory_order_relaxed)){
    std::atomic_signal_fence(std::memory_order_acquire);
    assert(b.load(std::memory_order_relaxed));
  }
}

int main(){
  
  std::signal(SIGTERM, handler);
  
  b.store(true, std::memory_order_relaxed);
  std::atomic_signal_fence(std::memory_order_release);
  a.store(true, std::memory_order_relaxed);
  
}
</code></pre>
<p>首先，第19行中为特定的信号SIGTERM设置了处理句柄。SIGTERM是程序的终止请求。<code> std::atomic_signal_handler</code>在释放操作<code>std:: signal_fence(std::memory_order_release)</code>(第22行)和获取操作<code>std:: signal_fence(std::memory_order_acquire)</code>(第12行)之间建立一个获取-释放栅栏。释放操作不能跨越释放栅栏进行重排序(第22行)，而获取操作不能跨越获取栅栏进行重排序(第11行)。因此，第13行<code>assert(b.load(std::memory_order_relax)</code>的断言永远不会触发，因为<code>a.store(true, std:: memory_order_relaxed)</code>(第23行)执行了的话, <code>b.store(true, std::memory_order_relax)</code>(第21行)就一定执行过。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="多线程-1"><a class="header" href="#多线程-1">多线程</a></h1>
<p>C++11添加了多线程接口，为创建多线程程序提供了基础件。多线程的基础件有：线程、共享数据(如互斥锁和锁)的同步原语、线程本地数据、线程(如条件变量)的同步机制和任务。任务(通常称为promise和future)会提供了比线程更高级的抽象。</p>
<p><img src="content/The-Details/Multithreading/../../../images/detail/multithreading/1.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><p>#线程</p>
<p>要用C++标准库启动一个线程，就必须包含<code>&lt;thread&gt;</code>头文件。</p>
<h2 id="创建线程"><a class="header" href="#创建线程">创建线程</a></h2>
<p>线程<code>std::thread</code>对象表示一个可执行单元。当工作包是可调用单元时，工作包可以立即启动。线程对象是不可复制构造或复制赋值的，但可移动构造或移动赋值。</p>
<p>可调用单元是行为类似于函数。当然，它可以是一个函数，也可以是一个函数对象，或者一个Lambda表达式。通常忽略可调用单元的返回值。</p>
<p>介绍完理论知识之后，我们来动手写个小例子。</p>
<pre><code class="language-c++">// createThread.cpp

#include &lt;iostream&gt;
#include &lt;thread&gt;

void helloFunction() {
  std::cout &lt;&lt; &quot;Hello from a function.&quot; &lt;&lt; std::endl;
}

class HelloFUncitonObject {
public:
  void operator()()const {
    std::cout &lt;&lt; &quot;Hello from a function object.&quot; &lt;&lt; std::endl;
  }
};

int main() {
  
  std::cout &lt;&lt; std::endl;

  std::thread t1(helloFunction);
  HelloFUncitonObject helloFunctionObject;
  std::thread t2(helloFunctionObject);

  std::thread t3([] {std::cout &lt;&lt; &quot;Hello from a lambda.&quot; &lt;&lt; std::endl; });

  t1.join();
  t2.join();
  t3.join();

  std::cout &lt;&lt; std::endl;

}
</code></pre>
<p>三个线程(<code>t1</code>、<code>t2</code>和<code>t3</code>)都会将信息写入控制台。线程<code>t2</code>的工作包是一个函数对象(第10 - 15行)，线程<code>t3</code>的工作包是一个Lambda函数(第26行)。第28 - 30行，主线程在等待子线程完成工作。</p>
<p>看一下输出。</p>
<p><img src="content/The-Details/Multithreading/../../../images/detail/multithreading/2.png" alt="" /></p>
<p>三个线程以任意顺序执行，这三个输出操作也可以交错。</p>
<p>线程的创建者(例子中是主线程)负责管理线程的生命周期，所以让我们来了解一下线程的生命周期。</p>
<p>##线程的生命周期</p>
<p>父母需要照顾自己的孩子，这个简单的原则对线程的生命周期非常重要。下面的程序(子线程最后没有汇入)，用来显示线程ID。</p>
<pre><code class="language-c++">#include &lt;iostream&gt;
#include &lt;thread&gt;

int main() {
  
  std::thread t([] {std::cout &lt;&lt; std::this_thread::get_id() &lt;&lt; std::endl; });
  
}
</code></pre>
<p>程序出现了错误，不过依旧打印了线程的ID。</p>
<p><img src="content/The-Details/Multithreading/../../../images/detail/multithreading/3.png" alt="" /></p>
<p>那是什么原因引起的异常呢？</p>
<p><strong>汇入和分离</strong></p>
<p>线程<code>t</code>的生命周期终止于可调用单元执行结束，而创建者有两个选择：</p>
<ol>
<li>等待线程完成: <code>t.join()</code></li>
<li>与创建线程解除关系:<code>t.detach() </code></li>
</ol>
<p>当后续代码依赖于线程中调用单元的计算结果时，需要使用<code>t.join()</code>。<code>t.detach()</code>允许线程与创建线程分离执行，所以分离线程的生命周期与可执行文件的运行周期相关。通常，服务器上长时间运行的后台服务，会使用分离线程。</p>
<p>如果<code>t.join()</code>和<code>t.detach()</code>都没有执行，那么线程<code>t</code>是可汇入的。可汇入线程的析构函数会抛出<code>std::terminate</code>异常，这也就是threadWithoutJoin.cpp程序产生异常的原因。如果在线程上多次调用<code>t.join()</code>或<code>t.detach()</code>，则会产生<code>std::system_error</code>异常。</p>
<p>解决问题的方法很简单：使用<code>t.join()</code>。</p>
<pre><code class="language-c++">#include &lt;iostream&gt;
#include &lt;thread&gt;

int main() {
  
  std::thread t([] {std::cout &lt;&lt; std::this_thread::get_id() &lt;&lt; std::endl; });
  
  t.join();
  
}
</code></pre>
<p>现在就能得到满意的输出了。</p>
<p><img src="content/The-Details/Multithreading/../../../images/detail/multithreading/4.png" alt="" /></p>
<p>线程ID是<code>std::thread</code>唯一的标识符。</p>
<blockquote>
<p><strong>分离线程的挑战</strong></p>
<p>当然，可以在最后一个程序中使用<code>t.detach()</code>代替<code>t.join()</code>。这样，线程<code>t</code>不能汇入了；因此，它的析构函数没有调用<code>std::terminate</code>函数。但现在有另一个问题：未定义行为。主程序可能在线程<code>t</code>前结束，所以由于主线程的生存期太短，无法显示ID。详细信息，可以参考变量的生存期。</p>
</blockquote>
<blockquote>
<p><strong>Anthony Williams提出的scoped_thread</strong></p>
<p>如果手动处理线程的生命周期可能有些麻烦，可以在包装器中封装<code>std::thread</code>。如果线程仍然是可汇入的，这个类应该在其析构函数中自动调用<code>t.join()</code>，也可以反过来调用<code>t.detach()</code>，但分离处理也有问题。</p>
<p>Anthony Williams提出了这样一个类，并在他的优秀著作<a href="https://www.manning.com/books/c-plus-plus-concurrency-in-action">《C++ Concurrency in Action》</a>中介绍了它。他将包装器称为<code>scoped_thread</code>。<code>scoped_thread</code>在构造函数中获取了线程对象，并检查线程对象是否可汇入。如果传递给构造函数的线程对象不可汇入，则不需要<code>scoped_thread</code>。如果线程对象可汇入，则析构函数调用<code>t.join()</code>。因为，复制构造函数和复制赋值操作符被声明为<code>delete</code>，所以<code>scoped_thread</code>的实例不能复制或赋值。</p>
<pre><code class="language-c++">// scoped_thread.cpp

#include &lt;thread&gt;
#include &lt;utility&gt;

class scoped_thread{
std::thread t;
public:
  explicit scoped_thread(std::thread t_): t(std::move(t_)){
  	if (!t.joinable()) throw std::logic_error(&quot;No thread&quot;);
  }
  ~scoped_thread(){
  	t.join();
  }
  scoped_thread(scoped_thread&amp;)= delete;
  scoped_thread&amp; operator=(scoped_thread const &amp;)= delete;
};
</code></pre>
</blockquote>
<h2 id="线程参数"><a class="header" href="#线程参数">线程参数</a></h2>
<p>和函数一样，线程可以通过复制、移动或引用来获取参数。<code>std::thread</code>是一个<a href="http://en.cppreference.com/w/cpp/language/parameter_pack">可变参数模板</a>，可以传入任意数量的参数。</p>
<p>线程通过引用的方式获取数据的情况，必须非常小心参数的生命周期和数据的共享方式。</p>
<h3 id="复制或引用"><a class="header" href="#复制或引用">复制或引用</a></h3>
<p>我们来看一个代码段。</p>
<pre><code class="language-c++">std::string s{&quot;C++11&quot;}

std::thread t1([=]{ std::cout &lt;&lt; s &lt;&lt; std::endl; });
t1.join();

std::thread t2([&amp;]{ std::cout &lt;&lt; s &lt;&lt; std::endl; });
t2.detach();
</code></pre>
<p>线程<code>t1</code>通过复制的方式获取参数，线程<code>t2</code>通过引用的方式获取参数。</p>
<blockquote>
<p><strong>线程的“引用”参数</strong></p>
<p>实际上，我骗了你。线程<code>t2</code>不是通过引用获取其参数，而是Lambda表达式通过引用捕获的参数。如果需要引用将参数传递给线程，则必须将其包装在<a href="http://en.cppreference.com/w/cpp/utility/functional/reference_wrapper">引用包装器</a>中，使用<a href="http://en.cppreference.com/w/cpp/utility/functional/ref">std::ref</a>就能完成这项任务。<code>std::ref</code>在<code>&lt;functional&gt;</code>头文件中定义。</p>
<pre><code class="language-c++">&lt;functional&gt;
...
void transferMoney(int amount, Account&amp; from, Account&amp; to){
...
}
...
std::thread thr1(transferMoney, 50, std::ref(account1), std::ref(account2));
</code></pre>
<p>线程<code>thr1</code>执行<code>transferMoney</code>函数。<code>transferMoney</code>的参数是使用引用的方式传递，所以线程<code>thr1</code>通过引用获取<code>account1</code>和<code>account2</code>。</p>
</blockquote>
<p>这几行代码中隐藏着什么问题呢？线程<code>t2</code>通过引用获取其字符串<code>s</code>，然后从其创建者的生命周期中分离。字符串<code>s</code>与创建者的生存期周期绑定，全局对象<code>std::cout</code>与主线程的生存周期绑定。因此，<code>std::cout</code>的生存周期可能比线程<code>t2</code>的生存周期短。现在，我们已经置身于未定义行为中了。</p>
<p>不相信？来看看未定义行为是什么样的。</p>
<pre><code class="language-c++">// threadArguments.cpp

#include &lt;chrono&gt;
#include &lt;iostream&gt;
#include &lt;thread&gt;

class Sleeper {
public:
  Sleeper(int&amp; i_) :i{ i_ } {};
  void operator()(int k) {
    for (unsigned int j = 0; j &lt;= 5; ++j) {
      std::this_thread::sleep_for(std::chrono::microseconds(100));
      i += k;
    }
    std::cout &lt;&lt; std::this_thread::get_id() &lt;&lt; std::endl;
  }
private:
  int&amp; i;
};


int main() {

  std::cout &lt;&lt; std::endl;

  int valSleepr = 1000;
  std::thread t(Sleeper(valSleepr), 5);
  t.detach();
  std::cout &lt;&lt; &quot;valSleeper = &quot; &lt;&lt; valSleepr &lt;&lt; std::endl;

  std::cout &lt;&lt; std::endl;

}
</code></pre>
<p>问题在于：<code>valSleeper</code>在第29行时值是多少？<code>valSleeper</code>是一个全局变量。线程<code>t</code>获得一个函数对象，该函数对象的实参为变量<code>valSleeper</code>和数字5(第27行)，而线程通过引用获得<code>valSleeper</code>(第9行)，并与主线程(第28行)分离。接下来，执行函数对象的调用操作符(第10 - 16行)，它从0计数到5，在每100毫秒的中休眠，将<code>k</code>加到<code>i</code>上。最后，屏幕上显示它的id。<a href="https://de.wikipedia.org/wiki/Liste_gefl%C3%BCgelter_Worte/N#Nach_Adam_Riese">Nach Adam Riese</a> (德国成语：真是精准的计算呀！)，期望的结果应该是1000 + 6 * 5 = 1030。</p>
<p>然而，发生了什么？结果为什么完全不对？</p>
<p><img src="content/The-Details/Multithreading/../../../images/detail/multithreading/5.png" alt="" /></p>
<p>这个输出有两个奇怪的地方：首先，<code>valSleeper</code>是1000；其次，ID没有显示。</p>
<p>这段程序至少有两个错误：</p>
<ol>
<li><code>valSleeper</code>是线程共享的。这会导致数据竞争，因为线程可能同时读写<code>valSleeper</code>。</li>
<li>主线程的生命周期很可能在子线程执行计算，或将其ID写入<code>std::cout</code>之前结束。</li>
</ol>
<p>这两个问题都是构成竞态条件，因为程序的结果取决于操作的交错。构成竞态的条件也是导致数据竞争的原因。</p>
<p>解决数据竞争也非常容易：使用锁或原子保护<code>valSleeper</code>。为了解决<code>valSleeper</code>和<code>std::cout</code>的生命周期问题，必须汇入线程而不是分离它。</p>
<p>修改后的主函数体。</p>
<pre><code class="language-c++">int main(){
  
  std::cout &lt;&lt; std::endl;
  
  int valSleeper= 1000;
  std::thread t(Sleeper(valSleeper),5);
  t.join();
  std::cout &lt;&lt; &quot;valSleeper = &quot; &lt;&lt; valSleeper &lt;&lt; std::endl;
  
  std::cout &lt;&lt; std::endl;
  
}
</code></pre>
<p>现在，我们得到了正确的结果。当然，执行速度会变慢。</p>
<p><img src="content/The-Details/Multithreading/../../../images/detail/multithreading/6.png" alt="" /></p>
<p>为了更完整的了解<code>std::thread</code>，接下来了解其成员函数。</p>
<p>###成员函数</p>
<p>下面是<code>std::thread</code>的接口，在一个简洁的表中。更多详情请访问<a href="http://de.cppreference.com/w/cpp/thread/thread">cppreference.com</a>。</p>
<table><thead><tr><th align="center">函数名称</th><th align="center">描述</th></tr></thead><tbody>
<tr><td align="center"><code>t.join()</code></td><td align="center">等待，直到线程t完成</td></tr>
<tr><td align="center"><code>t.detach()</code></td><td align="center">独立于创建者执行创建的线程t</td></tr>
<tr><td align="center"><code>t.joinable()</code></td><td align="center">如果线程t可以汇入，则返回true</td></tr>
<tr><td align="center"><code>t.get_id()</code>和<code>std::this_thread::get_id()</code></td><td align="center">返回线程的ID</td></tr>
<tr><td align="center"><code>std::thread::hardware_concurrency()</code></td><td align="center">返回可以并发运行的线程数</td></tr>
<tr><td align="center"><code>std::this_thread::sleep_until(absTime)</code></td><td align="center">将线程t置为睡眠状态，直到absTime时间点为止</td></tr>
<tr><td align="center"><code>std::this_thread::sleep_for(relTime)</code></td><td align="center">将线程t置为睡眠状态，直到休眠了relTime为止</td></tr>
<tr><td align="center"><code>std::this_thread::yield()</code></td><td align="center">允许系统运行另一个线程</td></tr>
<tr><td align="center"><code>t.swap(t2)</code>和<code>std::swap(t1, t2)</code></td><td align="center">交换线程对象</td></tr>
</tbody></table>
<p>静态函数<code>std::thread::hardware_concurrency</code>返回实现支持的并发线程数量，如果运行时无法确定数量，则返回0(这是根据C++标准编写的)。<code>sleep_until</code>和<code>sleep_for</code>操作需要一个时间点或持续时间作为参数。</p>
<blockquote>
<p><strong>访问特定系统的实现</strong></p>
<p>线程接口是底层实现的包装器，可以使用<code>native_handle</code>来访问(特定于系统的实现)。这个底层实现的句柄可用于线程、互斥对象和条件变量。</p>
</blockquote>
<p>作为对本小节的总结，下面是在实践中提到的一些方法。</p>
<pre><code class="language-c++">// threadMethods.cpp

#include &lt;iostream&gt;
#include &lt;thread&gt;

using namespace std;

int main() {

  cout &lt;&lt; boolalpha &lt;&lt; endl;

  cout &lt;&lt; &quot;hardware_concurrency() = &quot; &lt;&lt; thread::hardware_concurrency() &lt;&lt; endl;

  thread t1([] {cout &lt;&lt; &quot;t1 with id = &quot; &lt;&lt; this_thread::get_id() &lt;&lt; endl; });
  thread t2([] {cout &lt;&lt; &quot;t2 with id = &quot; &lt;&lt; this_thread::get_id() &lt;&lt; endl; });

  cout &lt;&lt; endl;

  cout &lt;&lt; &quot;FROM MAIN: id of t1 &quot; &lt;&lt; t1.get_id() &lt;&lt; endl;
  cout &lt;&lt; &quot;FROM MAIN: id of t2 &quot; &lt;&lt; t2.get_id() &lt;&lt; endl;

  cout &lt;&lt; endl;
  swap(t1, t2);

  cout &lt;&lt; &quot;FROM MAIN: id of t1 &quot; &lt;&lt; t1.get_id() &lt;&lt; endl;
  cout &lt;&lt; &quot;FROM MAIN: id of t2 &quot; &lt;&lt; t2.get_id() &lt;&lt; endl;

  cout &lt;&lt; endl;

  cout &lt;&lt; &quot;FROM MAIN: id of main= &quot; &lt;&lt; this_thread::get_id() &lt;&lt; endl;

  cout &lt;&lt; endl;

  cout &lt;&lt; &quot;t1.joinable(): &quot; &lt;&lt; t1.joinable() &lt;&lt; endl;

  cout &lt;&lt; endl;

  t1.join();
  t2.join();

  cout &lt;&lt; endl;

  cout &lt;&lt; &quot;t1.joinable(): &quot; &lt;&lt; t1.joinable() &lt;&lt; endl;

  cout &lt;&lt; endl;

}
</code></pre>
<p>与输出相结合来看，应该很容易理解。</p>
<p><img src="content/The-Details/Multithreading/../../../images/detail/multithreading/7.png" alt="" /></p>
<p>结果可能看起来有点奇怪，线程<code>t1</code>和<code>t2</code>(第14行和第15行)在不同时间点上运行。无法确定每个线程何时运行，只能确定在第38和39行<code>t1.join()</code>和<code>t2.join()</code>语句之前两个线程是肯定运行了的。</p>
<p>线程共享的可变(非const)变量越多，程序的风险就越大。</p>
<div style="break-before: page; page-break-before: always;"></div><p>#共享数据</p>
<p>为了更清楚地说明这一点，就需要考虑共享数据的同步问题，因为数据竞争很容易在共享数据上发生。如果并发地对数据进行非同步读写访问，则会产生未定义行为。</p>
<p>验证并发、未同步的读写操作的最简单方法，就是向<code>std::cout</code>写入一些内容。</p>
<p>让我们来看一下，使用不同步的方式进行<code>std::cout</code>打印输出。</p>
<pre><code class="language-c++">// coutUnsynchronised.cpp

#include &lt;chrono&gt;
#include &lt;iostream&gt;
#include &lt;thread&gt;

class Worker {
public:
  Worker(std::string n) :name(n) {}
  void operator()() {
    for (int i = 1; i &lt;= 3; ++i) {
      // begin work
      std::this_thread::sleep_for(std::chrono::microseconds(200));
      // end work
      std::cout &lt;&lt; name &lt;&lt; &quot;: &quot; &lt;&lt; &quot;Work &quot; &lt;&lt; i &lt;&lt; &quot; done !!!&quot; &lt;&lt; std::endl;
    }
  }
private:
  std::string name;
};


int main() {
  
  std::cout &lt;&lt; std::endl;

  std::cout &lt;&lt; &quot;Boss: Let's start working.\n\n&quot;;

  std::thread herb = std::thread(Worker(&quot;Herb&quot;));
  std::thread andrei = std::thread(Worker(&quot; Andrei&quot;));
  std::thread scott = std::thread(Worker(&quot;  Scott&quot;));
  std::thread bjarne = std::thread(Worker(&quot;   Bjarne&quot;));
  std::thread bart = std::thread(Worker(&quot;    Bart&quot;));
  std::thread jenne = std::thread(Worker(&quot;     Jenne&quot;));


  herb.join();
  andrei.join();
  scott.join();
  bjarne.join();
  bart.join();
  jenne.join();

  std::cout &lt;&lt; &quot;\n&quot; &lt;&lt; &quot;Boss: Let's go home.&quot; &lt;&lt; std::endl;

  std::cout &lt;&lt; std::endl;

}
</code></pre>
<p>该程序描述了一个工作流程：老板有六个员工(第29 - 34行)，每个员工必须处理3个工作包，处理每个工作包需要200毫秒(第13行)。当员工完成了他的所有工作包时，他向老板报告(第15行)。当老板收到所有员工的报告，老板就会把员工们送回家(第43行)。</p>
<p>这么简单的工作流程，输出却如此混乱。</p>
<p><img src="content/The-Details/Multithreading/../../../images/detail/multithreading/8.png" alt="" /></p>
<p>让输出变清晰的最简单解决方法，就是使用互斥量。</p>
<p>##互斥量</p>
<p>Mutex是互斥(<strong>mut</strong>ual <strong>ex</strong>clusion)的意思，它确保在任何时候只有一个线程可以访问临界区。</p>
<p>通过使用互斥量，工作流程的混乱变的和谐许多。</p>
<pre><code class="language-c++">// coutSynchronised.cpp

#include &lt;chrono&gt;
#include &lt;iostream&gt;
#include &lt;mutex&gt;
#include &lt;thread&gt;

std::mutex coutMutex;

class Worker {
public:
  Worker(std::string n) :name(n) {}
  void operator()() {
    for (int i = 1; i &lt;= 3; ++i) {
      // begin work
      std::this_thread::sleep_for(std::chrono::microseconds(200));
      // end work
      coutMutex.lock();
      std::cout &lt;&lt; name &lt;&lt; &quot;: &quot; &lt;&lt; &quot;Work &quot; &lt;&lt; i &lt;&lt; &quot; done !!!&quot; &lt;&lt; std::endl;
      coutMutex.unlock();
    }
  }
private:
  std::string name;
};


int main() {
  
  std::cout &lt;&lt; std::endl;

  std::cout &lt;&lt; &quot;Boss: Let's start working.\n\n&quot;;

  std::thread herb = std::thread(Worker(&quot;Herb&quot;));
  std::thread andrei = std::thread(Worker(&quot; Andrei&quot;));
  std::thread scott = std::thread(Worker(&quot;  Scott&quot;));
  std::thread bjarne = std::thread(Worker(&quot;   Bjarne&quot;));
  std::thread bart = std::thread(Worker(&quot;    Bart&quot;));
  std::thread jenne = std::thread(Worker(&quot;     Jenne&quot;));


  herb.join();
  andrei.join();
  scott.join();
  bjarne.join();
  bart.join();
  jenne.join();

  std::cout &lt;&lt; &quot;\n&quot; &lt;&lt; &quot;Boss: Let's go home.&quot; &lt;&lt; std::endl;

  std::cout &lt;&lt; std::endl;

}
</code></pre>
<p>第8行中<code>coutMutex</code>保护了<code>std::cout</code>，第19行中的<code>lock()</code>和第21行中的<code>unlock()</code>调用，确保工作人员不会同时进行报告。</p>
<p><img src="content/The-Details/Multithreading/../../../images/detail/multithreading/9.png" alt="" /></p>
<blockquote>
<p><strong>std:: cout是线程安全的</strong></p>
<p>C++11标准中，<code>std::cout</code>不需要额外的保护，每个字符都是原子式书写的。可能会有更多类似示例中的输出语句交织在一起的情况，但这些只是视觉问题，而程序则是定义良好的。所有全局流对象都是线程安全的，并且插入和提取全局流对象(<code>std::cout</code>、<code>std::cin</code>、<code>std::cerr</code>和<code>std::clog</code>)也都是线程安全的。</p>
<p>更正式地说：写入<code>std::cout</code>并不是数据竞争，而是一个竞争条件。这意味着输出内容的情况，完全取决于交错运行的线程。</p>
</blockquote>
<p>C++11有4个不同的互斥量，可以递归地、暂时地锁定，并且不受时间限制。</p>
<table><thead><tr><th align="center">成员函数</th><th align="center">mutex</th><th align="center">recursive_mutex</th><th align="center">timed_mutex</th><th align="center">recursive_timed_mutex</th></tr></thead><tbody>
<tr><td align="center">m.lock</td><td align="center">yes</td><td align="center">yes</td><td align="center">yes</td><td align="center">yes</td></tr>
<tr><td align="center">m.try_lock</td><td align="center">yes</td><td align="center">yes</td><td align="center">yes</td><td align="center">yes</td></tr>
<tr><td align="center">m.try_lock_for</td><td align="center"></td><td align="center"></td><td align="center">yes</td><td align="center">yes</td></tr>
<tr><td align="center">m.try_lock_until</td><td align="center"></td><td align="center"></td><td align="center">yes</td><td align="center">yes</td></tr>
<tr><td align="center">m.unlock</td><td align="center">yes</td><td align="center">yes</td><td align="center">yes</td><td align="center">yes</td></tr>
</tbody></table>
<p>递归互斥量允许同一个线程多次锁定互斥锁。互斥量保持锁定状态，直到解锁次数与锁定次数相等。可以锁定互斥量的最大次数默认并未指定，当达到最大值时，会抛出<a href="http://en.cppreference.com/w/cpp/error/system_error">std::system_error</a>异常。</p>
<p>C++14中有<code>std::shared_timed_mutex</code>，C++17中有<code>std::shared_mutex</code>。<code>std::shared_mutex</code>和<code>std::shared_timed_mutex</code>非常相似，使用的锁可以是互斥或共享的。另外，使用<code>std::shared_timed_mutex</code>可以指定时间点或时间段进行锁定。</p>
<table><thead><tr><th align="center">成员函数</th><th align="center">shared_timed_mutex</th><th align="center">shared_mutex</th></tr></thead><tbody>
<tr><td align="center">m.lock</td><td align="center">yes</td><td align="center">yes</td></tr>
<tr><td align="center">m.try_lock</td><td align="center">yes</td><td align="center">yes</td></tr>
<tr><td align="center">m.try_lock_for</td><td align="center">yes</td><td align="center"></td></tr>
<tr><td align="center">m.try_lock_until</td><td align="center">yes</td><td align="center"></td></tr>
<tr><td align="center">m.unlock</td><td align="center">yes</td><td align="center">yes</td></tr>
<tr><td align="center">m.lock_shared</td><td align="center">yes</td><td align="center">yes</td></tr>
<tr><td align="center">m.try_lock_shared</td><td align="center">yes</td><td align="center">yes</td></tr>
<tr><td align="center">m.try_lock_shared_for</td><td align="center">yes</td><td align="center"></td></tr>
<tr><td align="center">m.try_lock_shared_until</td><td align="center">yes</td><td align="center"></td></tr>
<tr><td align="center">m.unlock_shared</td><td align="center">yes</td><td align="center">yes</td></tr>
</tbody></table>
<p><code>std::shared_timed_mutex(std::shared_mutex)</code>可以用来实现读写锁，也就可以使用<code>std::shared_timed_mutex(std::shared_mutex)</code>进行独占或共享锁定。如果将<code>std::shared_timed_mutex(std::shared_mutex)</code>放入<code>std::lock_guard</code>或<code>std::unique_lock</code>中，就可实现独占锁；如果将<code>std::shared_timed_mutex(std::shared_lock)</code>放入<code>std::shared_lock</code>中，就可实现共享锁。<code>m.try_lock_for(relTime)</code>和<code>m.try_lock_shared_for(relTime)</code>需要一个时间段；<code>m.try_lock_until(absTime)</code>和<code>m.try_lock_shared_until(absTime)</code>需要一个绝对的时间点。</p>
<p><code>m.try_lock(m.try_lock_shared)</code>尝试锁定互斥量并立即返回。成功时，它返回true，否则返回false。相比之下，<code>m.try_lock_for(m.try_lock_shared_for)</code>和<code>m.try_lock_until(m.try_lock_shared_until)</code>也会尝试上锁，直到超时或完成锁定，这里应该使用稳定时钟来限制时间(稳定的时钟是不能调整的)。</p>
<p>不应该直接使用互斥量，应该将互斥量放入锁中，下面解释下原因。</p>
<h3 id="互斥量的问题"><a class="header" href="#互斥量的问题">互斥量的问题</a></h3>
<p>互斥量的问题可以归结为一个：死锁。</p>
<blockquote>
<p><strong>死锁</strong></p>
<p>两个或两个以上的个线程处于阻塞状态，并且每个线程在释放之前都要等待其他线程的释放。</p>
</blockquote>
<p>结果就是程序完全静止。试图获取资源的线程，通常会永久的阻塞程序。形成这种困局很简单，有兴趣了解一下吗?</p>
<h3 id="异常和未知代码"><a class="header" href="#异常和未知代码">异常和未知代码</a></h3>
<p>下面的代码段有很多问题。</p>
<pre><code class="language-c++">std::mutex m;
m.lock();
sharedVariable = getVar();
m.unlock();
</code></pre>
<p>问题如下：</p>
<ol>
<li>如果函数<code>getVar()</code>抛出异常，则互斥量<code>m</code>不会被释放。</li>
<li>永远不要在持有锁的时候调用函数。因为<code>m</code>不是递归互斥量，如果函数<code>getVar</code>试图锁定互斥量<code>m</code>，则程序具有未定义的行为。大多数情况下，未定义行为会导致死锁。</li>
<li>避免在持有锁时调用函数。可能这个函数来自一个库，但当这个函数发生改变，就有陷入僵局的可能。</li>
</ol>
<p>程序需要的锁越多，程序的风险就越高(非线性)。</p>
<h3 id="不同顺序锁定的互斥锁"><a class="header" href="#不同顺序锁定的互斥锁">不同顺序锁定的互斥锁</a></h3>
<p>下面是一个典型的死锁场景，死锁是按不同顺序进行锁定的。</p>
<p><img src="content/The-Details/Multithreading/../../../images/detail/multithreading/10.png" alt="" /></p>
<p>线程1和线程2需要访问两个资源来完成它们的工作。当资源被两个单独的互斥体保护，并且以不同的顺序被请求(线程1:锁1，锁2;线程2:锁2，锁1)时，线程交错执行，线程1得到互斥锁1，然后线程2得到互斥锁2，从而程序进入停滞状态。每个线程都想获得另一个互斥锁，但需要另一个线程释放其需要的互斥锁。“死亡拥抱”这个形容，很好地描述了这种状态。</p>
<p>将这上图转换成代码。</p>
<pre><code class="language-c++">// deadlock.cpp

#include &lt;iostream&gt;
#include &lt;chrono&gt;
#include &lt;mutex&gt;
#include &lt;thread&gt;

struct CriticalData {
  std::mutex mut;
};

void deadLock(CriticalData&amp; a, CriticalData&amp; b) {

  a.mut.lock();
  std::cout &lt;&lt; &quot;get the first mutex&quot; &lt;&lt; std::endl;
  std::this_thread::sleep_for(std::chrono::microseconds(1));
  b.mut.lock();
  std::cout &lt;&lt; &quot;get the second mutext&quot; &lt;&lt; std::endl;
  // do something with a and b
  a.mut.unlock();
  b.mut.unlock();

}

int main() {

  CriticalData c1;
  CriticalData c2;

  std::thread t1([&amp;] {deadLock(c1, c2); });
  std::thread t2([&amp;] {deadLock(c2, c1); });

  t1.join();
  t2.join();

}
</code></pre>
<p>线程<code>t1</code>和<code>t2</code>调用死锁函数(第12 - 23行)，向函数传入了<code>c1</code>和<code>c2</code>(第27行和第28行)。由于需要保护<code>c1</code>和<code>c2</code>不受共享访问的影响，它们在内部各持有一个互斥量(为了保持本例简短，关键数据除了互斥量外没有其他函数或成员)。</p>
<p>第16行中，约1毫秒的短睡眠就足以产生死锁。</p>
<p><img src="content/The-Details/Multithreading/../../../images/detail/multithreading/11.png" alt="" /></p>
<p>这时，只能按CTRL+C终止进程。</p>
<p>互斥量不能解决所有问题，但在很多情况下，锁可以帮助我们解决这些问题。</p>
<h3 id="锁-1"><a class="header" href="#锁-1">锁</a></h3>
<p>锁使用RAII方式处理它们的资源。锁在构造函数中自动绑定互斥量，并在析构函数中释放互斥量，这大大降低了死锁的风险。</p>
<p>锁有四种不同的形式：<code>std::lock_guard</code>用于简单程序，<code>std::unique_lock</code>用于高级程序。从C++14开始就可以用<code>std::shared_lock</code>来实现读写锁了。C++17中，添加了<code>std::scoped_lock</code>，它可以在原子操作中锁定更多的互斥对象。</p>
<p>首先，来看简单程序。</p>
<p><strong>std::lock_guard</strong></p>
<pre><code class="language-c++">std::mutex m;
m.lock();
sharedVariable = getVar();
m.unlock();
</code></pre>
<p>互斥量<code>m</code>可以确保对<code>sharedVariable = getVar()</code>的访问是有序的。有序指的是，每个线程按照某种顺序，依次访问临界区。代码很简单，但是容易出现死锁。如果临界区抛出异常或者忘记解锁互斥量，就会出现死锁。使用<code>std::lock_guard</code>，可以很优雅的解决问题：</p>
<pre><code class="language-c++">{
  std::mutex m,
  std::lock_guard&lt;std::mutex&gt; lockGuard(m);
  sharedVariable = getVar();
}
</code></pre>
<p>代码很简单，但是前后的花括号是什么呢？<code>std::lock_guard</code>的生存周期受其作用域的限制，作用域由<a href="http://en.cppreference.com/w/cpp/language/scope#Block_scope">花括号</a>构成。生命周期在达到右花括号时结束，<code>std::lock_guard</code>析构函数被调用，并且互斥量被释放。这都是自动发生的，如果<code>sharedVariable = getVar()</code>中的<code>getVar()</code>抛出异常，释放过程也会自动发生。函数作用域和循环作用域，也会限制实例对象的生命周期。</p>
<p><strong>std::scoped_lock</strong></p>
<p>C++17中，添加了<code>std::scoped_lock</code>。与<code>std::lock_guard</code>非常相似，但可以原子地锁定任意数量的互斥对象。</p>
<ol>
<li>如果<code>std::scoped_lock</code>调用一个互斥量，它的行为就类似于<code>std::lock_guard</code>，并锁定互斥量<code>m</code>: <code>m.lock</code>。如果<code>std::scoped_lock</code>被多个互斥对象调用<code>std::scoped_lock(mutextypes&amp;…)</code>，则使用<code>std::lock(m…)</code>函数进行锁定操作。</li>
<li>如果当前线程已经拥有了互斥量，但这个互斥量不可递归，那么这个行为就是未定义的，很有可能出现死锁。</li>
<li>只需要获得互斥量的所有权，而不需要锁定它们。这种情况下，必须将标志<code>std::adopt_lock_t</code>提供给构造函数：<code>std::scoped_lock(std::adopt_lock_t, mutextypes&amp;…m)</code>。</li>
</ol>
<p>使用<code>std::scoped_lock</code>，可以优雅地解决之前的死锁问题。下一节中，将讨论如何杜绝死锁。</p>
<p><strong>std::unique_lock</strong></p>
<p><code>std::unique_lock</code>比<code>std::lock_guard</code>更强大，也更重量级。</p>
<p>除了包含<code>std::lock_guard</code>提供的功能之外，<code>std::unique_lock</code>还允许：</p>
<ul>
<li>创建无需互斥量的锁</li>
<li>不锁定互斥量的情况下创建锁</li>
<li>显式地/重复地设置或释放关联的互斥锁量</li>
<li>递归锁定互斥量</li>
<li>移动互斥量</li>
<li>尝试锁定互斥量</li>
<li>延迟锁定关联的互斥量</li>
</ul>
<p>下表展示了<code>std::unique_lock lk</code>的成员函数：</p>
<table><thead><tr><th align="center">成员函数</th><th align="center">功能描述</th></tr></thead><tbody>
<tr><td align="center"><code>lk.lock()</code></td><td align="center">锁定相关互斥量</td></tr>
<tr><td align="center"><code>lk.try_lock()</code></td><td align="center">尝试锁定相关互斥量</td></tr>
<tr><td align="center"><code>lk.try_lock_for(relTime)</code></td><td align="center">尝试锁定相关互斥量</td></tr>
<tr><td align="center"><code>lk.try_lock_until(absTime)</code></td><td align="center">尝试锁定相关互斥量</td></tr>
<tr><td align="center"><code>lk.unlock()</code></td><td align="center">解锁相关互斥量</td></tr>
<tr><td align="center"><code>lk.release()</code></td><td align="center">释放互斥量，互斥量保持锁定状态</td></tr>
<tr><td align="center"><code>lk.swap(lk2)</code>和<code>std::swap(lk, lk2)</code></td><td align="center">交换锁</td></tr>
<tr><td align="center"><code>lk.mutex()</code></td><td align="center">返回指向相关互斥量的指针</td></tr>
<tr><td align="center"><code>lk.owns_lock()</code>和bool操作符</td><td align="center">检查锁<code>lk</code>是否有锁住的互斥量</td></tr>
</tbody></table>
<p><code>try_lock_for(relTime)</code>需要传入一个时间段，<code>try_lock_until(absTime)</code>需要传入一个绝对的时间点。<code>lk.try_lock_for(lk.try_lock_until)</code>会调用关联的互斥量<code>mut</code>的成员函数<code>mut.try_lock_for(mut.try_lock_until) </code>。相关的互斥量需要支持定时阻塞，这就需要使用稳定的时钟来限制时间。</p>
<p><code>lk.try_lock</code>尝试锁定互斥锁并立即返回。成功时返回true，否则返回false。相反，<code>lk.try_lock_for</code>和<code>lk.try_lock_until</code>则会让锁<code>lk</code>阻塞，直到超时或获得锁为止。如果没有关联的互斥锁，或者这个互斥锁已经被<code>std::unique_lock</code>锁定，那么<code>lk.try_lock</code>、<code>lk.try_lock_for</code>和<code>lk.try_lock_for</code>则抛出<code>std::system_error</code>异常。</p>
<p><code>lk.release()</code>返回互斥量，必须手动对其进行解锁。</p>
<p><code>std::unique_lock</code>在原子步骤中可以锁定多个互斥对象。因此，可以通过以不同的顺序锁定互斥量来避免死锁。还记得在互斥量中出现的死锁吗?</p>
<pre><code class="language-c++">// deadlock.cpp

#include &lt;iostream&gt;
#include &lt;chrono&gt;
#include &lt;mutex&gt;
#include &lt;thread&gt;

struct CriticalData {
  std::mutex mut;
};

void deadLock(CriticalData&amp; a, CriticalData&amp; b) {

  a.mut.lock();
  std::cout &lt;&lt; &quot;get the first mutex&quot; &lt;&lt; std::endl;
  std::this_thread::sleep_for(std::chrono::microseconds(1));
  b.mut.lock();
  std::cout &lt;&lt; &quot;get the second mutext&quot; &lt;&lt; std::endl;
  // do something with a and b
  a.mut.unlock();
  b.mut.unlock();

}

int main() {

  CriticalData c1;
  CriticalData c2;

  std::thread t1([&amp;] {deadLock(c1, c2); });
  std::thread t2([&amp;] {deadLock(c2, c1); });

  t1.join();
  t2.join();

}
</code></pre>
<p>让我们来解决死锁问题。死锁必须原子地锁定互斥对象，也正是下面的程序中所展示的。</p>
<pre><code class="language-c++">// deadlockResolved.cpp

#include &lt;iostream&gt;
#include &lt;chrono&gt;
#include &lt;mutex&gt;
#include &lt;thread&gt;

using namespace std;

struct CriticalData {
  mutex mut;
};

void deadLock(CriticalData&amp; a, CriticalData&amp; b) {

  unique_lock&lt;mutex&gt; guard1(a.mut, defer_lock);
  cout &lt;&lt; &quot;Thread: &quot; &lt;&lt; this_thread::get_id() &lt;&lt; &quot; first mutex&quot; &lt;&lt; endl;

  this_thread::sleep_for(chrono::milliseconds(1));

  unique_lock&lt;mutex&gt; guard2(b.mut, defer_lock);
  cout &lt;&lt; &quot; Thread: &quot; &lt;&lt; this_thread::get_id() &lt;&lt; &quot; second mutex&quot; &lt;&lt; endl;

  cout &lt;&lt; &quot;  Thread: &quot; &lt;&lt; this_thread::get_id() &lt;&lt; &quot; get both mutex&quot; &lt;&lt; endl;
  lock(guard1, guard2);
  // do something with a and b
}

int main() {

  cout &lt;&lt; endl;

  CriticalData c1;
  CriticalData c2;

  thread t1([&amp;] {deadLock(c1, c2); });
  thread t2([&amp;] {deadLock(c2, c1); });

  t1.join();
  t2.join();

  cout &lt;&lt; endl;

}
</code></pre>
<p>如果使用<code>std::defer_lock</code>对<code>std::unique_lock</code>进行构造，则底层的互斥量不会自动锁定。此时(第16行和第21行)，<code>std::unique_lock</code>就是互斥量的所有者。由于<code>std::lock</code>是可变参数模板，锁操作可以原子的执行(第25行)。</p>
<blockquote>
<p><strong>使用std::lock进行原子锁定</strong></p>
<p><code>std::lock</code>可以在原子的锁定互斥对象。<code>std::lock</code>是一个可变参数模板，因此可以接受任意数量的参数。<code>std::lock</code>尝试使用避免死锁的算法，在一个原子步骤获得所有锁。互斥量会锁定一系列操作，比如：<code>lock</code>、<code>try_lock</code>和<code>unlock</code>。如果对锁或解锁的调用异常，则解锁操作会在异常重新抛出之前执行。</p>
</blockquote>
<p>本例中，<code>std::unique_lock</code>管理资源的生存期，<code>std::lock</code>锁定关联的互斥量，也可以反过来。第一步中锁住互斥量，第二步中<code>std::unique_lock</code>管理资源的生命周期。下面是第二种方法的例子：</p>
<pre><code class="language-c++">std::lock(a.mut, b.mut);
std::lock_guard&lt;std::mutex&gt; guard1(a.mut, std::adopt_lock);
std::lock_guard&lt;std::mutex&gt; guard2(b.mut, std::adopt_lock);
</code></pre>
<p>这两个方式都能解决死锁。</p>
<p><img src="content/The-Details/Multithreading/../../../images/detail/multithreading/12.png" alt="" /></p>
<blockquote>
<p><strong>使用std::scoped_lock解决死锁</strong></p>
<p>C++17中解决死锁非常容易。有了<code>std::scoped_lock</code>帮助，可以原子地锁定任意数量的互斥。只需使用<code>std::scoped_lock</code>，就能解决所有问题。下面是修改后的死锁函数：</p>
<pre><code class="language-c++">// deadlockResolvedScopedLock.cpp
...
void deadLock(CriticalData&amp; a, CriticalData&amp; b) {
cout &lt;&lt; &quot;Thread: &quot; &lt;&lt; this_thread::get_id() &lt;&lt; &quot; first mutex&quot; &lt;&lt; endl;
this_thread::sleep_for(chrono::milliseconds(1));
  cout &lt;&lt; &quot; Thread: &quot; &lt;&lt; this_thread::get_id() &lt;&lt; &quot; second mutex&quot; &lt;&lt; endl;
  cout &lt;&lt; &quot; Thread: &quot; &lt;&lt; this_thread::get_id() &lt;&lt; &quot; get both mutex&quot; &lt;&lt; endl;
  
  std::scoped_lock(a.mut, b.mut);
// do something with a and b
  }
  
...
</code></pre>
</blockquote>
<p><strong>std::shared_lock</strong></p>
<p>C++14中添加了<code>std::shared_lock</code>。</p>
<p><code>std::shared_lock</code>与<code>std::unique_lock</code>的接口相同，但与<code>std::shared_timed_mutex</code>或<code>std::shared_mutex</code>一起使用时，行为会有所不同。许多线程可以共享一个<code>std::shared_timed_mutex (std::shared_mutex)</code>，从而实现读写锁。读写器锁的思想非常简单，而且非常有用。执行读操作的线程可以同时访问临界区，但是只允许一个线程写。</p>
<p>读写锁并不能解决最根本的问题——线程争着访问同一个关键区域。</p>
<p>电话本就是使用读写锁的典型例子。通常，许多人想要查询电话号码，但只有少数人想要更改。让我们看一个例子：</p>
<pre><code class="language-c++">// readerWriterLock.cpp

#include &lt;iostream&gt;
#include &lt;map&gt;
#include &lt;shared_mutex&gt;
#include &lt;string&gt;
#include &lt;thread&gt;

std::map&lt;std::string, int&gt; teleBook{ {&quot;Dijkstra&quot;, 1972}, {&quot;Scott&quot;, 1976},
                                                          {&quot;Ritchie&quot;, 1983} };

std::shared_timed_mutex teleBookMutex;

void addToTeleBook(const std::string&amp; na, int tele) {
  std::lock_guard&lt;std::shared_timed_mutex&gt; writerLock(teleBookMutex);
  std::cout &lt;&lt; &quot;\nSTARTING UPDATE &quot; &lt;&lt; na;
  std::this_thread::sleep_for(std::chrono::milliseconds(500));
  teleBook[na] = tele;
  std::cout &lt;&lt; &quot; ... ENDING UPDATE &quot; &lt;&lt; na &lt;&lt; std::endl;
}

void printNumber(const std::string&amp; na) {
  std::shared_lock&lt;std::shared_timed_mutex&gt; readerLock(teleBookMutex);
  std::cout &lt;&lt; na &lt;&lt; &quot;: &quot; &lt;&lt; teleBook[na];
}

int main() {

  std::cout &lt;&lt; std::endl;

  std::thread reader1([] {printNumber(&quot;Scott&quot;); });
  std::thread reader2([] {printNumber(&quot;Ritchie&quot;); });
  std::thread w1([] {addToTeleBook(&quot;Scott&quot;,1968); });
  std::thread reader3([] {printNumber(&quot;Dijkstra&quot;); });
  std::thread reader4([] {printNumber(&quot;Scott&quot;); });
  std::thread w2([] {addToTeleBook(&quot;Bjarne&quot;, 1965); });
  std::thread reader5([] {printNumber(&quot;Scott&quot;); });
  std::thread reader6([] {printNumber(&quot;Ritchie&quot;); });
  std::thread reader7([] {printNumber(&quot;Scott&quot;); });
  std::thread reader8([] {printNumber(&quot;Bjarne&quot;); });

  reader1.join();
  reader2.join();
  reader3.join();
  reader4.join();
  reader5.join();
  reader6.join();
  reader7.join();
  reader8.join();
  w1.join();
  w2.join();

  std::cout &lt;&lt; std::endl;

  std::cout &lt;&lt; &quot;\nThe new telephone book&quot; &lt;&lt; std::endl;
  for (auto teleIt : teleBook) {
    std::cout &lt;&lt; teleIt.first &lt;&lt; &quot;: &quot; &lt;&lt; teleIt.second &lt;&lt; std::endl;
  }

  std::cout &lt;&lt; std::endl;

}
</code></pre>
<p>第9行中的电话簿是共享变量，必须对其进行保护。八个线程要查询电话簿，两个线程想要修改它(第31 - 40行)。为了同时访问电话簿，读取线程使用<code>std::shared_lock&lt;std::shared_timed_mutex&gt;</code>(第23行)。写线程需要以独占的方式访问临界区，第15行中的<code>std::lock_guard&lt;std::shared_timed_mutex&gt;</code>具有独占性。最后，程序显示了更新后的电话簿(第55 - 58行)。</p>
<p><img src="content/The-Details/Multithreading/../../../images/detail/multithreading/13.png" alt="" /></p>
<p>屏幕截图显示，读线程的输出是重叠的，而写线程是一个接一个地执行。这就意味着，读取操作应该是同时执行的。</p>
<p>这很容易让“电话簿”有未定义行为。</p>
<h3 id="未定义行为"><a class="header" href="#未定义行为">未定义行为</a></h3>
<p>程序有未定义行为。更准确地说，它有一个数据竞争。啊哈！？在继续之前，停下来想几秒钟。</p>
<p>数据竞争的特征是，至少有两个线程同时访问共享变量，并且其中至少有一个线程是写线程，这种情况很可能在程序执行时发生。使用索引操作符读取容器中的值，并可以修改它。如果元素在容器中不存在，就会发生这种情况。如果在电话簿中没有找到“Bjarne”，则从读访问中创建一对<code>(“Bjarne”，0)</code>。可以通过在第40行前面打印Bjarne的数据，强制数据竞争。</p>
<p>可以看到的是，Bjarne的值是0。</p>
<p><img src="content/The-Details/Multithreading/../../../images/detail/multithreading/14.png" alt="" /></p>
<p>修复这个问题的最直接的方法是使用<code>printNumber</code>函数中的读取操作:</p>
<pre><code class="language-c++">// readerWriterLocksResolved.cpp

...

void printNumber(const std::string&amp; na){
  std::shared_lock&lt;std::shared_timed_mutex&gt; readerLock(teleBookMutex);
  auto searchEntry = teleBook.find(na);
  if(searchEntry != teleBook.end()){
    std::cout &lt;&lt; searchEntry-&gt;first &lt;&lt; &quot;: &quot; &lt;&lt; searchEntry-&gt;second &lt;&lt; std::endl;
  }
  else{
    std::cout &lt;&lt; na &lt;&lt; &quot; not found!&quot; &lt;&lt; std::endl;
  }
}
...
</code></pre>
<p>如果电话簿里没有相应键值，就把键值写下来，并且向控制台输出“找不到!”。</p>
<p><img src="content/The-Details/Multithreading/../../../images/detail/multithreading/15.png" alt="" /></p>
<p>第二个程序执行的输出中，可以看到Bjarne的信息没有找到。第一个程序执行中，首先执行了<code>addToTeleBook</code>，所以Bjarne被找到了。</p>
<h3 id="线程安全的初始化"><a class="header" href="#线程安全的初始化">线程安全的初始化</a></h3>
<p>如果变量从未修改过，那么就不需要锁或原子变量来进行同步，只需确保以线程安全的方式初始化就可以了。</p>
<p>C++中有三种以线程安全初始化变量的方法：</p>
<ul>
<li>常量表达式</li>
<li><code>std::call_once</code>与<code>std::once_flag</code>结合的方式</li>
<li>作用域的静态变量</li>
</ul>
<blockquote>
<p><strong>主线程中的安全初始化</strong></p>
<p>以线程安全的方式初始化变量的最简单方法，是在创建任何子线程之前在主线程中初始化变量。</p>
</blockquote>
<p><strong>常数表达式</strong></p>
<p>常量表达式，是编译器可以在编译时计算的表达式，隐式线程安全的。将关键字<code>constexpr</code>放在变量前面，会使该变量成为常量表达式。常量表达式必须初始化。</p>
<pre><code class="language-c++">constexpr double pi = 3.14;
</code></pre>
<p>此外，用户定义的类型也可以是常量表达式。不过，必须满足一些条件才能在编译时初始化：</p>
<ul>
<li>不能有虚方法或虚基类</li>
<li>构造函数必须为空，且本身为常量表达式</li>
<li>必须初始化每个基类和每个非静态成员</li>
<li>成员函数在编译时应该是可调用的，必须是常量表达式</li>
</ul>
<p><code>MyDouble</code>的实例满足所有这些需求，因此可以在编译时实例化。所以，这个实例化是线程安全的。</p>
<pre><code class="language-c++">// constexpr.cpp

#include &lt;iostream&gt;

class MyDouble {
private:
  double myVal1;
  double myVal2;
public:
  constexpr MyDouble(double v1, double v2):myVal1(v1),myVal2(v2){}
  constexpr double getSum() const { return myVal1 + myVal2; }
};

int main() {

  constexpr double myStatVal = 2.0;
  constexpr MyDouble myStatic(10.5, myStatVal);
  constexpr double sumStat = myStatic.getSum();

}
</code></pre>
<p><strong>std::call_once和std::once_flag</strong></p>
<p>通过使用<code>std::call_once</code>函数，可以注册一个可调用单元。<code>std::once_flag</code>确保已注册的函数只调用一次。可以通过相同的<code>std::once_flag</code>注册其他函数，只能调用注册函数组中的一个函数。</p>
<p><code>std::call_once</code>遵循以下规则:</p>
<ul>
<li>只执行其中一个函数的一次，未定义选择哪个函数执行。所选函数与<code>std::call_once</code>在同一个线程中执行。</li>
<li>上述所选函数的执行成功完成之前，不返回任何调用。</li>
<li>如果函数异常退出，则将其传播到调用处。然后，执行另一个函数。</li>
</ul>
<p>这个短例演示了<code>std::call_once</code>和<code>std::once_flag</code>的应用(都在头文件<code>&lt;mutex&gt;</code>中声明)。</p>
<pre><code class="language-c++">// callOnce.cpp

#include &lt;iostream&gt;
#include &lt;thread&gt;
#include &lt;mutex&gt;

std::once_flag onceFlag;

void do_once() {
  std::call_once(onceFlag, [] {std::cout &lt;&lt; &quot;Only once.&quot; &lt;&lt; std::endl; });
}

void do_once2() {
  std::call_once(onceFlag, [] {std::cout &lt;&lt; &quot;Only once2.&quot; &lt;&lt; std::endl; });
}

int main() {
  
  std::cout &lt;&lt; std::endl;

  std::thread t1(do_once);
  std::thread t2(do_once);
  std::thread t3(do_once2);
  std::thread t4(do_once2);

  t1.join();
  t2.join();
  t3.join();
  t4.join();

  std::cout &lt;&lt; std::endl;

}
</code></pre>
<p>程序从四个线程开始(第21 - 24行)。其中两个调用<code>do_once</code>，另两个调用<code>do_once2</code>。预期的结果是“Only once”或“Only once2”只显示一次。</p>
<p><img src="content/The-Details/Multithreading/../../../images/detail/multithreading/16.png" alt="" /></p>
<p>单例模式保证只创建类的一个实例，这在多线程环境中是一个具有挑战性的任务。由于<code>std::call_once</code>和<code>std::once_flag</code>的存在，实现这样的功能就非常容易了。</p>
<p>现在，单例以线程安全的方式初始化。</p>
<pre><code class="language-c++">// singletonCallOnce.cpp

#include &lt;iostream&gt;
#include &lt;mutex&gt;

using namespace std;

class MySingleton {

private:
  static once_flag initInstanceFlag;
  static MySingleton* instance;
  MySingleton() = default;
  ~MySingleton() = default;

public:
  MySingleton(const MySingleton&amp;) = delete;
  MySingleton&amp; operator=(const MySingleton&amp;) = delete;

  static MySingleton* getInstance() {
    call_once(initInstanceFlag, MySingleton::initSingleton);
    return instance;
  }

  static void initSingleton() {
    instance = new MySingleton();
  }
};

MySingleton* MySingleton::instance = nullptr;
once_flag MySingleton::initInstanceFlag;

int main() {

  cout &lt;&lt; endl;

  cout &lt;&lt; &quot;MySingleton::getInstance(): &quot; &lt;&lt; MySingleton::getInstance() &lt;&lt; endl;
  cout &lt;&lt; &quot;MySingleton::getInstance(): &quot; &lt;&lt; MySingleton::getInstance() &lt;&lt; endl;

  cout &lt;&lt; endl;

}
</code></pre>
<p>静态变量<code>initInstanceFlag</code>在第11行声明，在第31行初始化。静态方法<code>getInstance</code>(第20 - 23行)使用<code>initInstanceFlag</code>标志，来确保静态方法<code>initSingleton</code>(第25 - 27行)只执行一次。</p>
<blockquote>
<p><strong>default和delete修饰符</strong></p>
<p>可以使用关键字<code>default</code>向编译器申请函数实现，编译器可以创建并实现它们。</p>
<p>用<code>delete</code>修饰一个成员函数的话，则该函数不可用，因此不能被调用。如果尝试使用它们，将得到一个编译时错误。这里有<a href="https://isocpp.org/wiki/faq/cpp11-language-classes">default和delete</a>的详细信息。</p>
</blockquote>
<p><code>MySingleton::getIstance() </code>函数显示了单例的地址。</p>
<p><img src="content/The-Details/Multithreading/../../../images/detail/multithreading/17.png" alt="" /></p>
<h3 id="有作用域的静态变量"><a class="header" href="#有作用域的静态变量">有作用域的静态变量</a></h3>
<p>具有作用域的静态变量只创建一次，并且是惰性的，惰性意味着它们只在使用时创建。这一特点是基于Meyers单例的基础，以<a href="https://en.wikipedia.org/wiki/Scott_Meyers">Scott Meyers</a>命名，这是迄今为止C++中单例模式最优雅的实现。C++11中，带有作用域的静态变量有一个额外的特点，可以以线程安全的方式初始化。</p>
<p>下面是线程安全的Meyers单例模式。</p>
<pre><code class="language-c++">// meyersSingleton.cpp

class MySingleton {
public:
  static MySingleton&amp; getInstance() {
    static MySingleton instance;
    return instance;
  }

private:
  MySingleton();
  ~MySingleton();
  MySingleton(const MySingleton&amp;) = delete;
  MySingleton&amp; operator=(const MySingleton&amp;) = delete;
  
};

MySingleton::MySingleton()= default;
MySingleton::~MySingleton()= default;


int main(){
  
  MySingleton::getInstance();
  
}
</code></pre>
<blockquote>
<p><strong>编译器对静态变量的支持</strong></p>
<p>如果在并发环境中使用Meyers单例，请确保编译器对于C++11的支持。开发者经常依赖于C++11的静态变量语义，但是有时他们的编译器不支持这项特性，结果可能会创建多个单例实例。</p>
</blockquote>
<p>讨论了这么多，而在<code>thread_local</code>中就没有共享变量的问题了。</p>
<p>接下来，我们来了解一下<code>thread_local</code>。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="线程-本地数据"><a class="header" href="#线程-本地数据">线程-本地数据</a></h1>
<p>线程-本地数据(也称为线程-本地存储)是为每个线程单独创建的，其行为类似于静态数据。在命名空间范围内，或作为静态类成员的线程局部变量，是在第一次使用之前创建，而在函数中声明的线程局部变量是在第一次使用时创建，并且线程-本地数据只属于线程。</p>
<pre><code class="language-c++">// threadLocal.cpp

#include &lt;iostream&gt;
#include &lt;string&gt;
#include &lt;mutex&gt;
#include &lt;thread&gt;

std::mutex coutMutex;

thread_local std::string s(&quot;hello from &quot;);

void addThreadLocal(std::string const&amp; s2) {
  
  s += s2;
  // protect std::cout
  std::lock_guard&lt;std::mutex&gt; guard(coutMutex);
  std::cout &lt;&lt; s &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;&amp;s: &quot; &lt;&lt; &amp;s &lt;&lt; std::endl;
  std::cout &lt;&lt; std::endl;

}

int main() {

  std::cout &lt;&lt; std::endl;

  std::thread t1(addThreadLocal, &quot;t1&quot;);
  std::thread t2(addThreadLocal, &quot;t2&quot;);
  std::thread t3(addThreadLocal, &quot;t3&quot;);
  std::thread t4(addThreadLocal, &quot;t4&quot;);

  t1.join();
  t2.join();
  t3.join();
  t4.join();

}
</code></pre>
<p>通过在第10行中使用关键字<code>thread_local</code>，可以创建线程本地字符串<code>s</code>。线程<code>t1</code> - <code>t4</code>(第27 - 30行)使用<code>addThreadLocal</code>函数(第12 - 21行)作为工作包。线程分别获取字符串<code>t1</code>到<code>t4</code>作为参数，并添加到线程本地字符串<code>s</code>中。另外，<code>addThreadLocal</code>在第18行会打印<code>s</code>的地址。</p>
<p><img src="content/The-Details/Multithreading/../../../images/detail/multithreading/18.png" alt="" /></p>
<p>程序的输出在第17行显示内容，在第18行显示地址。要为字符串<code>s</code>创建线程本地字符串：首先，每个输出显示新的线程本地字符串；其次，每个字符串都有不同的地址。</p>
<p>我经常在研讨会上讨论：静态变量、<code>thread_local</code>变量和局部变量之间的区别是什么？静态变量与主线程的生命周期相同，<code>thread_local</code>变量与其所在线程的生存周期相同，而局部变量与创建作用域的生存周期相同。为了说明我的观点，来看一下代码。</p>
<pre><code class="language-c++">// threadLocalState.cpp

#include &lt;iostream&gt;
#include &lt;string&gt;
#include &lt;mutex&gt;
#include &lt;thread&gt;

std::mutex coutMutex;

thread_local std::string s(&quot;hello from &quot;);

void first() {
  s += &quot;first &quot;;
}

void second() {
  s += &quot;second &quot;;
}

void third() {
  s += &quot;third&quot;;
}

void addThreadLocal(std::string const&amp; s2) {
  
  s += s2;

  first();
  second();
  third();
  // protect std::cout
  std::lock_guard&lt;std::mutex&gt; guard(coutMutex);
  std::cout &lt;&lt; s &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;&amp;s: &quot; &lt;&lt; &amp;s &lt;&lt; std::endl;
  std::cout &lt;&lt; std::endl;

}

int main() {

  std::cout &lt;&lt; std::endl;

  std::thread t1(addThreadLocal, &quot;t1: &quot;);
  std::thread t2(addThreadLocal, &quot;t2: &quot;);
  std::thread t3(addThreadLocal, &quot;t3: &quot;);
  std::thread t4(addThreadLocal, &quot;t4: &quot;);

  t1.join();
  t2.join();
  t3.join();
  t4.join();

}
</code></pre>
<p>代码中，函数<code>addThreadLocal </code>(第24行)先调用函数<code>first</code> ，然后调用<code>second</code>，再调用<code>third</code> 。每个函数都使用<code>thread_local</code>字符串<code>s</code>来添加它的函数名。这种变化的关键之处在于，字符串<code>s</code>在函数<code>first</code>、<code>second</code>和<code>third</code>中操作时，处于一种本地数据的状态(第28 - 30行)，并且从输出表明字符串是独立存在的。</p>
<p><img src="content/The-Details/Multithreading/../../../images/detail/multithreading/19.png" alt="" /></p>
<blockquote>
<p><strong>单线程到多线程</strong></p>
<p>线程本地数据有助于将单线程程序移植成多线程程序。如果全局变量是线程局部的，则可以保证每个线程都得到其数据的副本，从而避免数据竞争。</p>
</blockquote>
<p>与线程-本地数据相比，条件变量的使用门槛更高。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="条件变量-1"><a class="header" href="#条件变量-1">条件变量</a></h1>
<p>条件变量通过消息对线程进行同步(需要包含<code>&lt;condition_variable&gt;</code>头文件)，一个线程作为发送方，另一个线程作为接收方，接收方等待来自发送方的通知。条件变量的典型用例：发送方-接收方或生产者-消费者模式。</p>
<p>条件变量<code>cv</code>的成员函数</p>
<table><thead><tr><th align="center">成员函数</th><th align="center">函数描述</th></tr></thead><tbody>
<tr><td align="center"><code>cv.notify_one()</code></td><td align="center">通知一个等待中的线程</td></tr>
<tr><td align="center"><code>cv.notify_all()</code></td><td align="center">通知所有等待中的线程</td></tr>
<tr><td align="center"><code>cv.wait(lock, ...)</code></td><td align="center">持有<code>std::unique_lock</code>，并等待通知</td></tr>
<tr><td align="center"><code>cv.wait_for(lock, relTime, ...)</code></td><td align="center">持有<code>std::unique_lock</code>，并在给定的时间段内等待通知</td></tr>
<tr><td align="center"><code>cv.wait_until(lock, absTime, ...)</code></td><td align="center">持有<code>std::unique_lock</code>的同时，并在给定的时间点前等待通知</td></tr>
<tr><td align="center"><code>cv.native_handle()</code></td><td align="center">返回条件变量的底层句柄</td></tr>
</tbody></table>
<p><code>cv.notify_one</code>和<code>cv.notify_all</code>相比较，<code>cv.notify_all</code>会通知所有正在等待的线程，<code>cv.notify_one</code>只通知一个正在等待的线程，其他条件变量依旧保持在等待状态。介绍条件变量的详细信息之前，来看个示例。</p>
<pre><code class="language-c++">// conditionVariable.cpp

#include &lt;iostream&gt;
#include &lt;condition_variable&gt;
#include &lt;mutex&gt;
#include &lt;thread&gt;

std::mutex mutex_;
std::condition_variable condVar;

bool dataReady{ false };

void doTheWork() {
  std::cout &lt;&lt; &quot;Processing shared data.&quot; &lt;&lt; std::endl;
}

void waitingForWork() {
  std::cout &lt;&lt; &quot;Worker: Waiting for work.&quot; &lt;&lt; std::endl;
  std::unique_lock&lt;std::mutex&gt; lck(mutex_);
  condVar.wait(lck, [] {return dataReady; });
  doTheWork();
  std::cout &lt;&lt; &quot;Work done.&quot; &lt;&lt; std::endl;
}

void setDataReady() {
  {
    std::lock_guard&lt;std::mutex&gt; lck(mutex_);
    dataReady = true;
  }
  std::cout &lt;&lt; &quot;Sender: Data is ready.&quot; &lt;&lt; std::endl;
  condVar.notify_one();
}

int main() {

  std::cout &lt;&lt; std::endl;

  std::thread t1(waitingForWork);
  std::thread t2(setDataReady);

  t1.join();
  t2.join();

  std::cout &lt;&lt; std::endl;

}
</code></pre>
<p>该程序有两个子线程：<code>t1</code>和<code>t2</code>。第38行和第39行中，线程得到工作包<code>waitingForWork</code>和<code>setDataRead</code>。<code>setDataReady</code>使用条件变量<code>condVar</code>通知其他线程准备工作已经完成：<code>condVar.notify_one()</code>。当持有锁时，线程<code>t1</code>等待它的通知：<code>condVar.wait(lck, []{ return dataReady; }) </code>。发送方和接收方需要一个锁，对于发送方，<code>std::lock_guard</code>就足够了，因为<code>lock</code>和<code>unlock</code>只调用一次；对于接收方来说，<code>std::unique_lock</code>是必需的，因为它需要锁定和解锁互斥锁。</p>
<p>程序的输出如下：</p>
<p><img src="content/The-Details/Multithreading/../../../images/detail/multithreading/20.png" alt="" /></p>
<blockquote>
<p><strong>std::condition_variable_any</strong></p>
<p><code>std::condition_variable</code>只能等待类型为<code>std::unique_lock&lt;mutex&gt;</code>的对象，但是<code>std::condition_variable_any</code>可以等待符合<a href="http://en.cppreference.com/w/cpp/concept/BasicLockable">BasicLockable</a>原则的锁类型。<code>std::condition_variable_any</code>与<code>std::condition_variable</code>支持的接口相同。</p>
</blockquote>
<h2 id="谓词"><a class="header" href="#谓词">谓词</a></h2>
<p>在没有谓词的情况下也可以调用<code>wait</code>，那么读者朋友应该很想知道，为什么调用<code>wait</code>需要谓词。</p>
<p>等待使用谓词与否都是可以的，先来看个例子。</p>
<pre><code class="language-c++">// conditionVariableBlock.cpp

#include &lt;iostream&gt;
#include &lt;condition_variable&gt;
#include &lt;mutex&gt;
#include &lt;thread&gt;

std::mutex mutex_;
std::condition_variable condVar;

void waitingForWork() {

  std::cout &lt;&lt; &quot;Worker: Waiting for work.&quot; &lt;&lt; std::endl;

  std::unique_lock&lt;std::mutex&gt; lck(mutex_);
  condVar.wait(lck);
  // do the work
  std::cout &lt;&lt; &quot;Work done.&quot; &lt;&lt; std::endl;

}

void setDataReady() {

  std::cout &lt;&lt; &quot;Sender: Data is ready.&quot; &lt;&lt; std::endl;
  condVar.notify_one();

}

int main() {

  std::cout &lt;&lt; std::endl;

  std::thread t1(setDataReady);
  std::thread t2(waitingForWork);

  t1.join();
  t2.join();

  std::cout &lt;&lt; std::endl;

}
</code></pre>
<p>程序的第一次运行正常，但第二次阻塞是因为通知(第25行)发生在线程<code>t2</code>(第34行)进入等待状态(第16行)之前。</p>
<p><img src="content/The-Details/Multithreading/../../../images/detail/multithreading/21.png" alt="" /></p>
<p>现在就很清楚了，谓词是无状态条件变量，所以等待过程中总是检查谓词。条件变量有两个已知有害现象：未唤醒和伪唤醒。</p>
<h2 id="未唤醒和伪唤醒"><a class="header" href="#未唤醒和伪唤醒">未唤醒和伪唤醒</a></h2>
<p><strong>未唤醒</strong></p>
<p>该现象是发送方在接收方到达其等待状态之前发送通知，结果是通知丢失了。C++标准将条件变量描述为同步机制：“条件变量类是同步原语，可用于阻塞一个线程，或同时阻塞多个线程……”所以通知丢失了，接收者就会持续等待……</p>
<p><strong>伪唤醒</strong></p>
<p>还有一种情况，就会没有发通知，但接收方会被唤醒。使用<a href="https://en.wikipedia.org/wiki/POSIX_Threads">POSIX Threads</a>和 <a href="https://en.wikipedia.org/wiki/Windows_API">Windows API</a>时，都会出现这样的现象。伪唤醒的真相，很可能是本来就没有处于休眠状态。这意味着，在被唤醒的线程有机会运行之前，另一个线程早就等候多时了。</p>
<h2 id="等待线程的工作流程"><a class="header" href="#等待线程的工作流程">等待线程的工作流程</a></h2>
<p>等待线程的工作流程相当复杂。</p>
<p>下面是来自前面示例conditionVariable.cpp的19和20行。</p>
<pre><code class="language-c++">std::unique_lock&lt;std::mutex&gt; lck(mutex_);
condVar.wait(lck, []{ return dataReady; });
</code></pre>
<p>上面两行与下面四行等价：</p>
<pre><code class="language-c++">std::unique_lock&lt;std::mutex&gt; lck(mutex_);
while ( ![]{ return dataReady; }() {
	condVar.wait(lck);
}
</code></pre>
<p>首先，必须区分<code>std::unique_lock&lt;std::mutex&gt; lck(mutex_)</code>的第一次调用与条件变量的通知：<code>condVar.wait(lck)</code>。</p>
<ul>
<li><code>std::unique_lock&lt;std::mutex&gt; lck(mutex_)</code> : 初始化阶段，线程就将互斥量锁定，并对谓词函数<code>[]{ return dataReady;}</code>进行检查。
<ul>
<li>谓词返回值：</li>
<li>true : 线程继续等待。</li>
<li>false : <code>condVar.wait()</code>解锁互斥量，并将线程置为等待(阻塞)状态。</li>
</ul>
</li>
<li><code>condVar.wait(lck)</code> : 如果<code>condition_variable condVar</code>处于等待状态，并获得通知或伪唤醒处于运行状态，则执行以下步骤：
<ul>
<li>线程解除阻塞，重新获得互斥锁。</li>
<li>检查谓词函数。</li>
<li>当谓词函数返回值为：
<ul>
<li>true : 线程继续工作。</li>
<li>false : <code>condVar.wait()</code>解锁互斥量，并将线程置为等待(阻塞)状态。</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>即使共享变量是原子的，也必须在互斥锁保护下进行修改，以便将正确地内容告知等待的线程。</p>
<blockquote>
<p><strong>使用互斥锁来保护共享变量</strong></p>
<p>即使将<code>dataReady</code>设置为原子变量，也必须在互斥锁的保护下进行修改；如果没有，对于等待线程来说<code>dataReady</code>的内容就可能是错的，此竞争条件可能导致死锁。让我们再次查看下等待的工作流，并假设<code>deadReady</code>是一个原子变量，在不受互斥量<code>mutex_</code>保护时进行修改的情况。</p>
<pre><code class="language-c++">std::unique_lock&lt;std::mutex&gt; lck(mutex_);
while ( ![]{ return dataReady.load(); }() {
// time window
condVar.wait(lck);
  }
</code></pre>
<p>假设在条件变量<code>condVar</code>，在不处于等待状态时发送通知。这样，线程执行到第2行和第4行之间时(参见注释时间窗口)会丢失通知。之后，线程返回到等待状态，可能会永远休眠。</p>
<p>如果<code>dataReady</code>被互斥锁保护，就不会发生这种情况。由于与互斥锁能够同步线程，只有在接收线程处于等待状态的情况下才会发送通知。</p>
</blockquote>
<p>大多数用例中，可以使用任务，用简单的方式同步线程。“任务-通知”章节中，将条件变量和任务进行了对比。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="任务-1"><a class="header" href="#任务-1">任务</a></h1>
<p>除了线程之外，C++还有可以异步处理任务，这种方式处理任务需要包含<code>&lt;future&gt;</code>头文件。任务由一个参数化工作包和两个组件组成：promise和future，两者构建一条数据通道。promise执行工作包并将结果放入数据通道，对应的future可以获取结果，两个通信端可以在不同的线程中运行。特别的是future可以在之后的某个时间点获取结果，所以通过promise计算结果与通过future查询结果的步骤是分开的。</p>
<blockquote>
<p><strong>将任务视为通信端间的数据通道</strong></p>
<p>任务的行为类似于通信点之间的数据通道。数据通道的一端称为promise，另一端称为future。这些端点可以存在于相同的线程中，也可以存在于不同的线程中。promise将其结果放入数据通道，future会在晚些时候把结果取走。</p>
</blockquote>
<p><img src="content/The-Details/Multithreading/../../../images/detail/multithreading/22.png" alt="" /></p>
<h2 id="任务-vs-线程"><a class="header" href="#任务-vs-线程">任务 vs. 线程</a></h2>
<p>任务与线程有很大的不同。</p>
<pre><code class="language-c++">// asyncVersusThread.cpp

#include &lt;future&gt;
#include &lt;thread&gt;
#include &lt;iostream&gt;

int main() {

  std::cout &lt;&lt; std::endl;

  int res;
  std::thread t([&amp;] {res = 2000 + 11; });
  t.join();
  std::cout &lt;&lt; &quot;res: &quot; &lt;&lt; res &lt;&lt; std::endl;

  auto fut = std::async([] {return 2000 + 11; });
  std::cout &lt;&lt; &quot;fut.get(): &quot; &lt;&lt; fut.get() &lt;&lt; std::endl;

  std::cout &lt;&lt; std::endl;

}
</code></pre>
<p>线程<code>t</code>和<code>std::async</code>异步调用函数同时计算2000和11的和。主线程通过共享变量<code>res</code>获取其线程<code>t</code>的计算结果，并在第14行中显示它。第16行中，使用<code>std::async</code>在发送方(<code>promise</code>)和接收方(<code>future</code>)之间创建数据通道。future 变量使用<code>fut.get()</code>(第17行)，通过数据通道获得计算结果。<code>fut.get </code>为阻塞调用。</p>
<p>下面是程序输出的结果：</p>
<p><img src="content/The-Details/Multithreading/../../../images/detail/multithreading/23.png" alt="" /></p>
<p>基于这个程序，我想强调线程和任务之间的区别。</p>
<p>任务 vs. 线程</p>
<table><thead><tr><th align="center">标准</th><th align="center">线程</th><th align="center">任务</th></tr></thead><tbody>
<tr><td align="center">构成元素</td><td align="center">创建线程和子线程</td><td align="center">promise和future</td></tr>
<tr><td align="center">通讯方式</td><td align="center">共享变量</td><td align="center">通信通道</td></tr>
<tr><td align="center">创建线程</td><td align="center">必定创建</td><td align="center">可选</td></tr>
<tr><td align="center">同步方式</td><td align="center">通过<code>join()</code>(等待)</td><td align="center">使用<code>get</code>阻塞式调用</td></tr>
<tr><td align="center">线程中的异常</td><td align="center">子线程和创建线程终止</td><td align="center">返回promise的值</td></tr>
<tr><td align="center">通信类型</td><td align="center">变量值</td><td align="center">变量值、通知和异常</td></tr>
</tbody></table>
<p>线程需要包含<code>&lt;thread&gt;</code>头文件，任务需要包含<code>&lt;future&gt;</code>头文件。</p>
<p>创建线程和子线程之间的通信需要使用共享变量，任务通过其隐式的数据通道保护数据通信。因此，任务不需要互斥锁之类的保护机制。</p>
<p>虽然，可以使用共享变量(的可变)来在子线程及其创建线程之间进行通信，但任务的通信方式更为明确。future只能获取一次任务的结果(通过调用<code>fut.get()</code>)，多次调用它会导致未定义的行为(而<code>std::shared_future</code>可以查询多次)。</p>
<p>创建线程需要等待子线程汇入。而使用<code>fut.get()</code>时，该调用将一直阻塞，直到获取结果为止。</p>
<p>如果子线程中抛出异常，创建的线程将终止，创建者和整个进程也将终止。相反，promise可以将异常发送给future，而future必须对异常进行处理。</p>
<p>一个promise可以对应于一个或多个future。它可以发送值、异常，或者只是通知，可以使用它们替换条件变量。</p>
<p><code>std::async </code>是创建future最简单的方法。</p>
<p><strong>std::async</strong></p>
<p><code>std::async</code>的行为类似于异步函数调用，可调用带有参数的函数。<code>std::async</code>是一个可变参数模板，因此可以接受任意数量的参数。对<code>std::async</code>的调用会返回一个future 的对象<code>fut</code>。可以通过<code>fut.get()</code>获得结果。</p>
<blockquote>
<p><strong>std::async应该首选</strong></p>
<p>C++运行时决定<code>std::async</code>是否在独立的线程中执行，决策可能取决于可用的CPU内核的数量、系统的利用率或工作包的大小。通过使用<code>std::async</code>，只需要指定运行的任务，C++运行时会自动管理线程。</p>
</blockquote>
<p>可以指定<code>std::async</code>的启动策略。</p>
<p>##启动策略</p>
<p>使用启动策略，可以显式地指定异步调用应该在同一线程(<code>std::launch::deferred</code>)中执行，还是在不同线程(<code>std::launch::async</code>)中执行。</p>
<blockquote>
<p><strong><a href="content/The-Details/Multithreading/%5Bhttps://zh.wikipedia.org/wiki/%E5%8F%8A%E6%97%A9%E6%B1%82%E5%80%BC%5D(https://zh.wikipedia.org/wiki/%E5%8F%8A%E6%97%A9%E6%B1%82%E5%80%BC)">及早求值</a>与<a href="content/The-Details/Multithreading/%5Bhttps://zh.wikipedia.org/wiki/%E6%83%B0%E6%80%A7%E6%B1%82%E5%80%BC%5D(https://zh.wikipedia.org/wiki/%E6%83%B0%E6%80%A7%E6%B1%82%E5%80%BC)">惰性求值</a></strong></p>
<p>及早求值与惰性求值是计算结果表达式的两种策略。在<a href="https://en.wikipedia.org/wiki/Eager_evaluation">及早求值</a>的情况下，立即计算表达式，而在<a href="https://en.wikipedia.org/wiki/Lazy_evaluation">惰性求值</a> 的情况下，仅在需要时才计算表达式。及早求值通常称为贪婪求值，而惰性求值通常称为按需调用。使用惰性求值，可以节省时间和计算资源。</p>
</blockquote>
<p>调用<code>auto fut = std::async(std::launch::deferred，…)</code>的特殊之处在于，promise可能不会立即执行，调用<code>fut.get()</code>时才执行对应的promise 。这意味着，promise只在future调用<code>fut.get()</code>时计算得到结果。</p>
<pre><code class="language-c++">// asyncLazy.cpp

#include &lt;chrono&gt;
#include &lt;future&gt;
#include &lt;iostream&gt;

int main() {

  std::cout &lt;&lt; std::endl;

  auto begin = std::chrono::system_clock::now();

  auto asyncLazy = std::async(std::launch::deferred,
    [] {return std::chrono::system_clock::now(); });

  auto asyncEager = std::async(std::launch::async,
    [] {return std::chrono::system_clock::now(); });

  std::this_thread::sleep_for(std::chrono::seconds(1));

  auto lazyStart = asyncLazy.get() - begin;
  auto eagerStart = asyncEager.get() - begin;

  auto lazyDuration = std::chrono::duration&lt;double&gt;(lazyStart).count();
  auto eagerDuration = std::chrono::duration&lt;double&gt;(eagerStart).count();

  std::cout &lt;&lt; &quot;asyncLazy evaluated after : &quot; &lt;&lt; lazyDuration
    &lt;&lt; &quot; seconds.&quot; &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;asyncEager  evaluated after : &quot; &lt;&lt; eagerDuration
    &lt;&lt; &quot; seconds.&quot; &lt;&lt; std::endl;

  std::cout &lt;&lt; std::endl;

}
</code></pre>
<p>两个<code>std::async</code>调用(第13行和第16行)都返回当前时间点。但是，第一个调用是<code>lazy</code>，第二个调用是<code>eager</code>。第21行中的<code>asyncLazy.get()</code>调用触发了第13行promise的执行——短睡一秒(第19行)。这对于<code>asyncEager</code>来说是不存在的，<code>asyncEager.get()</code>会立即获取执行结果。</p>
<p>下面就是该程序输出的结果：</p>
<p><img src="content/The-Details/Multithreading/../../../images/detail/multithreading/24.png" alt="" /></p>
<p>不必把future绑定到变量上。</p>
<h2 id="a-hrefcontentthe-detailsmultithreading5bhttpszhwikipediaorgwikie5b084e5be8ce4b88de790865dhttpszhwikipediaorgwikie5b084e5be8ce4b88de79086发后即忘afire-and-forget"><a class="header" href="#a-hrefcontentthe-detailsmultithreading5bhttpszhwikipediaorgwikie5b084e5be8ce4b88de790865dhttpszhwikipediaorgwikie5b084e5be8ce4b88de79086发后即忘afire-and-forget"><a href="content/The-Details/Multithreading/%5Bhttps://zh.wikipedia.org/wiki/%E5%B0%84%E5%BE%8C%E4%B8%8D%E7%90%86%5D(https://zh.wikipedia.org/wiki/%E5%B0%84%E5%BE%8C%E4%B8%8D%E7%90%86)">发后即忘</a>(Fire and Forget)</a></h2>
<p>发后即忘是比较特殊的future。因为其future不受某个变量的约束，所以只是在原地执行。对于一个发后即忘的future，相应的promise运行在一个不同的线程中，所以可以立即开始(这是通过<code>std::launch::async</code>策略完成的)。</p>
<p>我们对普通的future和发后即忘的future进行比较。</p>
<pre><code class="language-c++">auto fut= std::async([]{ return 2011; });
std::cout &lt;&lt; fut.get() &lt;&lt; std::endl;

std::async(std::launch::async,
						[]{ std::cout &lt;&lt; &quot;fire and forget&quot; &lt;&lt; std::endl; });
</code></pre>
<p>发后即忘的future看起来很有美好，但有一个很大的缺点。<code>std::async</code>创建的future会等待promise完成，才会进行析构。这种情况下，等待和阻塞就没有太大的区别了。future的析构函数会中阻塞程序的进程，当使用发后即忘的future时，这一点变得更加明显，看起来程序上是并发的，但实际上是串行运行的。</p>
<pre><code class="language-c++">// fireAndForgetFutures.cpp

#include &lt;chrono&gt;
#include &lt;future&gt;
#include &lt;iostream&gt;
#include &lt;thread&gt;

int main() {

  std::cout &lt;&lt; std::endl;

  std::async(std::launch::async, [] {
    std::this_thread::sleep_for(std::chrono::seconds(2));
    std::cout &lt;&lt; &quot;first thread&quot; &lt;&lt; std::endl;
    });

  std::async(std::launch::async, [] {
    std::this_thread::sleep_for(std::chrono::seconds(2));
    std::cout &lt;&lt; &quot;second thread&quot; &lt;&lt; std::endl; }
  );

  std::cout &lt;&lt; &quot;main thread&quot; &lt;&lt; std::endl;

  std::cout &lt;&lt; std::endl;

}
</code></pre>
<p>程序在线程中执行两个promise，这样就会产生发后即忘的future。future在析构函数中阻塞线程，直到相关的promise完成。promise是按照源代码顺序执行的，执行顺序与执行时间无关。</p>
<p><img src="content/The-Details/Multithreading/../../../images/detail/multithreading/25.png" alt="" /></p>
<p><code>std::async</code>是一种方便的机制，可用于在分解较大的计算任务。</p>
<h2 id="并行计算"><a class="header" href="#并行计算">并行计算</a></h2>
<p>标量乘积的计算可分布在四个异步调用中。</p>
<pre><code class="language-c++">// dotProductAsync.cpp

#include &lt;iostream&gt;
#include &lt;future&gt;
#include &lt;random&gt;
#include &lt;vector&gt;
#include &lt;numeric&gt;

using namespace std;

static const int NUM = 100000000;

long long getDotProduct(vector&lt;int&gt;&amp; v, vector&lt;int&gt;&amp; w) {

  auto vSize = v.size();

  auto future1 = async([&amp;] {
    return inner_product(&amp;v[0], &amp;v[vSize / 4], &amp;w[0], 0LL);
    });

  auto future2 = async([&amp;] {
    return inner_product(&amp;v[vSize / 4], &amp;v[vSize / 2], &amp;w[vSize / 4], 0LL);
    });

  auto future3 = async([&amp;] {
    return inner_product(&amp;v[vSize / 2], &amp;v[vSize * 3 / 4], &amp;w[vSize / 2], 0LL);
    });

  auto future4 = async([&amp;] {
    return inner_product(&amp;v[vSize * 3 / 4], &amp;v[vSize], &amp;w[vSize * 3 / 4], 0LL);
    });

  return future1.get() + future2.get() + future3.get() + future4.get();
}


int main() {

  cout &lt;&lt; endl;

  random_device seed;

  // generator
  mt19937 engine(seed());

  // distribution
  uniform_int_distribution&lt;int&gt; dist(0, 100);

  // fill the vector
  vector&lt;int&gt; v, w;
  v.reserve(NUM);
  w.reserve(NUM);
  for (int i = 0; i &lt; NUM; ++i) {
    v.push_back(dist(engine));
    w.push_back(dist(engine));
  }

  cout &lt;&lt; &quot;getDotProduct(v, w): &quot; &lt;&lt; getDotProduct(v, w) &lt;&lt; endl;

  cout &lt;&lt; endl;

}
</code></pre>
<p>该程序使用了随机库和时间库，创建两个向量<code>v</code>和<code>w</code>并用随机数填充(第50-56行)，每个向量添加(第53 - 56行)1亿个元素。第54和55行中的<code>dist(engine)</code>生成均匀分布在0到100之间的随机数。标量乘积的计算在<code>getDotProduct</code>中进行(第13 - 34行)。内部实现中，<code>std::async</code>使用标准库算法<code>std::inner_product</code>。最后，使用future获取结果进行相加，就得到了最终结果。</p>
<p><img src="content/The-Details/Multithreading/../../../images/detail/multithreading/26.png" alt="" /></p>
<p><code>std::packaged_task</code>通常也用于并发。</p>
<p><strong>std::packaged_task</strong></p>
<p><code>std::packaged_task</code>是用于异步调用的包装器。通过<code>pack.get_future() </code>可以获得相关的future。可以使用可调用操作符<code>pack(pack())</code>执行<code>std::packaged_task</code>。</p>
<p>处理<code>std::packaged_task</code>通常包括四个步骤:</p>
<p>I. 打包:</p>
<pre><code class="language-c++">std::packaged_task&lt;int(int, int)&gt; sumTask([](int a, int b){ return a + b; });
</code></pre>
<p>II. 创建future:</p>
<pre><code class="language-c++">std::future&lt;int&gt; sumResult= sumTask.get_future();
</code></pre>
<p>III. 执行计算:</p>
<pre><code class="language-c++">sumTask(2000, 11);
</code></pre>
<p>IV. 查询结果:</p>
<pre><code class="language-c++">sumResult.get();
</code></pre>
<p>下面的示例，展示了这四个步骤。</p>
<pre><code class="language-c++">// packagedTask.cpp

#include &lt;utility&gt;
#include &lt;future&gt;
#include &lt;iostream&gt;
#include &lt;thread&gt;
#include &lt;deque&gt;

class SumUp {
public:
  int operator()(int beg, int end) {
    long long int sum{ 0 };
    for (int i = beg; i &lt; end; ++i) sum += i;
    return static_cast&lt;int&gt;(sum);
  }
};

int main() {

  std::cout &lt;&lt; std::endl;

  SumUp sumUp1;
  SumUp sumUp2;
  SumUp sumUp3;
  SumUp sumUp4;

  // wrap the task
  std::packaged_task&lt;int(int, int)&gt; sumTask1(sumUp1);
  std::packaged_task&lt;int(int, int)&gt; sumTask2(sumUp2);
  std::packaged_task&lt;int(int, int)&gt; sumTask3(sumUp3);
  std::packaged_task&lt;int(int, int)&gt; sumTask4(sumUp4);

  // create the futures
  std::future&lt;int&gt; sumResult1 = sumTask1.get_future();
  std::future&lt;int&gt; sumResult2 = sumTask2.get_future();
  std::future&lt;int&gt; sumResult3 = sumTask3.get_future();
  std::future&lt;int&gt; sumResult4 = sumTask4.get_future();

  // push the task on the container
  std::deque&lt;std::packaged_task&lt;int(int, int)&gt;&gt; allTasks;
  allTasks.push_back(std::move(sumTask1));
  allTasks.push_back(std::move(sumTask2));
  allTasks.push_back(std::move(sumTask3));
  allTasks.push_back(std::move(sumTask4));

  int begin{ 1 };
  int increment{ 2500 };
  int end = begin + increment;

  // preform each calculation in a separate thread
  while (!allTasks.empty()) {
    std::packaged_task&lt;int(int, int)&gt; myTask = std::move(allTasks.front());
    allTasks.pop_front();
    std::thread sumThread(std::move(myTask), begin, end);
    begin = end;
    end += increment;
    sumThread.detach();
  }
  
  // pick up the results
  auto sum = sumResult1.get() + sumResult2.get() +
    sumResult3.get() + sumResult4.get();

  std::cout &lt;&lt; &quot;sum of 0 .. 10000 = &quot; &lt;&lt; sum &lt;&lt; std::endl;

  std::cout &lt;&lt; std::endl;

}
</code></pre>
<p>这段程序的是计算从0到10000的整数和。创建四个<code>std::packaged_task</code>的对象，并且每个<code>std::packaged_task</code>有自己的线程，并使用future来汇总结果。当然，也可以直接使用<a href="https://de.wikipedia.org/wiki/Gau%C3%9Fsche_Summenformel">Gaußschen Summenformel</a>(高斯求和公式)。真奇怪，我没有找到英文网页。(译者注：打开网页就是最熟悉的高斯求和公式，也就是<a href="content/The-Details/Multithreading/%5Bhttps://baike.baidu.com/item/%E9%AB%98%E6%96%AF%E7%AE%97%E6%B3%95/4727683%5D(https://baike.baidu.com/item/%E9%AB%98%E6%96%AF%E7%AE%97%E6%B3%95/4727683)">等差数列求和公式</a>。翻了下维基百科，确实没有相关的英文页面。)</p>
<p><strong>I. 打包任务</strong>：程序将工作包打包进<code>std::packaged_task</code>(第28 - 31行)的实例中，工作包就是<code>SumUp</code>的实例(第9 - 16行)，使用函数操作符完成任务(第11 - 15行)。函数操作符将<code>beg</code>到<code>end - 1</code>的所有整数相加并返回结果。第28 - 31行中的<code>std::packaged_task</code>实例可以处理需要两个<code>int</code>参数的函数调用，并返回一个<code>int: int(int, int)</code>类型的任务包。</p>
<p><strong>II.创建future</strong>：第34到37行中，使用<code>std::packaged_task</code>创建future对象，这时<code>std::packaged_task</code>对象属于通信通道中的promise。future的类型有明确定义：<code>std::future&lt;int&gt; sumResult1 = sumTask1.get_future()</code>，也可以让编译器来确认future的具体类型：<code>auto  sumResult1 sumTask1.get_future()</code>。</p>
<p><strong>III. 进行计算</strong>：开始计算。将任务包移动到<a href="http://en.cppreference.com/w/cpp/container/deque"><code>std::deque</code></a>(第40 - 44行)中，while循环(第51 - 58行)会执行每个任务包。为此，将<code>std::deque</code>的队头任务包移动到一个<code>std::packaged_task</code>实例中(第52行)，并将这个实例移动到一个新线程中(第54行)，并让这个线程在后台运行(第57行)。因为<code>packaged_task</code>对象不可复制的，所以会在52和54行中使用<code>move</code>语义。这个限制不仅适用于所有的promise实例，但也适用于future和线程实例。但有一个例外：<code>std::shared_future</code>。</p>
<p><strong>IV. 查询结果</strong>：最后一步中，从每个future获取计算的结果，并把它们加起来(第61行)。</p>
<p><img src="content/The-Details/Multithreading/../../../images/detail/multithreading/27.png" alt="" /></p>
<p>下表展示<code>std::packaged_task pack</code>的接口</p>
<table><thead><tr><th align="center">成员函数</th><th align="center">函数描述</th></tr></thead><tbody>
<tr><td align="center"><code>pack.swap(pack2)</code>和<code>std::swap(pack, pack2)</code></td><td align="center">交换对象</td></tr>
<tr><td align="center"><code>pack.valid()</code></td><td align="center">检查对象中的函数是否合法</td></tr>
<tr><td align="center"><code>pack.get_future()</code></td><td align="center">返回future</td></tr>
<tr><td align="center"><code>pack.make_ready_at_thread_exit(ex)</code></td><td align="center">执行的函数，如果线程还存在，那么结果还是可用的</td></tr>
<tr><td align="center"><code>pack.reset()</code></td><td align="center">重置任务的状态，擦除之前执行的结果</td></tr>
</tbody></table>
<p>与<code>std::async</code>或<code>std::promise</code>相比，<code>std::packaged_task</code>可以复位并重复使用。下面的程序展示了<code>std::packaged_task</code>的“特殊”使用方式。</p>
<pre><code class="language-c++">// packagedTaskReuse.cpp

#include &lt;functional&gt;
#include &lt;future&gt;
#include &lt;iostream&gt;
#include &lt;utility&gt;
#include &lt;vector&gt;

void calcProducts(std::packaged_task&lt;int(int, int)&gt;&amp; task,
  const std::vector&lt;std::pair&lt;int, int&gt;&gt;&amp; pairs) {
  for (auto&amp; pair : pairs) {
    auto fut = task.get_future();
    task(pair.first, pair.second);
    std::cout &lt;&lt; pair.first &lt;&lt; &quot; * &quot; &lt;&lt; pair.second &lt;&lt; &quot; = &quot; &lt;&lt; fut.get()&lt;&lt;
      std::endl;
    task.reset();
  }
}

int main() {

  std::cout &lt;&lt; std::endl;

  std::vector&lt;std::pair&lt;int, int&gt;&gt; allPairs;
  allPairs.push_back(std::make_pair(1, 2));
  allPairs.push_back(std::make_pair(2, 3));
  allPairs.push_back(std::make_pair(3, 4));
  allPairs.push_back(std::make_pair(4, 5));

  std::packaged_task&lt;int(int, int)&gt; task{ [](int fir, int sec) {
    return fir * sec; }
  };

  calcProducts(task, allPairs);

  std::cout &lt;&lt; std::endl;
  
  std::thread t(calcProducts, std::ref(task), allPairs);
  t.join();

  std::cout &lt;&lt; std::endl;

}
</code></pre>
<p>函数<code>calcProduct</code>(第9行)有两个参数：<code>task</code>和<code>pairs</code>。使用任务包<code>task</code>来计算<code>pairs</code>中的每个整数对的乘积(第13行)，并在第16行重置任务<code>task</code>。这样，<code>calcProduct</code>就能在主线程(第34行)和另外开启的线程(第38行)中运行。下面是程序的输出。</p>
<p><img src="content/The-Details/Multithreading/../../../images/detail/multithreading/28.png" alt="" /></p>
<p><strong>std::promise和std::future</strong></p>
<p><code>std::promise</code>和<code>std::future</code>可以完全控制任务。</p>
<p>promise和future是一对强有力的组合。promise可以将值、异常或通知放入数据通道。一个promise可以对应多个<code>std::shared_future</code>对象。</p>
<p>下面是<code>std::promise</code>和<code>std::future</code>用法的示例。两个通信端点都可以在不同的的线程中，因此通信可以在线程间发生。</p>
<pre><code class="language-c++">// promiseFuture.cpp

#include &lt;future&gt;
#include &lt;iostream&gt;
#include &lt;thread&gt;
#include &lt;utility&gt;

void product(std::promise&lt;int&gt;&amp;&amp; intPromise, int a, int b) {
  intPromise.set_value(a * b);
}

struct Div {

  void operator()(std::promise&lt;int&gt;&amp;&amp; intPromise, int a, int b) const {
    intPromise.set_value(a / b);
  }

};

int main() {
  
  int a = 20;
  int b = 10;

  std::cout &lt;&lt; std::endl;

  // define the promises
  std::promise&lt;int&gt; prodPromise;
  std::promise&lt;int&gt; divPromise;

  // get the futures
  std::future&lt;int&gt; prodResult = prodPromise.get_future();
  std::future&lt;int&gt; divResult = divPromise.get_future();

  // calculate the result in a separate thread
  std::thread prodThread(product, std::move(prodPromise), a, b);
  Div div;
  std::thread divThread(div, std::move(divPromise), a, b);

  // get the result
  std::cout &lt;&lt; &quot;20*10 = &quot; &lt;&lt; prodResult.get() &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;20/10 = &quot; &lt;&lt; divResult.get() &lt;&lt; std::endl;

  prodThread.join();

  divThread.join();

  std::cout &lt;&lt; std::endl;

}
</code></pre>
<p>将函数<code>product</code>(第8 -10行)、<code>prodPromise</code>(第32行)以及数字<code>a</code>和<code>b</code>放入线程<code>Thread prodThread</code>(第36行)中。<code>prodThread</code>的第一个参数需要一个可调用的参数，上面程序中就是函数乘积函数。函数需要一个类型右值引用的promise(<code>std::promise&lt;int&gt;&amp;&amp; intPromise</code>)和两个数字。<code>std::move</code>(第36行)创建一个右值引用。剩下的就简单了，<code>divThread</code>(第38行)将<code>a</code>和<code>b</code>分开传入。</p>
<p>future通过<code>prodResult.get()</code>和<code>divResult.get()</code>获取结果</p>
<p><img src="content/The-Details/Multithreading/../../../images/detail/multithreading/29.png" alt="" /></p>
<p><strong>std::promise</strong></p>
<p><code>std::promise</code>允许设置一个值、一个通知或一个异常。此外，promise可以以延迟的方式提供结果。</p>
<p><code>std::promise prom</code>的成员函数</p>
<table><thead><tr><th align="center">成员函数</th><th align="center">函数描述</th></tr></thead><tbody>
<tr><td align="center"><code>prom.swap(prom2)</code>和<code>std::swap(prom, prom2)</code></td><td align="center">交换对象</td></tr>
<tr><td align="center"><code>prom.get_future()</code></td><td align="center">返回future</td></tr>
<tr><td align="center"><code>prom.set_value(val)</code></td><td align="center">设置值</td></tr>
<tr><td align="center"><code>prom.set_exception(ex)</code></td><td align="center">设置异常</td></tr>
<tr><td align="center"><code>prom.set_value_at_thread_exit(val)</code></td><td align="center">promise退出前存储该值</td></tr>
<tr><td align="center"><code>prom.set_exception_at_thread_exit(ex)</code></td><td align="center">promise退出前存储该异常</td></tr>
</tbody></table>
<p>如果多次对promise设置值或异常，则会抛出<code>std::future_error</code>。</p>
<p><strong>std::future</strong></p>
<p><code>std::future</code>可以完成的事情有：</p>
<ul>
<li>从promise中获取值。</li>
<li>查询promise值是否可获取。</li>
<li>等待promise通知，这种等待可以用一个时间段或一个绝对的时间点来完成。</li>
<li>创建共享future(<code>std::shared_future</code>)。</li>
</ul>
<p>future实例<code>fut</code>的成员函数</p>
<table><thead><tr><th align="center">成员函数</th><th align="center">函数描述</th></tr></thead><tbody>
<tr><td align="center"><code>fut.share()</code></td><td align="center">返回<code>std::shared_future</code></td></tr>
<tr><td align="center"><code>fut.get()</code></td><td align="center">返回可以是值或异常</td></tr>
<tr><td align="center"><code>fut.valid()</code></td><td align="center">检查当前实例是否可用调用<code>fut.get()</code>。使用get()之后，返回false</td></tr>
<tr><td align="center"><code>fut.wait()</code></td><td align="center">等待结果</td></tr>
<tr><td align="center"><code>fut.wait_for(relTime)</code></td><td align="center">在<code>relTime</code>时间段内等待获取结果，并返回<code>std:: future_status</code>实例</td></tr>
<tr><td align="center"><code>fut.wait_until(absTime)</code></td><td align="center">在<code>absTime</code>时间点前等待获取结果，并返回<code>std:: future_status</code>实例</td></tr>
</tbody></table>
<p>与<code>wait</code>不同，<code>wait_for</code>和<code>wait_until</code>会返回future的状态。</p>
<p><strong>std::future_status</strong></p>
<p>future和共享future的<code>wait_for</code>和<code>wait_until</code>成员函数将返回其状态。有三种可能:</p>
<pre><code class="language-c++">enum class future_status {
  ready,
  timeout,
  deferred
};	
</code></pre>
<p>下表描述了每种状态:</p>
<table><thead><tr><th align="center">状态</th><th align="center">描述</th></tr></thead><tbody>
<tr><td align="center">deferred</td><td align="center">函数还未运行</td></tr>
<tr><td align="center">ready</td><td align="center">结果已经准备就绪</td></tr>
<tr><td align="center">timeout</td><td align="center">结果超时得到，视为过期</td></tr>
</tbody></table>
<p>使用<code>wait_for</code>或<code>wait_until</code>可以一直等到相关的promise完成。</p>
<pre><code class="language-c++">// waitFor.cpp

#include &lt;iostream&gt;
#include &lt;future&gt;
#include &lt;thread&gt;
#include &lt;chrono&gt;

using namespace std::literals::chrono_literals;

void getAnswer(std::promise&lt;int&gt; intPromise) {
  std::this_thread::sleep_for(3s);
  intPromise.set_value(42);
}

int main() {

  std::cout &lt;&lt; std::endl;

  std::promise&lt;int&gt; answerPromise;
  auto fut = answerPromise.get_future();

  std::thread prodThread(getAnswer, std::move(answerPromise));

  std::future_status status{};
  do {
    status = fut.wait_for(0.2s);
    std::cout &lt;&lt; &quot;... doing something else&quot; &lt;&lt; std::endl;
  } while (status != std::future_status::ready);

  std::cout &lt;&lt; std::endl;

  std::cout &lt;&lt; &quot;The Answer: &quot; &lt;&lt; fut.get() &lt;&lt; '\n';

  prodThread.join();

  std::cout &lt;&lt; std::endl;
}
</code></pre>
<p>在future<code>fut</code>在等待promise时，可以执行其他操作。</p>
<p><img src="content/The-Details/Multithreading/../../../images/detail/multithreading/30.png" alt="" /></p>
<p>如果多次获取future<code>fut</code>的结果，会抛出<code>std::future_error</code>异常。</p>
<p>promise和future是一对一的关系，而<code>std::shared_future</code>支持一个promise 对应多个future。</p>
<p><strong>std::shared_future</strong></p>
<p>创建<code>std::shared_future </code>的两种方式：</p>
<ol>
<li>通过promise实例<code>prom</code>创建<code>std::shared_future</code>:<code> std::shared_future&lt;int&gt; fut = prom.get_future()</code>。</li>
<li>使用<code>fut</code>的<code>fut.share()</code>进行创建。执行了<code>fut.share()</code>后，<code>fut.valid()</code>会返回false。</li>
</ol>
<p>共享future是与相应的promise相关联的，可以获取promise的结果。共享future与<code>std::future</code>有相同的接口。</p>
<p>除了有<code>std::future</code>的功能外，<code>std::shared_future</code>还允许和其他future查询关联promise的值。</p>
<p><code>std::shared_future</code>的操作很特殊，下面的代码中就直接创建了一个<code>std::shared_future</code>。</p>
<pre><code class="language-c++">// sharedFuture.cpp

#include &lt;future&gt;
#include &lt;iostream&gt;
#include &lt;thread&gt;
#include &lt;utility&gt;

std::mutex coutMutex;

struct Div {

  void operator()(std::promise&lt;int&gt;&amp;&amp; intPromise, int a, int b) {
    intPromise.set_value(a / b);
  }

};

struct Requestor {

  void operator()(std::shared_future&lt;int&gt; shaFut) {

    // lock std::cout
    std::lock_guard&lt;std::mutex&gt; coutGuard(coutMutex);

    // get the thread id
    std::cout &lt;&lt; &quot;threadId(&quot; &lt;&lt; std::this_thread::get_id() &lt;&lt; &quot;): &quot;;

    std::cout &lt;&lt; &quot;20/10= &quot; &lt;&lt; shaFut.get() &lt;&lt; std::endl;

  }

};

int main() {

  std::cout &lt;&lt; std::endl;

  // define the promises
  std::promise&lt;int&gt; divPromise;

  // get the futures
  std::shared_future&lt;int&gt; divResult = divPromise.get_future();

  // calculate the result in a separate thread
  Div div;
  std::thread divThread(div, std::move(divPromise), 20, 10);

  Requestor req;
  std::thread sharedThread1(req, divResult);
  std::thread sharedThread2(req, divResult);
  std::thread sharedThread3(req, divResult);
  std::thread sharedThread4(req, divResult);
  std::thread sharedThread5(req, divResult);

  divThread.join();

  sharedThread1.join();
  sharedThread2.join();
  sharedThread3.join();
  sharedThread4.join();
  sharedThread5.join();

  std::cout &lt;&lt; std::endl;

}
</code></pre>
<p>promise和future的工作包都是函数对象。第46行中将<code>divPromise</code>移动到线程<code>divThread</code>中执行，因此会将<code>std::shared_future</code>复制到5个线程中(第49 - 53行)。与只能移动的<code>std::future</code>对象不同，可以<code>std::shared_future</code>对象可以进行复制。</p>
<p>主线程在第57到61行等待子线程完成它们的任务。</p>
<p><img src="content/The-Details/Multithreading/../../../images/detail/multithreading/31.png" alt="" /></p>
<p>前面提到过，可以通过使用<code>std::future</code>的成员函数创建<code>std::shared_future</code>。我们把上面的代码改一下。</p>
<pre><code class="language-c++">// sharedFutureFromFuture.cpp

#include &lt;future&gt;
#include &lt;iostream&gt;
#include &lt;thread&gt;
#include &lt;utility&gt;

std::mutex coutMutex;

struct Div {

  void operator()(std::promise&lt;int&gt;&amp;&amp; intPromise, int a, int b) {
    intPromise.set_value(a / b);
  }

};

struct Requestor {

  void operator()(std::shared_future&lt;int&gt; shaFut) {

    // lock std::cout
    std::lock_guard&lt;std::mutex&gt; coutGuard(coutMutex);

    // get the thread id
    std::cout &lt;&lt; &quot;threadId(&quot; &lt;&lt; std::this_thread::get_id() &lt;&lt; &quot;): &quot;;

    std::cout &lt;&lt; &quot;20/10= &quot; &lt;&lt; shaFut.get() &lt;&lt; std::endl;

  }

};

int main() {

  std::cout &lt;&lt; std::boolalpha &lt;&lt; std::endl;

  // define the promises
  std::promise&lt;int&gt; divPromise;

  // get the futures
  std::future&lt;int&gt; divResult = divPromise.get_future();

  std::cout &lt;&lt; &quot;divResult.valid(): &quot; &lt;&lt; divResult.valid() &lt;&lt; std::endl;

  // calculate the result in a separate thread
  Div div;
  std::thread divThread(div, std::move(divPromise), 20, 10);

  std::cout &lt;&lt; &quot;divResult.valid(): &quot; &lt;&lt; divResult.valid() &lt;&lt; std::endl;

  std::shared_future&lt;int&gt; sharedResult = divResult.share();

  std::cout &lt;&lt; &quot;divResult.valid(): &quot; &lt;&lt; divResult.valid() &lt;&lt; &quot;\n\n&quot;;

  Requestor req;
  std::thread sharedThread1(req, sharedResult);
  std::thread sharedThread2(req, sharedResult);
  std::thread sharedThread3(req, sharedResult);
  std::thread sharedThread4(req, sharedResult);
  std::thread sharedThread5(req, sharedResult);

  divThread.join();

  sharedThread1.join();
  sharedThread2.join();
  sharedThread3.join();
  sharedThread4.join();
  sharedThread5.join();

  std::cout &lt;&lt; std::endl;

}
</code></pre>
<p><code>std::future</code>(第44行和第50行)前两次调用<code>divResult.valid()</code>都返回true。第52行执行<code>divResult.share()</code>之后，因为该操作使得状态转换为共享，所以在执行到第54行时，程序会返回false。</p>
<p><img src="content/The-Details/Multithreading/../../../images/detail/multithreading/32.png" alt="" /></p>
<h2 id="异常"><a class="header" href="#异常">异常</a></h2>
<p>如果<code>std::async</code>或<code>std::packaged_task</code>的工作包抛出错误，则异常会存储在共享状态中。当future<code>fut</code>调用<code>fut.get()</code>时，异常将重新抛出。</p>
<p><code>std::promise prom</code>提供了相同的功能，但是它有一个成员函数<code>prom.set_value(std::current_exception())</code>可以将异常设置为共享状态。</p>
<p>数字除以0是未定义的行为，函数<code>executeDivision</code>显示计算结果或异常。</p>
<pre><code class="language-c++">// promiseFutureException.cpp

#include &lt;exception&gt;
#include &lt;future&gt;
#include &lt;iostream&gt;
#include &lt;thread&gt;
#include &lt;utility&gt;

#ifdef WIN32
#include &lt;string&gt;
#endif

struct Div {
  void operator()(std::promise&lt;int&gt;&amp;&amp; intPromise, int a, int b){
    try {
      if (b == 0) {
        std::string errMess = std::string(&quot;Illegal division by zero: &quot;) +
          std::to_string(a) + &quot;/&quot; + std::to_string(b);
        throw std::runtime_error(errMess);
      }
      intPromise.set_value(a / b);
    }
    catch (...) {
      intPromise.set_exception(std::current_exception());
    }
  }
};

void executeDivision(int nom, int denom) {
  std::promise&lt;int&gt; divPromise;
  std::future&lt;int&gt; divResult = divPromise.get_future();

  Div div;
  std::thread divThread(div, std::move(divPromise), nom, denom);

  // get the result or the exception
  try {
    std::cout &lt;&lt; nom &lt;&lt; &quot;/&quot; &lt;&lt; denom &lt;&lt; &quot; = &quot; &lt;&lt; divResult.get() &lt;&lt; std::endl;
  }
  catch (std::runtime_error&amp; e) {
    std::cout &lt;&lt; e.what() &lt;&lt; std::endl;
  }

  divThread.join();
}

int main() {

  std::cout &lt;&lt; std::endl;

  executeDivision(20, 0);
  executeDivision(20, 10);

  std::cout &lt;&lt; std::endl;

}
</code></pre>
<p>这个程序中，promise会处理分母为0的情况。如果分母为0，则在第24行中将异常设置为返回值：<code>intPromise.set_exception(std::current_exception())</code>。future需要在try-catch中处理异常(第37 - 42行)。</p>
<p>下面是程序的输出。</p>
<p><img src="content/The-Details/Multithreading/../../../images/detail/multithreading/33.png" alt="" /></p>
<blockquote>
<p><strong>std::current_exception和std::make_exception_ptr</strong></p>
<p><code>std::current_exception()</code>捕获当前异常对象，并创建一个
<code>std:: exception_ptr</code>。<code>std::exception_ptr</code>保存异常对象的副本或引用。如果在没有异常处理时调用该函数，则返回一个空的<a href="http://en.cppreference.com/w/cpp/error/current_exception"><code>std::exception_ptr</code></a>。</p>
<p>为了不在try/catch中使用<code>intPromise.set_exception(std::current_exception())</code>检索抛出的异常，可以直接调用<code>intPromise.set_exception(std::make_exception_ptr(std::runtime_error(errMess)))</code>。</p>
</blockquote>
<p>如果在<code>std::promise</code>销毁之前没有调用设置类的成员函数，或是在<code>std::packaged_task</code>调用它，那么<code>std::future_error</code>异常和错误代码<code>std::future_errc::broken_promise</code>将存储在共享future中。</p>
<h2 id="通知"><a class="header" href="#通知">通知</a></h2>
<p>任务是条件变量的一种替代方式。如果使用promise和future来同步线程，它们与条件变量有很多相同之处。大多数时候，promise和future是更好的选择。</p>
<p>在看例子之前，先了解下任务和条件变量的差异。</p>
<table><thead><tr><th align="center">对比标准</th><th align="center">条件变量</th><th align="center">任务</th></tr></thead><tbody>
<tr><td align="center">多重同步</td><td align="center">Yes</td><td align="center">No</td></tr>
<tr><td align="center">临界区保护</td><td align="center">Yes</td><td align="center">No</td></tr>
<tr><td align="center">接收错误处理机制</td><td align="center">No</td><td align="center">Yes</td></tr>
<tr><td align="center">伪唤醒</td><td align="center">Yes</td><td align="center">No</td></tr>
<tr><td align="center">未唤醒</td><td align="center">Yes</td><td align="center">No</td></tr>
</tbody></table>
<p>与promise和future相比，条件变量的优点是可以多次同步线程，而promise只能发送一次通知，因此必须使用更多promise和future对，才能模拟出条件变量的功能。如果只同步一次，那条件变量正确的使用方式或许将更具大的挑战。promise和future对不需要共享变量，所以不需要锁，并且不大可能出现伪唤醒或未唤醒的情况。除了这些，任务还可以处理异常。所以，在同步线程上我会更偏重于选择任务，而不是条件变量。</p>
<p>还记得使用条件变量有多难吗？如果忘记了，这里展示了两个线程同步所需的关键部分。</p>
<pre><code class="language-c++">void waitingForWork(){
  std::cout &lt;&lt; &quot;Worker: Waiting for work.&quot; &lt;&lt; std::endl;
  
  std::unique_lock&lt;std::mutex&gt; lck(mutex_);
  condVar.wait(lck, []{ return dataReady; });
  doTheWork();
  std::cout &lt;&lt; &quot;Work done.&quot; &lt;&lt; std::endl;
}

void setDataReady(){
  std::lock_guard&lt;std::mutex&gt; lck(mutex_);
  dataReady=true;
  std::cout &lt;&lt; &quot;Sender: Data is ready.&quot; &lt;&lt; std::endl;
  condVar.notify_one();
}
</code></pre>
<p>函数<code>setDataReady</code>为同步通知，函数<code>waitingForWork</code>为同步等待。</p>
<p>使用任务完成相同的工作流程。</p>
<pre><code class="language-c++">// promiseFutureSynchronise.cpp

#include &lt;future&gt;
#include &lt;iostream&gt;
#include &lt;utility&gt;


void doTheWork() {
  std::cout &lt;&lt; &quot;Processing shared data.&quot; &lt;&lt; std::endl;
}

void waitingForWork(std::future&lt;void&gt;&amp;&amp; fut) {

  std::cout &lt;&lt; &quot;Worker: Waiting for work.&quot; &lt;&lt; std::endl;
  fut.wait();
  doTheWork();
  std::cout &lt;&lt; &quot;Work done.&quot; &lt;&lt; std::endl;

}

void setDataReady(std::promise&lt;void&gt;&amp;&amp; prom) {

  std::cout &lt;&lt; &quot;Sender: Data is ready.&quot; &lt;&lt; std::endl;
  prom.set_value();

}

int main() {

  std::cout &lt;&lt; std::endl;

  std::promise&lt;void&gt; sendReady;
  auto fut = sendReady.get_future();

  std::thread t1(waitingForWork, std::move(fut));
  std::thread t2(setDataReady, std::move(sendReady));

  t1.join();
  t2.join();

  std::cout &lt;&lt; std::endl;

}
</code></pre>
<p>是不是非常简单？</p>
<p>通过<code>sendReady</code>(第32行)获得了一个future<code>fut</code>(第33行)，promise使用其返回值<code>void (std::promise&lt;void&gt; sendReady)</code>进行通信，并且只能够发送通知。两个通信端点分别移动到线程<code>t1</code>和<code>t2</code>中(第35行和第36行)，调用<code>fut.wait()</code>(第15行)等待promise的通知(<code>prom.set_value()</code>(第24行))。</p>
<p>程序结构和输出，与条件变量章节程序的输出一致。</p>
<p><img src="content/The-Details/Multithreading/../../../images/detail/multithreading/34.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="标准库的并行算法"><a class="header" href="#标准库的并行算法">标准库的并行算法</a></h1>
<p>标准模板库有100多种搜索、计数和范围操作算法。C++17中，重载了69个，并新添加了8个。这些重载版本和新算法，可以使用执行策略来调用。</p>
<p><img src="content/The-Details/Parallel-Algorithms-of-the-Standard/../../../images/detail/Parallel-Algorithms-of-the-Standard/1.png" alt="" /></p>
<p>执行策略可以指定算法串行、并行，还是向量化并行。使用执行策略时，需要包含头文件<code>&lt;execution&gt;</code>。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="执行策略-1"><a class="header" href="#执行策略-1">执行策略</a></h1>
<p>C++17标准中定义了三种执行策略:</p>
<ul>
<li><code>std::execution::sequenced_policy</code></li>
<li><code>std::execution::parallel_policy</code></li>
<li><code>std::execution::parallel_unsequenced_policy</code></li>
</ul>
<p>(译者注：C++20中添加了<code>unsequenced_policy</code>策略)</p>
<p>相应的策略标定了程序应该串行、并行，还是与向量化并行。</p>
<ul>
<li><code>std::execution::seq </code>: 串行执行</li>
<li><code>std::execution::par </code>: 多线程并行执行</li>
<li><code>std::execution::par_unseq</code>: 多个线程上并行，可以循环交叉，也能使用<a href="https://en.wikipedia.org/wiki/SIMD">SIMD</a>(单指令多数据)</li>
</ul>
<p><code>std::execution::par</code>或<code>std::execution::par_unseq</code>允许算法并行或向量化并行。</p>
<p>下面的代码片段展示了所有执行策略的使用方式。</p>
<pre><code class="language-c++">
#include &lt;execution&gt;
#include &lt;vector&gt;
#include &lt;algorithm&gt;

int main() {
  
  std::vector&lt;int&gt; v = { 1, 2, 3, 4, 5, 6, 7, 8, 9 };

  // standard sequential sort
  std::sort(v.begin(), v.end());

  // sequential execution
  std::sort(std::execution::seq, v.begin(), v.end());
                    
  // permitting parallel execution
  std::sort(std::execution::par, v.begin(), v.end());

  //permitting parallel and vectorized execution
  std::sort(std::execution::par_unseq, v.begin(), v.end());

}
</code></pre>
<p>示例中，可以使用经典的<code>std::sort</code>(第11行)。C++17中，可以明确指定使用方式：串行(第14行)、并行(第17行)，还是向量化并行(第20行)。</p>
<p><code>std::is_execution_policy</code>可以检查模板参数<code>T</code>是标准数据类型，还是执行策略类型：<code>std::is_execution_policy&lt;T&gt;::value</code>。如果<code>T</code>是<code>std::execution::sequenced_policy</code>, <code>std::execution::parallel_policy</code>, <code>std::execution::parallel_unsequenced_policy</code>，或已定义的执行策略类型，则表达式结果为true；否则，为false。</p>
<h2 id="并行和向量化执行"><a class="header" href="#并行和向量化执行">并行和向量化执行</a></h2>
<p>算法是否以并行和向量化的方式运行，取决于许多因素。例如：CPU和编译器是否支持SIMD指令，还取决于编译器实现和代码的优化级别。</p>
<p>下面的示例使用循环填充数组。</p>
<pre><code class="language-c++">
#include &lt;iostream&gt;

const int SIZE = 8;

int vec[] = { 1, 2, 3, 4, 5, 6, 7, 8 };
int res[] = { 0, 0, 0, 0, 0, 0, 0, 0 };

int main() {

  for (int i = 0; i &lt; SIZE; ++i) {
    res[i] = vec[i] + 5;
  }

  for (int i = 0; i &lt; SIZE; ++i) {
    std::cout &lt;&lt; res[i] &lt;&lt; &quot; &quot;;
  }
  std::cout &lt;&lt; std::endl;

}
</code></pre>
<p>第12行是这个示例中的关键。我们可以在<a href="https://godbolt.org">compiler explorer</a>看一下clang 3.6生成的相应汇编指令。</p>
<p><strong>无优化</strong></p>
<p>汇编指令中，每个加法都是串行进行的。</p>
<p><img src="content/The-Details/Parallel-Algorithms-of-the-Standard/../../../images/detail/Parallel-Algorithms-of-the-Standard/2.png" alt="" /></p>
<p><strong>使用最高优化级别</strong></p>
<p>通过使用最高的优化级别<code>-O3</code>，寄存器(如：xmm0)可以容纳128位，或者说是4个整型数字。这样，加法就可以同时在四个元素进行了。</p>
<p><img src="content/The-Details/Parallel-Algorithms-of-the-Standard/../../../images/detail/Parallel-Algorithms-of-the-Standard/3.png" alt="" /></p>
<p>无执行策略算法的重载，与具有串行执行策略<code>std::execution::seq</code>算法的重载在<strong>异常</strong>处理方面有所不同。</p>
<p>##异常</p>
<p>如果执行策略的算法发生异常，将调用<a href="https://en.cppreference.com/w/cpp/error/terminate"><code>std::terminate</code></a>。<code>std::terminate</code>调用<a href="https://en.cppreference.com/w/cpp/error/terminate_handler"><code>std::terminate_handler</code></a>，之后使用<a href="https://en.cppreference.com/w/cpp/utility/program/abort"><code>std::abort</code></a>，让异常程序终止。执行策略的算法与调用<code>std::execution::seq</code>执行策略的算法之间没有区别。无执行策略的算法会传播异常，因此可以对异常进行处理。exceptionExecutionPolicy.cpp可以佐证我的观点。</p>
<pre><code class="language-c++">// exceptionExecutionPolicy.cpp

#include &lt;algorithm&gt;
#include &lt;execution&gt;
#include &lt;iostream&gt;
#include &lt;stdexcept&gt;
#include &lt;string&gt;
#include &lt;vector&gt;

int main() {

  std::cout &lt;&lt; std::endl;

  std::vector&lt;int&gt; myVec{ 1,2,3,4,5 };

  try {
    std::for_each(myVec.begin(), myVec.end(),
      [](int) {throw std::runtime_error(&quot;Without  execution policy&quot;); }
    );
  }
  catch (const std::runtime_error &amp; e) {
    std::cout &lt;&lt; e.what() &lt;&lt; std::endl;
  }

  try {
    std::for_each(std::execution::seq, myVec.begin(), myVec.end(),
      [](int) {throw std::runtime_error(&quot;With execution policy&quot;); }
    );
  }
  catch (const std::runtime_error &amp; e) {
    std::cout &lt;&lt; e.what() &lt;&lt; std::endl;
  }
  catch (...) {
    std::cout &lt;&lt; &quot;Catch-all exceptions&quot; &lt;&lt; std::endl;
  }

}
</code></pre>
<p>第21行可以捕获异常<code>std::runtime_error</code>，但不能捕获第30行中的异常，甚至在第33行中的捕获全部异常也无法捕获相应的异常。</p>
<p>使用新的MSVC编译器，并开启<code>std:c++latest</code>选项，程序会给出期望的输出。</p>
<p><img src="content/The-Details/Parallel-Algorithms-of-the-Standard/../../../images/detail/Parallel-Algorithms-of-the-Standard/4.png" alt="" /></p>
<p>只有第一个异常顺利捕获。</p>
<p>##数据竞争和死锁的风险</p>
<p>并行算法无法避免数据竞争和死锁。</p>
<p>下面的并行代码中，就存在数据竞争。</p>
<pre><code class="language-c++">
#include &lt;execution&gt;
#include &lt;vector&gt;

int main() {

  std::vector&lt;int&gt; v = { 1, 2, 3 };
  int sum = 0;
  std::for_each(std::execution::par, v.begin(), v.end(), [&amp;sum](int i) {
    sum += i + i;
    });

}
</code></pre>
<p>代码段中，<code>sum</code>有数据竞争。<code>sum</code>上累加了<code>i + i</code>的和，并且是并发修改的，所以必须保护<code>sum</code>。</p>
<pre><code class="language-c++">
#include &lt;execution&gt;
#include &lt;vector&gt;
#include &lt;mutex&gt;

std::mutex m;

int main() {

  std::vector&lt;int&gt; v = { 1, 2, 3 };

  int sum = 0;
  std::for_each(std::execution::par, v.begin(), v.end(), [&amp;sum](int i) {
    std::lock_guard&lt;std::mutex&gt; lock(m);
    sum += i + i;
    });

}
</code></pre>
<p>将执行策略更改为<code>std::execution::par_unseq</code>时，会出现条件竞争，并导致死锁。</p>
<pre><code class="language-c++">
#include &lt;execution&gt;
#include &lt;vector&gt;
#include &lt;mutex&gt;

std::mutex m;

int main() {

  std::vector&lt;int&gt; v = { 1, 2, 3 };

  int sum = 0;
  std::for_each(std::execution::par_unseq, v.begin(), v.end(), [&amp;sum](int i) {
    std::lock_guard&lt;std::mutex&gt; lock(m);
    sum += i + i;
    });

}
</code></pre>
<p>同一个线程上，Lambda函数可能连续两次调用<code>m.lock</code>，这会产生未定义行为，大多数情况下会导致死锁。这里，可以使用原子来避免死锁。</p>
<pre><code class="language-c++">#include &lt;execution&gt;
#include &lt;vector&gt;
#include &lt;mutex&gt;
#include &lt;atomic&gt;

std::mutex m;

int main() {

  std::vector&lt;int&gt; v = { 1, 2, 3 };

  std::atomic&lt;int&gt; sum = 0;
  std::for_each(std::execution::par_unseq, v.begin(), v.end(), [&amp;sum](int i) {
    std::lock_guard&lt;std::mutex&gt; lock(m);
    sum += i + i;
    });

}
</code></pre>
<p>因为<code>sum</code>是一个原子计数器，所以将语义放宽也没关系：<code>sum.fetch_add(i * i, std::memory_order_relaxed)</code> .</p>
<p>执行策略可以作为参数传入69个STL重载算法中，以及C++17添加的8个新算法中。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="算法"><a class="header" href="#算法">算法</a></h1>
<p>下面是69个算法的并行版本。</p>
<table><thead><tr><th align="center"><code>std::adjacent_difference</code></th><th align="center"><code>std::adjacent_find</code></th><th align="center"><code>std::all_of</code></th><th align="center"><code>std::any_of</code></th></tr></thead><tbody>
<tr><td align="center"><code>std::copy</code></td><td align="center"><code>std::copy_if</code></td><td align="center"><code>std::copy_n</code></td><td align="center"><code>std::count</code></td></tr>
<tr><td align="center"><code>std::count_if</code></td><td align="center"><code>std::equal</code></td><td align="center"><code>std::fill</code></td><td align="center"><code>std::fill_n</code></td></tr>
<tr><td align="center"><code>std::find</code></td><td align="center"><code>std::find_end</code></td><td align="center"><code>std::find_first_of</code></td><td align="center"><code>std::find_if</code></td></tr>
<tr><td align="center"><code>std::find_if_not</code></td><td align="center"><code>std::generate</code></td><td align="center"><code>std::generate_n</code></td><td align="center"><code>std::includes</code></td></tr>
<tr><td align="center"><code>std::inner_product</code></td><td align="center"><code>std::inplace_merge</code></td><td align="center"><code>std::is_heap</code></td><td align="center"><code>std::is_heap_until</code></td></tr>
<tr><td align="center"><code>std::is_partitioned</code></td><td align="center"><code>std::is_sorted</code></td><td align="center"><code>std::is_sorted_until</code></td><td align="center"><code>std::lexicographical_compare</code></td></tr>
<tr><td align="center"><code>std::max_element</code></td><td align="center"><code>std::merge</code></td><td align="center"><code>std::min_element</code></td><td align="center"><code>std::minmax_element</code></td></tr>
<tr><td align="center"><code>std::mismatch</code></td><td align="center"><code>std::move</code></td><td align="center"><code>std::none_of</code></td><td align="center"><code>std::nth_element</code></td></tr>
<tr><td align="center"><code>std::partial_sort</code></td><td align="center"><code>std::partial_sort_copy</code></td><td align="center"><code>std::partition</code></td><td align="center"><code>std::partition_copy</code></td></tr>
<tr><td align="center"><code>std::remove</code></td><td align="center"><code>std::remove_copy</code></td><td align="center"><code>std::remove_copy_if</code></td><td align="center"><code>std::remove_if</code></td></tr>
<tr><td align="center"><code>std::replace</code></td><td align="center"><code>std::replace_copy</code></td><td align="center"><code>std::replace_copy_if</code></td><td align="center"><code>std::replace_if</code></td></tr>
<tr><td align="center"><code>std::reverse</code></td><td align="center"><code>std::reverse_copy</code></td><td align="center"><code>std::rotate</code></td><td align="center"><code>std::rotate_copy</code></td></tr>
<tr><td align="center"><code>std::search</code></td><td align="center"><code>std::search_n</code></td><td align="center"><code>std::set_difference</code></td><td align="center"><code>std::set_intersection</code></td></tr>
<tr><td align="center"><code>std::set_symmetric_difference</code></td><td align="center"><code>std::set_union</code></td><td align="center"><code>std::sort</code></td><td align="center"><code>std::stable_partition</code></td></tr>
<tr><td align="center"><code>std::stable_sort</code></td><td align="center"><code>std::swap_ranges</code></td><td align="center"><code>std::transform</code></td><td align="center"><code>std::uninitialized_copy</code></td></tr>
<tr><td align="center"><code>std::uninitialized_copy_n</code></td><td align="center"><code>std::uninitialized_fill</code></td><td align="center"><code>std::uninitialized_fill_n</code></td><td align="center"><code>std::unique</code></td></tr>
<tr><td align="center"><code>std::unique_copy</code></td><td align="center"></td><td align="center"></td><td align="center"></td></tr>
</tbody></table>
<p>除了以上这些算法，还有8种新算法。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="新算法-1"><a class="header" href="#新算法-1">新算法</a></h1>
<p>新算法包含在<code>std</code>命名空间中，<code>std::for_each</code>和<code>std::for_each_n</code>在<code>&lt;algorithm&gt;</code>头文件中声明，其余六种算法在<code>&lt;numeric&gt;</code>头文件中声明。</p>
<p>下面是新算法的概述。</p>
<table><thead><tr><th align="center">算法</th><th align="center">描述</th></tr></thead><tbody>
<tr><td align="center"><code>std::for_each</code></td><td align="center">将一元函数对象应用于引用范围。</td></tr>
<tr><td align="center"><code>std::for_each_n</code></td><td align="center">将一元函数对象应用于引用范围的前n个元素。</td></tr>
<tr><td align="center"><code>std::exclusive_scan</code></td><td align="center">将二元函数对象从左向右应用与引用范围。“排除性”(exclusive)表示第i个输入元素不包含在第i个和内。二元函数对象的第一个参数是之前计算的结果，运算可能以任意顺序进行，并存储中间结果。若二元函数对象不满足结合律，则函数行为不确定。行为与<a href="http://en.cppreference.com/w/cpp/algorithm/partial_sum"><code>std::partial_sum</code></a>类似。</td></tr>
<tr><td align="center"><code>std::inclusive_scan</code></td><td align="center">将二元函数对象从左向右应用与引用范围。“包含性”(inclusive)表示第i个输入元素包含于第i个和中。二元函数对象的第一个参数是之前计算的结果，运算可能以任意顺序进行，并存储中间结果。若二元函数对象不满足结合律，则函数行为不确定。行为与<a href="http://en.cppreference.com/w/cpp/algorithm/partial_sum"><code>std::partial_sum</code></a>类似</td></tr>
<tr><td align="center"><code>std::transform_exclusive_scan</code></td><td align="center">首先，将一元函数对象应用于引用范围，然后使用<code>std::exclusive_scan</code>。若二元函数对象不满足结合律，则函数行为不确定。</td></tr>
<tr><td align="center"><code>std::transform_inclusive_scan</code></td><td align="center">首先，将一元函数对象应用于引用范围，然后使用<code>std::inclusive_scan</code>。若二元函数对象不满足结合律，则函数行为不确定。</td></tr>
<tr><td align="center"><code>std::reduce</code></td><td align="center">将二元函数对象从左向右应用与引用范围。若二元函数对象不满足交换律或结合律，则函数行为不确定。行为与<a href="http://en.cppreference.com/w/cpp/algorithm/accumulate"><code>std::accumulate</code></a>类似。</td></tr>
<tr><td align="center"><code>std::transform_reduce</code></td><td align="center">首先，将一元函数对象应用于引用范围，然后使用<code>std::reduce</code>。若二元函数对象不满足交换律或结合律，则函数行为不确定。</td></tr>
</tbody></table>
<p>表中的函数描述不大容易理解，若对<code>std::accumulate</code>和<code>std::partial_sum</code>比较了解，那对前缀求和算法应该是非常熟悉。归约算法可以并行使用累加的方式，扫描算法可以并行的使用<code>partial_sum</code>。这就是<code>std::reduce</code>(归约算法)需要满足交换律和结合律的原因。</p>
<p>首先，给出一个算法示例，然后介绍这些函数的功能。示例中，忽略了新的<code>std::for_each</code>算法。与返回一元函数的C++98实现不同，C++17中什么也不返回。<code>std::accumulate</code>从左到右处理元素，而<code>std::reduce</code>可以以任意的顺序处理元素。让我们从使用<code>std::accumulate</code>和<code>std::reduce</code>的小代码段开始，二元函数对象为Lambda函数<code> [](int a, int b){ return a * b; }</code>。</p>
<pre><code class="language-c++">std::vector&lt;int&gt; v{1, 2, 3, 4};
std::accumulate(v.begin(), v.end(), 1, [](int a, int b){ return a * b; });
std::reduce(std::execution::par, v.begin(), v.end(), 1 ,
[](int a, int b){ return a * b; });
</code></pre>
<p>下面两张图显示了<code>std::accumulate</code>和<code>std::reduce</code>的不同策略。</p>
<p><code>std::accumulate</code>从左开始，依次使用二进制操作符。</p>
<p><img src="content/The-Details/Parallel-Algorithms-of-the-Standard/../../../images/detail/Parallel-Algorithms-of-the-Standard/5.png" alt="" /></p>
<p>与<code>std::accumulate</code>不同，<code>std::reduce</code>以一种不确定的方式使用二元操作符。</p>
<p><img src="content/The-Details/Parallel-Algorithms-of-the-Standard/../../../images/detail/Parallel-Algorithms-of-the-Standard/6.png" alt="" /></p>
<p>结合律允许<code>std::reduce</code>算法计算任意邻接元素对。因为元素顺序可交换，所以中间结果可以按任意顺序计算。</p>
<blockquote>
<p><strong>当前可用的算法实现</strong></p>
<p>展示代码之前，必须做个说明。据我所知，本书更新的时候(2018年9月)，并没有完全符合标准的并行STL实现。MSVC 17.8也只是增加了对大约30种算法的支持。</p>
<p>MSVC 17.8中的并行算法</p>
<table><thead><tr><th align="center"><code>std::adjacent_difference</code></th><th align="center"><code>std::adjacent_find</code></th><th align="center"><code>std::all_of</code></th></tr></thead><tbody>
<tr><td align="center"><code>std::any_of</code></td><td align="center"><code>std::count</code></td><td align="center"><code>std::count_if</code></td></tr>
<tr><td align="center"><code>std::equal</code></td><td align="center"><code>std::exclusive_scan</code></td><td align="center"><code>std::find</code></td></tr>
<tr><td align="center"><code>std::find_end</code></td><td align="center"><code>std::find_first_of</code></td><td align="center"><code>std::find_if</code></td></tr>
<tr><td align="center"><code>std::for_each</code></td><td align="center"><code>std::for_each_n</code></td><td align="center"><code>std::inclusive_scan</code></td></tr>
<tr><td align="center"><code>std::mismatch</code></td><td align="center"><code>std::none_of</code></td><td align="center"><code>std::reduce</code></td></tr>
<tr><td align="center"><code>std::remove</code></td><td align="center"><code>std::remove_if</code></td><td align="center"><code>std::search</code></td></tr>
<tr><td align="center"><code>std::search_n</code></td><td align="center"><code>std::sort</code></td><td align="center"><code>std::stable_sort</code></td></tr>
<tr><td align="center"><code>std::transform</code></td><td align="center"><code>std::transform_exclusive_scan</code></td><td align="center"><code>std::transform_inclusive_scan</code></td></tr>
<tr><td align="center"><code>std::transform_reduce</code></td><td align="center"></td><td align="center"></td></tr>
</tbody></table>
<p>这里使用HPX实现功能，并生成输出，<a href="http://stellar.cct.lsu.edu/projects/hpx">HPX (High-Performance ParalleX)</a>是一种可用于任何规模的并行和分布式应用程序的通用C++运行时系统框架。HPX已经在其的一个名称空间中实现了所有并行STL。</p>
<p>为了完整性，这里是并行STL的部分实现连接:</p>
<ul>
<li><a href="https://software.intel.com/en-us/get-started-with-pstl">Intel</a></li>
<li><a href="https://github.com/t-lutz/ParallelSTL">Thibaut Lutz</a></li>
<li><a href="https://thrust.github.io/doc/group__execution__policies.html">Nvidia(thrust)</a></li>
<li><a href="https://github.com/KhronosGroup/SyclParallelSTL">Codeplay</a></li>
</ul>
</blockquote>
<p>新算法示例代码</p>
<pre><code class="language-c++">// newAlgorithm.cpp

#include &lt;algorithm&gt;
#include &lt;execution&gt;
#include &lt;numeric&gt;
#include &lt;iostream&gt;
#include &lt;string&gt;
#include &lt;vector&gt;


int main() {

  std::cout &lt;&lt; std::endl;

  // for_each_n

  std::vector&lt;int&gt; intVec{ 1,2,3,4,5,6,7,8,9,10 };
  std::for_each_n(std::execution::par,
    intVec.begin(), 5, [](int&amp; arg) {arg *= arg; });

  std::cout &lt;&lt; &quot;for_each_n: &quot;;
  for (auto v : intVec)std::cout &lt;&lt; v &lt;&lt; &quot; &quot;;
  std::cout &lt;&lt; &quot;\n\n&quot;;

  // exclusive_scan and inclusive_scan
  std::vector&lt;int&gt; resVec{ 1,2,3,4,5,6,7,8,9 };
  std::exclusive_scan(std::execution::par,
    resVec.begin(), resVec.end(), resVec.begin(), 1,
    [](int fir, int sec) {return fir * sec; });

  std::cout &lt;&lt; &quot;exclusive_scan: &quot;;
  for (auto v : resVec)std::cout &lt;&lt; v &lt;&lt; &quot; &quot;;
  std::cout &lt;&lt; std::endl;

  std::vector&lt;int&gt; resVec2{ 1,2,3,4,5,6,7,8,9 };

  std::inclusive_scan(std::execution::par,
    resVec2.begin(), resVec2.end(), resVec2.begin(),
    [](int fir, int sec) {return fir * sec; });

  std::cout &lt;&lt; &quot;inclusive_scan: &quot;;
  for (auto v : resVec2)std::cout &lt;&lt; v &lt;&lt; &quot; &quot;;
  std::cout &lt;&lt; &quot;\n\n&quot;;

  // transform_exclusive_scan and transform_inclusive_scan
  std::vector&lt;int&gt; resVec3{ 1,2,3,4,5,6,7,8,9 };
  std::vector&lt;int&gt; resVec4(resVec3.size());
  std::transform_exclusive_scan(std::execution::par,
    resVec3.begin(), resVec3.end(),
    resVec4.begin(), 0,
    [](int fir, int sec) {return fir + sec; },
    [](int arg) {return arg *= arg; });

  std::cout &lt;&lt; &quot;transform_exclusive_scan: &quot;;
  for (auto v : resVec4)std::cout &lt;&lt; v &lt;&lt; &quot; &quot;;
  std::cout &lt;&lt; std::endl;

  std::vector&lt;std::string&gt; strVec{ &quot;Only&quot;, &quot;for&quot;,&quot;testing&quot;, &quot;purpose&quot; };
  std::vector&lt;int&gt; resVec5(strVec.size());

  std::transform_inclusive_scan(std::execution::par,
    strVec.begin(), strVec.end(),
    resVec5.begin(), 0,
    [](auto fir, auto sec) {return fir + sec; },
    [](auto s) {return s.length(); });

  std::cout &lt;&lt; &quot;transform_inclusive_scan: &quot;;
  for (auto v : resVec5) std::cout &lt;&lt; v &lt;&lt; &quot; &quot;;
  std::cout &lt;&lt; &quot;\n\n&quot;;

  // reduce and transform_reduce
  std::vector&lt;std::string&gt; strVec2{ &quot;Only&quot;, &quot;for&quot;, &quot;testing&quot;, &quot;purpose&quot; };

  std::string res = std::reduce(std::execution::par,
    strVec2.begin() + 1, strVec2.end(), strVec2[0],
    [](auto fir, auto sec) {return fir + &quot;:&quot; + sec; });

  std::cout &lt;&lt; &quot;reduce: &quot; &lt;&lt; res &lt;&lt; std::endl;

  std::size_t res7 = std::transform_reduce(std::execution::par,
    strVec2.begin(), strVec2.end(),
    [](std::string s) {return s.length(); },
    0, [](std::size_t a, std::size_t b) {return a + b; });


  std::cout &lt;&lt; &quot;transform_reduce: &quot; &lt;&lt; res7 &lt;&lt; std::endl;

  std::cout &lt;&lt; std::endl;

}
</code></pre>
<p>程序在第17行使用了<code>std::vector&lt;int&gt;</code>，在第58行使用了<code>std::vectorstd::string</code>。</p>
<p>第18行中的<code>std::for_each_n</code>将向量的前n个元素映射为2次幂。<code>std::exclusive_scan</code>(第27行)和<code>std::inclusive_scan</code>(第37行)非常相似，两者都对元素应用二元操作。区别在于<code>std::exclusive_scan</code>排除了每个迭代中的最后一个元素。</p>
<p>第48行中的<code>std::transform_exclusive_scan</code>比较难理解。第一步中，使用Lambda函数<code>[](int arg){return arg *= arg;}</code>，对<code>resVec3.begin()</code>到<code>resVec3.end()</code>范围内的每个元素，进行2次幂操作。第二步，对保存中间结果的向量(<code>resVec4</code>)使用二元运算<code>[](int fir, int sec){return fir + sec;}</code>。这样，使用0作为元素求和的初始值，结果放在<code>resVec4.begin()</code>中。</p>
<p>第61行中的<code>std::transform_inclusive_scan</code>类似，而这里操作的是元素的长度。</p>
<p>这里的<code>std::reduce</code>应该比较容易理解，程序中在输入向量的每两个元素之间放置“:”字符，因为结果字符串不应该以“:”字符开头，所以从第二个元素<code>(strVec2.begin() + 1)</code>开始，并使用<code>strVec2[0]</code>作为初始值。</p>
<blockquote>
<p><strong>transform_reduce与map_reduce</strong> </p>
<p>关于第80行的<code>std::transform_reduce</code>，我还想多补充两句。首先，C++算法的转换算法，在其他语言中通常称为映射(map)。因此，也可以称<code>std::transform_reduce</code>为<code> std::map_reduce</code>。<code>std::transform_reduce</code>的后端实现，使用的是C++中著名的并行<a href="https://en.wikipedia.org/wiki/MapReduce">MapReduce</a>算法。相应地，<code>std::transform_reduce</code>在某个范围内使用一元函数(<code>([](std::string s){ return s.length();})</code>)，并将结果归约为一个输出值：<code>[](std::size_t a, std::size_t b){return a+b;}</code>。</p>
</blockquote>
<p>下面是程序的输出。</p>
<p><img src="content/The-Details/Parallel-Algorithms-of-the-Standard/../../../images/detail/Parallel-Algorithms-of-the-Standard/7.png" alt="" /></p>
<h2 id="更多的重载"><a class="header" href="#更多的重载">更多的重载</a></h2>
<p>归约和扫描算法的C++实现有很多重载版本。最简版本中，可以在没有二元函数对象和初始元素的情况下使用。如果不使用二元函数对象，则默认将加法作为二元操作符。如果没有指定初始元素，则初始元素取决于使用的算法:</p>
<ul>
<li><code>std::inclusive_scan</code>和<code>std::transform_inclusive_scan</code>算法 : 选用第一个元素。</li>
<li><code>std::reduce</code> 和<code>std::transform_reduce</code>算法 : 相应类型的构造值<code>std::iterator_traits&lt;InputIt&gt;::value_type{}</code>。</li>
</ul>
<p>接下来，从函数的角度再来看看这些新算法。</p>
<h2 id="功能性继承"><a class="header" href="#功能性继承">功能性继承</a></h2>
<p>时间宝贵，长话短说：所有的C++新算法在纯函数语言Haskell中都有对应。</p>
<ul>
<li><code>std::for_each_n</code>对应map。</li>
<li><code>std::exclusive_scan</code>和<code>std::inclusive_scan</code> 分别对应scanl和scanl1。</li>
<li><code>std::transform_exclusive_scan</code>和<code>std::transform_inclusive_scan</code> 分别对应map与scan1和scan2的组合。</li>
<li><code>std::reduce</code>对应foldl或foldl1。</li>
<li><code>std::transform_reduce</code> 对应于foldl或foldl1与map的组合。</li>
</ul>
<p>展示Haskell的实际效果之前，先了解下功能上的差异。</p>
<ul>
<li>map将一个函数应用于列表。</li>
<li>foldl和foldl1将一个二元操作符应用于列表，并将该列表的值归约成一个。与foldl1不同，foldl需要一个初始值。</li>
<li>scanl和scanl1与foldl和foldl1类似，但可以获取计算时的中间结果列表。</li>
<li>foldl , foldl1 , scanl和scanl1从左向右处理元素。</li>
</ul>
<p>让我们看一下这些Haskell函数，下面是Haskell解释器的命令行界面。</p>
<p><img src="content/The-Details/Parallel-Algorithms-of-the-Standard/../../../images/detail/Parallel-Algorithms-of-the-Standard/8.png" alt="" /></p>
<p>(1)和(2)定义了一个整数列表和一个字符串列表。(3)中将Lambda函数<code>(\a -&gt; a * a)</code>应用到整数列表中。(4)和(5)比较复杂，表达式(4)以1作为乘法的中间元素，乘以<code>(*)</code>所有整数对。表达式(5)做相应的加法运算。理解(6)、(7)和(9)是比较具有挑战性的，必须从右到左读。<code>scanl1(+).map(\a-&gt;length)</code>(7)是一个函数组合，点<code>(.)</code>左右是两个函数。第一个函数将每个元素映射为自身长度，第二个函数将长度列表累加。(9)与(7)相似，不同之处在于<code>foldl</code>生成一个值，并需要一个初始值。到这，表达式(8)就好理解了，它连续地用“:”字符将两个字符串连接起来。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="性能概况"><a class="header" href="#性能概况">性能概况</a></h1>
<p>使用并行STL的首要原因，肯定是性能。</p>
<p>下面的代码就能反映不同执行策略的性能差异。</p>
<pre><code class="language-c++">// parallelSTLPerformance.cpp

#include &lt;algorithm&gt;
#include &lt;cmath&gt;
#include &lt;chrono&gt;
#include &lt;execution&gt;
#include &lt;iostream&gt;
#include &lt;random&gt;
#include &lt;string&gt;
#include &lt;vector&gt;

constexpr long long size = 500'000'000;

const double pi = std::acos(-1);

template &lt;typename Func&gt;
void getExecutionTime(const std::string&amp; title, Func func) {

  const auto sta = std::chrono::steady_clock::now();
  func();
  const std::chrono::duration&lt;double&gt; dur = std::chrono::steady_clock::now() - sta;

  std::cout &lt;&lt; title &lt;&lt; &quot;: &quot; &lt;&lt; dur.count() &lt;&lt; &quot; sec.&quot; &lt;&lt; std::endl;

}

int main() {

  std::cout &lt;&lt; std::endl;

  std::vector&lt;double&gt; randValues;
  randValues.reserve(size);

  std::mt19937 engine;
  std::uniform_real_distribution&lt;&gt; uniformDist(0, pi / 2);
  for (long long i = 0; i &lt; size; ++i) randValues.push_back(uniformDist(engine));

  std::vector&lt;double&gt; workVec(randValues);

  getExecutionTime(&quot;std::execution::seq&quot;, [workVec]()mutable {
    std::transform(std::execution::seq, workVec.begin(), workVec.end(),
      workVec.begin(),
      [](double arg) {return std::tan(arg); }
    );
    });

  getExecutionTime(&quot;std::execution::par&quot;, [workVec]()mutable {
    std::transform(std::execution::par, workVec.begin(), workVec.end(),
      workVec.begin(),
      [](double arg) {return std::tan(arg); }
    );
    });

  getExecutionTime(&quot;std::execution::par_unseq&quot;, [workVec]()mutable {
    std::transform(std::execution::par_unseq, workVec.begin(), workVec.end(),
      workVec.begin(),
      [](double arg) {return std::tan(arg); }
    );
    });

}
</code></pre>
<p>parallelSTLPerformance.cpp统计了串行(第39行)、并行(第46行)和向量化并行(第53行)执行策略的耗时。首先，<code>randValues</code>由区间在[0,pi/2)的5亿个数字填充。函数模板<code>getExecutionTime</code>(第16 - 24行)获取标题和Lambda函数，在第20行执行Lambda函数，并显示执行耗时(第22行)。程序使用了三个Lambda函数(第39、46和53行)，它们被声明为<code>mutable</code>。因为Lambda函数修改它的参数<code>workVec</code>，而Lambda函数默认是不能对其进行修改的。如果Lambda函数想要修改，那么就必须声明为<code>mutable</code>。</p>
<p>我的windows笔记本电脑有8个逻辑核心，但并行执行速度要比串行的快10倍以上。</p>
<p><img src="content/The-Details/Parallel-Algorithms-of-the-Standard/../../../images/detail/Parallel-Algorithms-of-the-Standard/9.png" alt="" /></p>
<p>并行执行和并行向量化执行的性能大致相同。Visual C++团队的博客对此进行了解释：<a href="https://blogs.msdn.microsoft.com/vcblog/2018/09/11/using-c17-parallel-algorithms-for-better-performance">使用C++17并行算法更好的性能</a>。Visual C++团队使用相同的方式实现了并行计算和并行策略，所以目前就不要期望<code>par_unseq</code>有更好性能(但未来就不好说了)。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="案例研究-1"><a class="header" href="#案例研究-1">案例研究</a></h1>
<p>了解了内存模型和多线程接口后，现在就要进行实践了，本章会提供一些性能数据作为参考。</p>
<blockquote>
<p><strong>电脑配置参考</strong></p>
<p>我用Linux桌面版(GCC 4.8.3)和Windows笔记本电脑(cl.exe 19.00.23506)对程序的性能进行测试，使用优化的64位可执行文件进行测试。Linux PC有四个核心，而Windows PC有两个核心。下面是这两个编译器的详细信息：</p>
<p><img src="content/The-Details/Case-Studies/../../../images/detail/Case-Studies/10.png" alt="" /></p>
</blockquote>
<p>读者们应该只将这里的性能数值作为参考。我更喜欢凭直觉判断哪些算法可行，哪些算法不可行，但对Linux和Windows操作系统支持算法的确切数目不感兴趣。我想知道一些算法在不同的操作系统下，是否会有不同的性能表现(译者注：这里作者主要想比较操作系统中的实现，而不是对机器硬件进行比较)。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="求向量元素的加和-1"><a class="header" href="#求向量元素的加和-1">求向量元素的加和</a></h1>
<p>向<code>std::vector</code>中添加元素最快的方法是哪种？为了得到答案，我准备向<code>std::vector</code>中填充了一亿个数值，这些数在1~10之间<a href="https://en.wikipedia.org/wiki/Uniform_distribution_(continuous)">均匀分布</a> 。我们的任务是用各种方法计算这些数字的和，并添加执行时间作为性能指标。本节将讨论原子、锁、线程本地数据和任务。</p>
<h2 id="单线程方式"><a class="header" href="#单线程方式">单线程方式</a></h2>
<p>最直接的方式是使用for循环进行数字的添加。</p>
<p><strong>for循环</strong></p>
<p>下面的代码中，第27行进行加和计算。</p>
<pre><code class="language-c++">// calculateWithLoop.cpp

#include &lt;chrono&gt;
#include &lt;iostream&gt;
#include &lt;random&gt;
#include &lt;vector&gt;

constexpr long long size = 100000000;

int main() {

  std::cout &lt;&lt; std::endl;

  std::vector&lt;int&gt;randValues;
  randValues.reserve(size);

  // random values
  std::random_device seed;
  std::mt19937 engine(seed());
  std::uniform_int_distribution&lt;&gt; uniformDIst(1, 10);
  for (long long i = 0; i &lt; size; ++i)
    randValues.push_back(uniformDIst(engine));

  const auto sta = std::chrono::steady_clock::now();

  unsigned long long sum = {};
  for (auto n : randValues)sum += n;

  const std::chrono::duration&lt;double&gt; dur =
    std::chrono::steady_clock::now() - sta;

  std::cout &lt;&lt; &quot;Time for mySumition &quot; &lt;&lt; dur.count()
    &lt;&lt; &quot;seconds&quot; &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;Result: &quot; &lt;&lt; sum &lt;&lt; std::endl;

  std::cout &lt;&lt; std::endl;

}
</code></pre>
<p>我的电脑可够快？</p>
<p><img src="content/The-Details/Case-Studies/../../../images/detail/Case-Studies/11.png" alt="" /></p>
<p>显式地使用循环没什么技术含量。大多数情况下，可以使用标准模板库中的算法。</p>
<p><strong>使用std::accumulate进行加和计算</strong></p>
<p><code>std::accumulate</code>是计算向量和的正确选择，下面代码展示了<code>std::accumulate</code>的使用方法。完整的源文件可以在本书的参考资料中找到。</p>
<pre><code class="language-c++">// calculateWithStd.cpp
...
const unsigned long long sum = std::accumulate(randValues.begin(),
              randValues.end(), 0);
...
</code></pre>
<p>Linux上，<code>std::accumulate</code>的性能与for循环的性能大致相同，而在Windows上使用<code>std::accumulate</code>会产生很大的性能收益。</p>
<p><img src="content/The-Details/Case-Studies/../../../images/detail/Case-Studies/12.png" alt="" /></p>
<p>现在有了基线参考时间，就可以继续剩余的两个单线程场景了：使用锁和原子操作。为什么是这两个场景？我们需要有性能数字佐证，在没有竞争的情况下，锁和原子操作对数据进行保护，需要付出多大的性能代价。</p>
<p><strong>使用锁进行保护</strong></p>
<p>如果使用锁保护对求和变量的访问，需要回答两个问题。</p>
<ol>
<li>无争抢的同步锁，需要多大的代价?</li>
<li>最优的情况下，锁能有多快？</li>
</ol>
<p>这里使用<code>std::lock_guard</code>的方式，完整源码可在本书资源中找到。</p>
<pre><code class="language-c++">// calculateWithLock.cpp
...
std::mutex myMutex;
for (auto i: randValues){
	std::lock_guard&lt;std::mutex&gt; myLockGuard(myMutex);
	sum += i;
}
...
</code></pre>
<p>执行时间与预期的一样：对变量<code>sum</code>进行保护后，程序变得很慢。</p>
<p><img src="content/The-Details/Case-Studies/../../../images/detail/Case-Studies/13.png" alt="" /></p>
<p><code>std::lock_guard</code>的方式大约比<code>std::accumulate </code>慢50-150倍。接下来，让我们来看看原子操作的表现。</p>
<p><strong>使用原子操作进行保护</strong></p>
<p>对于原子操作的问题与锁一样：</p>
<ol>
<li>原子同步的代价有多大?</li>
<li>如果没有竞争，原子操作能有多快?</li>
</ol>
<p>还有一个问题：原子操作和锁的性能有多大差异?</p>
<pre><code class="language-c++">// calculateWithAtomic.cpp

#include &lt;atomic&gt;
#include &lt;chrono&gt;
#include &lt;iostream&gt;
#include &lt;numeric&gt;
#include &lt;random&gt;
#include &lt;vector&gt;

constexpr long long size = 100000000;

int main() {

  std::cout &lt;&lt; std::endl;

  std::vector&lt;int&gt;randValues;
  randValues.reserve(size);

  // random values
  std::random_device seed;
  std::mt19937 engine(seed());
  std::uniform_int_distribution&lt;&gt; uniformDist(1, 10);
  for (long long i = 0; i &lt; size; ++i)
    randValues.push_back(uniformDist(engine));

  std::atomic&lt;unsigned long long&gt; sum = {};
  std::cout &lt;&lt; std::boolalpha &lt;&lt; &quot;sum.is_lock_free(): &quot;
    &lt;&lt; sum.is_lock_free() &lt;&lt; std::endl;
  std::cout &lt;&lt; std::endl;

  auto sta = std::chrono::steady_clock::now();

  for (auto i : randValues) sum += i;

  std::chrono::duration&lt;double&gt; dur = std::chrono::steady_clock::now() - sta;


  std::cout &lt;&lt; &quot;Time for addition &quot; &lt;&lt; dur.count()
    &lt;&lt; &quot; seconds&quot; &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;Result: &quot; &lt;&lt; sum &lt;&lt; std::endl;

  std::cout &lt;&lt; std::endl;
  
  sum = 0;
  sta = std::chrono::steady_clock::now();

  for (auto i : randValues) sum.fetch_add(i);

  dur = std::chrono::steady_clock::now() - sta;
  std::cout &lt;&lt; &quot;Time for addition &quot; &lt;&lt; dur.count()
    &lt;&lt; &quot; seconds&quot; &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;Result: &quot; &lt;&lt; sum &lt;&lt; std::endl;

  std::cout &lt;&lt; std::endl;

}
</code></pre>
<p>首先，第28行检查是否有锁，否则锁和原子操作就没有区别了。所有主流平台上，原子变量都是无锁的。然后，用两种方法计算加和。第33行使用<code>+=</code>操作符，第45行使用<code>fetch_add</code>方法。单线程情况下，两种方式相差不多；不过，我可以显式地指定<code>fetch_add</code>的内存序。关于这点将在下一小节中详细介绍。</p>
<p>下面是程序的结果。</p>
<p><img src="content/The-Details/Case-Studies/../../../images/detail/Case-Studies/14.png" alt="" /></p>
<p><img src="content/The-Details/Case-Studies/../../../images/detail/Case-Studies/15.png" alt="" /></p>
<p><strong>单线程场景总结</strong></p>
<ol>
<li>原子操作在Linux和Windows上的速度比<code>std::accumulate </code>要慢12 - 50倍。</li>
<li>在Linux和Windows上，原子操作的速度比锁快2 - 3倍。</li>
<li><code>std::accumulate</code>似乎在Windows上有更好的优化。</li>
</ol>
<p>进行多线程场景测试之前，用表总结了单线程执行的结果，时间单位是秒。</p>
<table><thead><tr><th align="center">操作系统(编译器)</th><th align="center">for循环</th><th align="center"><code>std::accumulate</code></th><th align="center">锁</th><th align="center">原子操作</th></tr></thead><tbody>
<tr><td align="center">Linux(GCC)</td><td align="center">0.07</td><td align="center">0.07</td><td align="center">3.34</td><td align="center">1.34/1.33</td></tr>
<tr><td align="center">Windows(cl.exe)</td><td align="center">0.08</td><td align="center">0.03</td><td align="center">4.07</td><td align="center">1.50/1.61</td></tr>
</tbody></table>
<h2 id="多线程使用共享变量进行求和"><a class="header" href="#多线程使用共享变量进行求和">多线程：使用共享变量进行求和</a></h2>
<p>使用四个线程并用共享变量进行求和，并不是最优的最优的方式，因为同步开销超过了性能收益。</p>
<p>还是那两个问题：</p>
<ol>
<li>使用锁和原子的求和方式，在性能上有什么不同?</li>
<li><code>std::accumulate</code>的单线程执行和多线程执行的性能表现有什么不同?</li>
</ol>
<p><strong>使用<code>std::lock_guard</code></strong></p>
<p>实现线程安全的求和，最简单方法是使用<code>std::lock_guard</code>。</p>
<pre><code class="language-c++">// synchronisationWithLock.cpp

#include&lt;chrono&gt;
#include &lt;iostream&gt;
#include &lt;mutex&gt;
#include &lt;random&gt;
#include &lt;thread&gt;
#include &lt;utility&gt;
#include &lt;vector&gt;

constexpr long long size = 100000000;

constexpr long long fir = 25000000;
constexpr long long sec = 50000000;
constexpr long long thi = 75000000;
constexpr long long fou = 100000000;

std::mutex myMutex;

void sumUp(unsigned long long&amp; sum, const std::vector&lt;int&gt;&amp; val,
  unsigned long long beg, unsigned long long end) {
  for (auto it = beg; it &lt; end; ++it) {
    std::lock_guard&lt;std::mutex&gt; myLock(myMutex);
    sum += val[it];
  }
}

int main() {

  std::cout &lt;&lt; std::endl;

  std::vector&lt;int&gt; randValues;
  randValues.reserve(size);

  std::mt19937 engine;
  std::uniform_int_distribution&lt;&gt; uniformDist(1, 10);
  for (long long i = 0; i &lt; size; ++i)
    randValues.push_back(uniformDist(engine));

  unsigned long long sum = 0;
  const auto sta = std::chrono::steady_clock::now();

  std::thread t1(sumUp, std::ref(sum), std::ref(randValues), 0, fir);
  std::thread t2(sumUp, std::ref(sum), std::ref(randValues), fir, sec);
  std::thread t3(sumUp, std::ref(sum), std::ref(randValues), sec, thi);
  std::thread t4(sumUp, std::ref(sum), std::ref(randValues), thi, fou);

  t1.join();
  t2.join();
  t3.join();
  t4.join();

  std::chrono::duration&lt;double&gt; dur = std::chrono::steady_clock::now() - sta;
  std::cout &lt;&lt; &quot;Time for addition &quot; &lt;&lt; dur.count()
    &lt;&lt; &quot; seconds&quot; &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;Result: &quot; &lt;&lt; sum &lt;&lt; std::endl;

  std::cout &lt;&lt; std::endl;

}
</code></pre>
<p>程序很简单，函数<code>sumUp</code>(第20 - 26行)是需要线程完成的工作包。通过引用的方式得到变量<code>sum</code>和<code>std::vector val</code>，<code>beg</code>和<code>end</code>用来限定求和的范围，<code>std::lock_guard</code>(第23行)用于保护共享变量<code>sum</code>。每个线程(第43 - 46行)对四分之一的数据进行加和计算。</p>
<p>下面是我电脑上的性能数据：</p>
<p><img src="content/The-Details/Case-Studies/../../../images/detail/Case-Studies/16.png" alt="" /></p>
<p><img src="content/The-Details/Case-Studies/../../../images/detail/Case-Studies/17.png" alt="" /></p>
<p>因为<code>std::lock_guard</code>需要对行了同步，所以瓶颈在共享变量<code>sum</code>处。简单直接的解决方案：用轻量级的原子操作来替换重量级的锁。</p>
<blockquote>
<p>没有更改，为了简单起见，本小节之后只展示<code>sumUp</code>函数体。完整的示例，请参阅本书的参考资料。</p>
</blockquote>
<p><strong>使用原子变量</strong></p>
<p>求和变量<code>sum</code>是一个原子变量，就不再需要<code>std::lock_guard</code>。以下是修改后的求和函数。</p>
<pre><code class="language-c++">// synchronisationWithAtomic.cpp
...
void sumUp(std::atomic&lt;unsigned long long&gt;&amp; sum, const 	std::vector&lt;int&gt;&amp; val,
		unsigned long long beg, unsigned long long end){
	for (auto it = beg; it &lt; end; ++it){
		sum += val[it];
	}
}
</code></pre>
<p>我的Windows笔记本电脑的性能数据相当奇怪，耗时是使用<code>std::lock_guard</code>的两倍多。</p>
<p><img src="content/The-Details/Case-Studies/../../../images/detail/Case-Studies/18.png" alt="" /></p>
<p>除了使用<code>+=</code>操作符外，还可以使用<code>fetch_add</code>。</p>
<p><strong>使用fetch_add</strong></p>
<p>这次，代码的修改的更少，只是将求和表达式改为<code>sum.fetch_add(val[it])</code>。</p>
<pre><code class="language-c++">// synchronisationWithFetchAdd.cpp
...
void sumUp(std::atomic&lt;unsigned long long&gt;&amp; sum, const std::vector&lt;int&gt;&amp; val,
	unsigned long long beg, unsigned long long end){
	for (auto it = beg; it &lt; end; ++it){
		sum.fetch_add(val[it]);
	}
}
...
</code></pre>
<p>现在的性能与前面的例子相似，操作符<code>+=</code>和<code>fetch_add</code>之间貌似没有什么区别。</p>
<p><img src="content/The-Details/Case-Studies/../../../images/detail/Case-Studies/19.png" alt="" /></p>
<p>虽然<code>+=</code>操作和<code>fetch_add</code>在性能上没有区别，但是<code>fetch_add</code>有一个优势，可以显式地弱化内存序，并使用自由语义。</p>
<p><strong>使用自由语义的fetch_add</strong></p>
<pre><code class="language-c++">// synchronisationWithFetchAddRelaxed.cpp

...
  void sumUp(std::atomic&lt;unsigned long long&gt;&amp; sum, const std::vector&lt;int&gt;&amp; val,
             unsigned long long beg, unsigned long long end){
  for (auto it = beg; it &lt; end; ++it){
    sum.fetch_add(val[it], std::memory_order_relaxed);
  }
}
  
...
</code></pre>
<p>原子变量默认是顺序一致的。对于原子变量的加和和赋值，使用<code>fetch_add</code>是没问题的，也可以进行优化。我将求和表达式中的内存序调整为自由语义：<code>sum.fetch_add (val[it],std::memory_order_relaxed)</code>。自由语义是最弱的内存序，也是我们优化的终点。</p>
<p>这个用例中，自由语义能很好的完成工作，因为<code>fetch_add</code>进行的每个加和都是原子的，并且线程会进行同步。</p>
<p>因为是最弱的内存模型，所以性能最好。</p>
<p><img src="content/The-Details/Case-Studies/../../../images/detail/Case-Studies/20.png" alt="" /></p>
<p><strong>多线程使用共享变量求和总结</strong></p>
<p>性能数值的时间单位是秒。</p>
<table><thead><tr><th align="center">操作系统(编译器)</th><th align="center"><code>std::lock_guard</code></th><th align="center">原子 +=</th><th align="center">fetch_add</th><th align="center">fetch_add (使用自由内存序)</th></tr></thead><tbody>
<tr><td align="center">Linux(GCC)</td><td align="center">20.81</td><td align="center">7.78</td><td align="center">7.87</td><td align="center">7.66</td></tr>
<tr><td align="center">Windows(cl.exe)</td><td align="center">6.22</td><td align="center">15.73</td><td align="center">15.78</td><td align="center">15.01</td></tr>
</tbody></table>
<p>性能数据并不乐观，使用自由语义的共享原子变量，在四个线程的帮助下计算加和，其速度大约比使用<code>std::accumulate</code>算法的单个线程慢100倍。</p>
<p>结合前面的两种加和的策略，接下来会使用四个线程，并尽量减少线程之间的同步。</p>
<h2 id="线程本地的加和"><a class="header" href="#线程本地的加和">线程本地的加和</a></h2>
<p>接下来使用局部变量、线程本地数据和任务，可以最小化同步。</p>
<p><strong>使用本地变量</strong></p>
<p>每个线程都使用本地变量求和，所以可以在不同步的情况下完成自己的工作。不过，汇总局部变量的总和时需要进行同步。简单地说：只添加了4个同步，所以从性能的角度来看，使用哪种同步并不重要。我使用<code>std::lock_guard</code>和一个具有顺序一致语义和自由语义的原子变量。</p>
<p><strong>std::lock_guard</strong></p>
<p>使用<code>std::lock_guard</code>进行最小化同步的加和计算。</p>
<pre><code class="language-c++">// localVariable.cpp

#include &lt;mutex&gt;
#include&lt;chrono&gt;
#include &lt;iostream&gt;
#include &lt;random&gt;
#include &lt;thread&gt;
#include &lt;utility&gt;
#include &lt;vector&gt;

constexpr long long size = 100000000;

constexpr long long fir = 25000000;
constexpr long long sec = 50000000;
constexpr long long thi = 75000000;
constexpr long long fou = 100000000;

std::mutex myMutex;

void sumUp(unsigned long long&amp; sum, const std::vector&lt;int&gt;&amp; val,
  unsigned long long beg, unsigned long long end) {
  unsigned long long tmpSum{};
  for (auto i = beg; i &lt; end; ++i) {
    tmpSum += val[i];
  }
  std::lock_guard&lt;std::mutex&gt; lockGuard(myMutex);
  sum += tmpSum;
}

int main() {

  std::cout &lt;&lt; std::endl;

  std::vector&lt;int&gt; randValues;
  randValues.reserve(size);

  std::mt19937 engine;
  std::uniform_int_distribution&lt;&gt; uniformDist(1, 10);
  for (long long i = 0; i &lt; size; ++i)
    randValues.push_back(uniformDist(engine));

  unsigned long long sum{};
  const auto sta = std::chrono::steady_clock::now();

  std::thread t1(sumUp, std::ref(sum), std::ref(randValues), 0, fir);
  std::thread t2(sumUp, std::ref(sum), std::ref(randValues), fir, sec);
  std::thread t3(sumUp, std::ref(sum), std::ref(randValues), sec, thi);
  std::thread t4(sumUp, std::ref(sum), std::ref(randValues), thi, fou);

  t1.join();
  t2.join();
  t3.join();
  t4.join();

  std::chrono::duration&lt;double&gt; dur = 
    std::chrono::steady_clock::now() - sta;


  std::cout &lt;&lt; &quot;Time for addition &quot; &lt;&lt; dur.count()
    &lt;&lt; &quot; seconds&quot; &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;Result: &quot; &lt;&lt; sum &lt;&lt; std::endl;

  std::cout &lt;&lt; std::endl;

}
</code></pre>
<p>第26和27行，将局部求和结果<code>tmpSum</code>添加到全局求和变量<code>sum</code>中。</p>
<p><img src="content/The-Details/Case-Studies/../../../images/detail/Case-Studies/21.png" alt="" /></p>
<p><img src="content/The-Details/Case-Studies/../../../images/detail/Case-Studies/22.png" alt="" /></p>
<p>接下来使用局部变量的示例中，只有函数求和方式发生了变化，所以只展示这个函数体实现。完整的程序代码，请参考源文件。</p>
<p><strong>使用顺序一致语义的原子变量</strong></p>
<p>让我们用一个原子变量来声明全局求和变量<code>sum</code>。</p>
<pre><code class="language-c++">// localVariableAtomic.cpp
...
void sumUp(std::atomic&lt;unsigned long long&gt;&amp; sum, const std::vector&lt;int&gt;&amp; val,
           unsigned long long beg, unsigned long long end){
  unsigned int long long tmpSum{};
  for (auto i = beg; i &lt; end; ++i){
    tmpSum += val[i];
  }
  sum+= tmpSum;
}
...
</code></pre>
<p>下面是具体的性能数据：</p>
<p><img src="content/The-Details/Case-Studies/../../../images/detail/Case-Studies/23.png" alt="" /></p>
<p><img src="content/The-Details/Case-Studies/../../../images/detail/Case-Studies/24.png" alt="" /></p>
<p><strong>使用自由语义的原子变量</strong></p>
<p>现在不使用默认的内存序，而使用的是自由语义。只需要保证，所有求和操作是原子的就好。</p>
<pre><code class="language-c++">// localVariableAtomicRelaxed.cpp
...
void sumUp(std::atomic&lt;unsigned long long&gt;&amp; sum, const std::vector&lt;int&gt;&amp; val,
           unsigned long long beg, unsigned long long end){
  unsigned int long long tmpSum{};
  for (auto i = beg; i &lt; end; ++i){
    tmpSum += val[i];
  }
  sum.fetch_add(tmpSum, std::memory_order_relaxed);
}
...
</code></pre>
<p>和预期一样，使用<code>std::lock_guard</code>，使用顺序一致的原子变量，或是使用自由语义的原子变量进行求和，在性能方面并没什么差异。</p>
<p><img src="content/The-Details/Case-Studies/../../../images/detail/Case-Studies/25.png" alt="" /></p>
<p><img src="content/The-Details/Case-Studies/../../../images/detail/Case-Studies/26.png" alt="" /></p>
<p>线程本地数据不同于其他类型的数据，它的生命周期与线程绑定，并非函数的生命周期，例如：本例中的变量<code>tmpSum</code>。</p>
<p><strong>使用线程本地数据</strong></p>
<p>线程本地数据属于创建它的线程，其只在需要时被创建，非常适合于本地求和。</p>
<pre><code class="language-c++">// threadLocalSummation.cpp

#include &lt;atomic&gt;
#include&lt;chrono&gt;
#include &lt;iostream&gt;
#include &lt;random&gt;
#include &lt;thread&gt;
#include &lt;utility&gt;
#include &lt;vector&gt;

constexpr long long size = 100000000;

constexpr long long fir = 25000000;
constexpr long long sec = 50000000;
constexpr long long thi = 75000000;
constexpr long long fou = 100000000;

thread_local unsigned long long tmpSum = 0;

void sumUp(std::atomic&lt;unsigned long long&gt;&amp; sum, const std::vector&lt;int&gt;&amp; val,
  unsigned long long beg, unsigned long long end) {
  for (auto i = beg; i &lt; end; ++i) {
    tmpSum += val[i];
  }
  sum.fetch_add(tmpSum, std::memory_order_relaxed);
}

int main() {

  std::cout &lt;&lt; std::endl;

  std::vector&lt;int&gt; randValues;
  randValues.reserve(size);

  std::mt19937 engine;
  std::uniform_int_distribution&lt;&gt; uniformDist(1, 10);
  for (long long i = 0; i &lt; size; ++i)
    randValues.push_back(uniformDist(engine));

  std::atomic&lt;unsigned long long&gt; sum{};
  const auto sta = std::chrono::steady_clock::now();

  std::thread t1(sumUp, std::ref(sum), std::ref(randValues), 0, fir);
  std::thread t2(sumUp, std::ref(sum), std::ref(randValues), fir, sec);
  std::thread t3(sumUp, std::ref(sum), std::ref(randValues), sec, thi);
  std::thread t4(sumUp, std::ref(sum), std::ref(randValues), thi, fou);

  t1.join();
  t2.join();
  t3.join();
  t4.join();

  std::chrono::duration&lt;double&gt; dur = 
    std::chrono::steady_clock::now() - sta;

  std::cout &lt;&lt; &quot;Time for addition &quot; &lt;&lt; dur.count()
    &lt;&lt; &quot; seconds&quot; &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;Result: &quot; &lt;&lt; sum &lt;&lt; std::endl;

  std::cout &lt;&lt; std::endl;

}
</code></pre>
<p>第18行中声明了线程本地变量<code>tmpSum</code>，并在第23和25行中使用它进行加和。</p>
<p>下面是使用本地变量加和的性能数据：</p>
<p><img src="content/The-Details/Case-Studies/../../../images/detail/Case-Studies/27.png" alt="" /></p>
<p>最后，来看下如何使用任务(task)完成这项工作。</p>
<p><strong>使用任务</strong></p>
<p>使用任务，我们可以使用隐式同步完成整个工作。每个部分求和在单独的线程中执行，最后在主线程中进行求和。</p>
<p>代码如下：</p>
<pre><code class="language-c++">// tasksSummation.cpp

#include&lt;chrono&gt;
#include &lt;future&gt;
#include &lt;iostream&gt;
#include &lt;random&gt;
#include &lt;thread&gt;
#include &lt;utility&gt;
#include &lt;vector&gt;

constexpr long long size = 100000000;

constexpr long long fir = 25000000;
constexpr long long sec = 50000000;
constexpr long long thi = 75000000;
constexpr long long fou = 100000000;

void sumUp(std::promise&lt;unsigned long long&gt;&amp;&amp; prom, const std::vector&lt;int&gt;&amp; val,
  unsigned long long beg, unsigned long long end) {
  unsigned long long sum = {};
  for (auto i = beg; i &lt; end; ++i) {
    sum += val[i];
  }
  prom.set_value(sum);
}

int main() {

  std::cout &lt;&lt; std::endl;

  std::vector&lt;int&gt; randValues;
  randValues.reserve(size);

  std::mt19937 engine;
  std::uniform_int_distribution&lt;&gt; uniformDist(1, 10);
  for (long long i = 0; i &lt; size; ++i)
    randValues.push_back(uniformDist(engine));

  std::promise&lt;unsigned long long&gt; prom1;
  std::promise&lt;unsigned long long&gt; prom2;
  std::promise&lt;unsigned long long&gt; prom3;
  std::promise&lt;unsigned long long&gt; prom4;

  auto fut1 = prom1.get_future();
  auto fut2 = prom2.get_future();
  auto fut3 = prom3.get_future();
  auto fut4 = prom4.get_future();

  const auto sta = std::chrono::steady_clock::now();

  std::thread t1(sumUp, std::move(prom1), std::ref(randValues), 0, fir);
  std::thread t2(sumUp, std::move(prom2), std::ref(randValues), fir, sec);
  std::thread t3(sumUp, std::move(prom3), std::ref(randValues), sec, thi);
  std::thread t4(sumUp, std::move(prom4), std::ref(randValues), thi, fou);

  auto sum = fut1.get() + fut2.get() + fut3.get() + fut4.get();

  std::chrono::duration&lt;double&gt; dur = std::chrono::steady_clock::now() - sta;
  std::cout &lt;&lt; &quot;Time for addition &quot; &lt;&lt; dur.count()
    &lt;&lt; &quot; seconds&quot; &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;Result: &quot; &lt;&lt; sum &lt;&lt; std::endl;

  t1.join();
  t2.join();
  t3.join();
  t4.join();

  std::cout &lt;&lt; std::endl;

}
</code></pre>
<p>第39 - 47行定义了四个promise和future。第51 - 54行中，每个promise都被移动到线程中。promise只能移动，不能复制。<code>sumUp</code>的第一个参数使用右值引用的promise。future在第56行使用阻塞的<code>get</code>获取求和结果。</p>
<p><img src="content/The-Details/Case-Studies/../../../images/detail/Case-Studies/28.png" alt="" /></p>
<p><strong>所有线程本地求和场景的总结</strong></p>
<p>无论是使用局部变量，任务来部分求和，还是各种同步原语(如原子)，性能上好像没有太大的区别，只有线程本地数据似乎让程序变慢了一些。这个观察结果适用于Linux和Windows，不要对Linux相对于Windows的更高性能感到惊讶。别忘了，Linux的电脑上有4个核，而Windows笔记本电脑只有2个核。</p>
<table><thead><tr><th>操作系统(编译器)</th><th align="center"><code>std::lock_guard</code></th><th align="center">使用顺序一致语义的原子变量</th><th align="center">使用自由语义的原子变量</th><th>线程本地数据</th><th>任务</th></tr></thead><tbody>
<tr><td>Linux(GCC)</td><td align="center">0.03</td><td align="center">0.03</td><td align="center">0.03</td><td>0.04</td><td>0.03</td></tr>
<tr><td>Windows(cl.exe)</td><td align="center">0.10</td><td align="center">0.10</td><td align="center">0.10</td><td>0.20</td><td>0.10</td></tr>
</tbody></table>
<p>多线程的本地求和的速度，大约是单线程求和的两倍。因为线程之间几乎不需要同步，所以在最优的情况下，我认为性能会提高四倍。背后的根本原因是什么？</p>
<h2 id="总结求向量元素的加和"><a class="header" href="#总结求向量元素的加和">总结：求向量元素的加和</a></h2>
<p><strong>单线程</strong></p>
<p>基于for循环和STL算法<code>std::accumulate</code>的性能差不多。优化版本中，编译器会使用向量化的<a href="https://en.wikipedia.org/wiki/SIMD">SIMD</a>指令(SSE或AVX)用于求和。因此，循环计数器增加了4(SSE)或8(AVX)。</p>
<p><strong>使用共享变量多线程求和</strong></p>
<p>使用共享变量作为求和变量，可以说明了一点：同步操作是代价是非常昂贵的，应该尽可能避免。虽然我使用了原子变量，甚至打破了顺序一致性，但这四个线程比一个线程还要慢100倍。从性能角度考虑，要尽可能减少同步。</p>
<p><strong>线程本地求和</strong></p>
<p>线程本地求和仅比单线程for循环或<code>std::accumulate</code>快两倍，即使四个线程都可以独立工作，这种情况仍然存在。这也让我很惊讶，因为我原以为会有四倍的性能提升。更让我惊讶的是，电脑的四个核心并没有充分利用。</p>
<p><img src="content/The-Details/Case-Studies/../../../images/detail/Case-Studies/29.png" alt="" /></p>
<p>没有充分利用的原因也很简单，CPU无法快速地从内存中获取数据。程序执行是有<a href="https://en.wikipedia.org/wiki/Memory_bound_function">内存限制</a>的，或者说内存延迟了CPU核的计算速度。下图展示了计算时的瓶颈内存。</p>
<p><img src="content/The-Details/Case-Studies/../../../images/detail/Case-Studies/30.png" alt="" /></p>
<p><a href="https://en.wikipedia.org/wiki/Roofline_model">Roofline模型</a>是一种直观的性能模型，可对运行在多核或多核体系结构上的应用程序进行性能评估。该模型依赖于体系结构的峰值性能、峰值带宽和计算密度。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="单例模式线程安全的初始化"><a class="header" href="#单例模式线程安全的初始化">单例模式：线程安全的初始化</a></h1>
<p>开始研究之前，说明一下：我个人并不提倡使用单例模式。</p>
<blockquote>
<p><strong>对于单例模式的看法</strong></p>
<p>我只在案例研究中使用单例模式，因为它是以线程安全的方式，初始化变量的典型例子。先来了解一下单例模式的几个严重缺点：</p>
<ul>
<li>单例是一个经过乔装打扮的全局变量。因此，测试起来非常困难，因为它依赖于全局的状态。</li>
<li>通过<code>MySingleton::getInstance()</code>可以在函数中使用单例，不过函数接口不会说明内部使用了单例，并隐式依赖于对单例。</li>
<li>若将静态对象<code>x</code>和<code>y</code>放在单独的源文件中，并且这些对象的构造方式相互依赖，因为无法保证先初始化哪个静态对象，将陷入<a href="https://isocpp.org/wiki/faq/ctors">静态初始化混乱顺序</a>的情况。这里要注意的是，单例对象是<strong>静态对象</strong>。</li>
<li>单例模式是惰性创建对象，但不管理对象的销毁。如果不销毁不需要的东西，那就会造成内存泄漏。</li>
<li>试想一下，当子类化单例化，可能实现吗？这意味着什么?</li>
<li>想要实现一个线程安全且快速的单例，非常具有挑战性。</li>
</ul>
<p>关于单例模式的详细讨论，请参阅Wikipedia中有关<a href="https://en.wikipedia.org/wiki/Singleton_pattern">单例模式</a>的文章。</p>
</blockquote>
<p>我想在开始讨论单例的线程安全初始化前，先说点别的。</p>
<p>##双重检查的锁定模式</p>
<p><a href="http://www.cs.wustl.edu/%7Eschmidt/PDF/DC-Locking.pdf">双重检查锁定</a>模式是用线程安全的方式，初始化单例的经典方法。听起来像是最佳实践或模式之类的方法，但更像是一种<a href="https://en.wikipedia.org/wiki/Anti-pattern">反模式</a>。它假设传统实现中有相关的保障机制，而Java、C#或C++内存模型不再提供这种保障。这样，创建单例是原子操作就是一个错误的假设，这样看起来是线程安全的解决方案并不安全。</p>
<p>什么是双重检查锁定模式？实现线程安全单例的，首先会想到用锁来保护单例的初始化过程。</p>
<pre><code class="language-c++">std::mutex myMutex;

class MySingleton {
public:
  static MySingleton&amp; getInstance() {
    std::lock_guard&lt;mutex&gt; myLock(myMutex);
    if (!instance) instance = new MySingleton();
    return *instance;
  }
private:
  MySingleton() = default;
  ~MySingleton() = default;
  MySingleton(const MySingleton&amp;) = delete;
  MySingleton&amp; operator= (const MySingleton&amp;) = delete;
  static MySingleton* instance;
};

MySingleton* MySingleton::instance = nullptr;
</code></pre>
<p>程序有毛病么？有毛病：是因为性能损失太大；没毛病：是因为实现的确线程安全。第7行的锁会对单例的每次访问进行保护，这也适用于读取。不过，构造<code>MySingleton</code>之后，就没有必要读取了。这里双重检查锁定模式就发挥了其作用，再看一下<code>getInstance</code>函数。</p>
<pre><code class="language-c++">static MySingleton&amp; getInstance() {
  if (!instance) { // check
    lock_guard&lt;mutex&gt; myLock(myMutex); // lock
    if (!instance) instance = new MySingleton(); // check
  }
  return *instance;
}
</code></pre>
<p>第2行没有使用锁，而是使用指针比较。如果得到一个空指针，则申请锁的单例(第3行)。因为，可能有另一个线程也在初始化单例，并且到达了第2行或第3行，所以需要额外的指针在第4行进行比较。顾名思义，其中两次是检查，一次是锁定。</p>
<p>牛B不？牛。线程安全？不安全。</p>
<p>问题出在哪里？第4行中的<code>instance= new MySingleton()</code>至少包含三个步骤：</p>
<ol>
<li>为<code>MySingleton</code>分配内存。</li>
<li>初始化<code>MySingleton</code>对象。</li>
<li>引用完全初始化的<code>MySingleton</code>对象。</li>
</ol>
<p>能看出问在哪了么？</p>
<p>C++运行时不能保证这些步骤按顺序执行。例如，处理器可能会将步骤重新排序为序列1、3和2。因此，在第一步中分配内存，在第二步中实例引用一个非初始化的单例。如果此时另一个线程<code>t2</code>试图访问该单例对象并进行指针比较，则比较成功。其结果是线程<code>t2</code>引用了一个非初始化的单例，并且程序行为未定义。</p>
<h2 id="性能测试"><a class="header" href="#性能测试">性能测试</a></h2>
<p>我要测试访问单例对象的开销。对引用测试时，使用了一个单例对象，连续访问4000万次。当然，第一个访问的线程会初始化单例对象，四个线程的访问是并发进行的。我只对性能数字感兴趣，因此我汇总了这四个线程的执行时间。使用一个带范围(<code>Meyers Singleton</code>)的静态变量、一个锁<code>std::lock_guard</code>、函数<code>std::call_once</code>和<code>std::once_flag</code>以及具有顺序一致和获取-释放语义的原子变量进行性能测试。</p>
<p>程序在两台电脑上运行。读过上一节的朋友肯定知道，我的Linux(GCC)电脑上有四个核心，而我的Windows(cl.exe)电脑只有两个核心，用最大级别的优化来编译程序。相关设置的详细信息，参见本章的开头。</p>
<p>接下来，需要回答两个问题：</p>
<ol>
<li>各种单例实现的性能具体是多少?</li>
<li>Linux (GCC)和Windows (cl.exe)之间的差别是否显著?</li>
</ol>
<p>最后，我会将所有数字汇总到一个表中。</p>
<p>展示各种多线程实现的性能数字前，先来看一下串行的代码。C++03标准中，<code>getInstance</code>方法线程不安全。</p>
<pre><code class="language-c++">// singletonSingleThreaded.cpp

#include &lt;chrono&gt;
#include &lt;iostream&gt;

constexpr auto tenMill = 10000000;

class MySingLeton {
public:
  static MySingLeton&amp; getInstance() {
    static MySingLeton instance;
    volatile int dummy{};
    return instance;
  }
private:
  MySingLeton() = default;
  ~MySingLeton() = default;
  MySingLeton(const MySingLeton&amp;) = delete;
  MySingLeton&amp; operator=(const MySingLeton&amp;) = delete;

};

int main() {

  constexpr auto fourtyMill = 4 * tenMill;

  const auto begin = std::chrono::system_clock::now();

  for (size_t i = 0; i &lt;= fourtyMill; ++i) {
    MySingLeton::getInstance();
  }

  const auto end = std::chrono::system_clock::now() - begin;

  std::cout &lt;&lt; std::chrono::duration&lt;double&gt;(end).count() &lt;&lt; std::endl;

}
</code></pre>
<p>作为参考实现，我使用了以<a href="https://en.wikipedia.org/wiki/Scott_Meyers">Scott Meyers</a>命名的Meyers单例。这个实现的优雅之处在于，第11行中的<code>singleton</code>对象是一个带有作用域的静态变量，实例只初始化一次，而初始化发生在第一次执行静态方法<code>getInstance</code>(第10 - 14行)时。</p>
<blockquote>
<p>使用volatile声明变量dummy</p>
<p>当我用最高级别的优化选项来编译程序时，编译器删除了第30行中的<code>MySingleton::getInstance()</code>，因为调用不调用都没有效果，我得到了非常快的执行，但结果错误的性能数字。通过使用<code>volatile</code>声明变量<code>dummy</code>(第12行)，明确告诉编译器不允许优化第30行中的<code>MySingleton::getInstance()</code>调用。</p>
</blockquote>
<p>下面是单线程用例的性能结果。</p>
<p><img src="content/The-Details/Case-Studies/../../../images/detail/Case-Studies/31.png" alt="" /></p>
<p>C++11中，Meyers单例已经线程安全了。</p>
<h2 id="线程安全的meyers单例"><a class="header" href="#线程安全的meyers单例">线程安全的Meyers单例</a></h2>
<p>C++11标准中，保证以线程安全的方式初始化具有作用域的静态变量。Meyers单例使用就是有作用域的静态变量，这样就成了！剩下要做的工作，就是为多线程用例重写Meyers单例。</p>
<p>多线程中的Meyers单例</p>
<pre><code class="language-c++">// singletonMeyers.cpp

#include &lt;chrono&gt;
#include &lt;iostream&gt;
#include &lt;future&gt;

constexpr auto tenMill = 10000000;

class MySingLeton {
public:
  static MySingLeton&amp; getInstance() {
    static MySingLeton instance;
    volatile int dummy{};
    return instance;
  }
private:
  MySingLeton() = default;
  ~MySingLeton() = default;
  MySingLeton(const MySingLeton&amp;) = delete;
  MySingLeton&amp; operator=(const MySingLeton&amp;) = delete;

};

std::chrono::duration&lt;double&gt; getTime() {

  auto begin = std::chrono::system_clock::now();
  for (size_t i = 0; i &lt;= tenMill; ++i) {
    MySingLeton::getInstance();
  }
  return std::chrono::system_clock::now() - begin;

}

int main() {

  auto fut1 = std::async(std::launch::async, getTime);
  auto fut2 = std::async(std::launch::async, getTime);
  auto fut3 = std::async(std::launch::async, getTime);
  auto fut4 = std::async(std::launch::async, getTime);

  const auto total = fut1.get() + fut2.get() + fut3.get() + fut4.get();

  std::cout &lt;&lt; total.count() &lt;&lt; std::endl;

}
</code></pre>
<p>函数<code>getTime</code>中使用单例对象(第24 - 32行)，函数由第36 - 39行中的四个promise来执行，相关future的结果汇总在第41行。</p>
<p><img src="content/The-Details/Case-Studies/../../../images/detail/Case-Studies/32.png" alt="" /></p>
<p>我们来看看最直观的方式——锁。</p>
<h2 id="stdlock_guard"><a class="header" href="#stdlock_guard">std::lock_guard</a></h2>
<p><code>std::lock_guard</code>中的互斥量，保证了能以线程安全的方式初始化单例对象。</p>
<pre><code class="language-c++">// singletonLock.cpp

#include &lt;chrono&gt;
#include &lt;iostream&gt;
#include &lt;future&gt;
#include &lt;mutex&gt;

constexpr auto tenMill = 10000000;

std::mutex myMutex;

class MySingleton {
public:
  static MySingleton&amp; getInstance() {
    std::lock_guard&lt;std::mutex&gt; myLock(myMutex);
    if (!instance) {
      instance = new MySingleton();
    }
    volatile int dummy{};
    return *instance;
  }
private:
  MySingleton() = default;
  ~MySingleton() = default;
  MySingleton(const MySingleton&amp;) = delete;
  MySingleton&amp; operator=(const MySingleton&amp;) = delete;

  static MySingleton* instance;
};

MySingleton* MySingleton::instance = nullptr;

std::chrono::duration&lt;double&gt; getTime() {

  auto begin = std::chrono::system_clock::now();
  for (size_t i = 0; i &lt;= tenMill; ++i) {
    MySingleton::getInstance();
  }
  return std::chrono::system_clock::now() - begin;

}

int main() {

  auto fut1 = std::async(std::launch::async, getTime);
  auto fut2 = std::async(std::launch::async, getTime);
  auto fut3 = std::async(std::launch::async, getTime);
  auto fut4 = std::async(std::launch::async, getTime);

  const auto total = fut1.get() + fut2.get() + fut3.get() + fut4.get();

  std::cout &lt;&lt; total.count() &lt;&lt; std::endl;

}
</code></pre>
<p>这种方式非常的慢。</p>
<p><img src="content/The-Details/Case-Studies/../../../images/detail/Case-Studies/33.png" alt="" /></p>
<p>线程安全单例模式的下一个场景，基于多线程库，并结合<code>std::call_once</code>和<code>std::once_flag</code>。</p>
<h2 id="使用stdonce_flag的stdcall_once"><a class="header" href="#使用stdonce_flag的stdcall_once">使用std::once_flag的std::call_once</a></h2>
<p><code>std::call_once</code>和<code>std::once_flag</code>可以一起使用，以线程安全的方式执行可调用对象。</p>
<pre><code class="language-c++">// singletonCallOnce.cpp

#include &lt;chrono&gt;
#include &lt;iostream&gt;
#include &lt;future&gt;
#include &lt;mutex&gt;
#include &lt;thread&gt;

constexpr auto tenMill = 10000000;

class MySingleton {
public:
  static MySingleton&amp; getInstance() {
    std::call_once(initInstanceFlag, &amp;MySingleton::initSingleton);
    volatile int dummy{};
    return *instance;
  }
private:
  MySingleton() = default;
  ~MySingleton() = default;
  MySingleton(const MySingleton&amp;) = delete;
  MySingleton&amp; operator=(const MySingleton&amp;) = delete;

  static MySingleton* instance;
  static std::once_flag initInstanceFlag;

  static void initSingleton() {
    instance = new MySingleton;
  }
};

MySingleton* MySingleton::instance = nullptr;
std::once_flag MySingleton::initInstanceFlag;

std::chrono::duration&lt;double&gt; getTime() {

  auto begin = std::chrono::system_clock::now();
  for (size_t i = 0; i &lt;= tenMill; ++i) {
    MySingleton::getInstance();
  }
  return std::chrono::system_clock::now() - begin;

}

int main() {

  auto fut1 = std::async(std::launch::async, getTime);
  auto fut2 = std::async(std::launch::async, getTime);
  auto fut3 = std::async(std::launch::async, getTime);
  auto fut4 = std::async(std::launch::async, getTime);

  const auto total = fut1.get() + fut2.get() + fut3.get() + fut4.get();

  std::cout &lt;&lt; total.count() &lt;&lt; std::endl;

}
</code></pre>
<p>下面是具体的性能数字：</p>
<p><img src="content/The-Details/Case-Studies/../../../images/detail/Case-Studies/34.png" alt="" /></p>
<p>继续使用原子变量来实现线程安全的单例。</p>
<h2 id="原子变量"><a class="header" href="#原子变量">原子变量</a></h2>
<p>使用原子变量，让实现变得更具有挑战性，我甚至可以为原子操作指定内存序。基于前面提到的双重检查锁定模式，实现了以下两个线程安全的单例。</p>
<p><strong>顺序一致语义</strong></p>
<p>第一个实现中，使用了原子操作，但没有显式地指定内存序，所以默认是顺序一致的。</p>
<pre><code class="language-c++">// singletonSequentialConsistency.cpp

#include &lt;chrono&gt;
#include &lt;iostream&gt;
#include &lt;future&gt;
#include &lt;mutex&gt;
#include &lt;thread&gt;

constexpr auto tenMill = 10000000;

class MySingleton {
public:
  static MySingleton&amp; getInstance() {
    MySingleton* sin = instance.load(); 
    if (!sin) {
      std::lock_guard&lt;std::mutex&gt;myLock(myMutex);
      sin = instance.load(std::memory_order_relaxed);
      if (!sin) {
        sin = new MySingleton();
        instance.store(sin);
      }
    }
    volatile int dummy{};
    return *instance;
  }
private:
  MySingleton() = default;
  ~MySingleton() = default;
  MySingleton(const MySingleton&amp;) = delete;
  MySingleton&amp; operator=(const MySingleton&amp;) = delete;

  static std::atomic&lt;MySingleton*&gt; instance;
  static std::mutex myMutex;
};


std::atomic&lt;MySingleton*&gt; MySingleton::instance;
std::mutex MySingleton::myMutex;

std::chrono::duration&lt;double&gt; getTime() {

  auto begin = std::chrono::system_clock::now();
  for (size_t i = 0; i &lt;= tenMill; ++i) {
    MySingleton::getInstance();
  }
  return std::chrono::system_clock::now() - begin;

}

int main() {

  auto fut1 = std::async(std::launch::async, getTime);
  auto fut2 = std::async(std::launch::async, getTime);
  auto fut3 = std::async(std::launch::async, getTime);
  auto fut4 = std::async(std::launch::async, getTime);

  const auto total = fut1.get() + fut2.get() + fut3.get() + fut4.get();

  std::cout &lt;&lt; total.count() &lt;&lt; std::endl;

}
</code></pre>
<p>与双重检查锁定模式不同，由于原子操作的默认是顺序一致的，现在可以保证第19行中的<code>sin = new MySingleton()</code>出现在第20行<code>instance.store(sin)</code>之前。看一下第17行：<code>sin = instance.load(std::memory_order_relax)</code>，因为另一个线程可能会在第14行第一个load和第16行锁的使用之间，介入并更改instance的值，所以这里的load是必要的。</p>
<p><img src="content/The-Details/Case-Studies/../../../images/detail/Case-Studies/35.png" alt="" /></p>
<p>我们进一步的对程序进行优化。</p>
<p><strong>获取-释放语义</strong></p>
<p>仔细看看之前使用原子实现单例模式的线程安全实现。第14行中单例的加载(或读取)是一个获取操作，第20行中存储(或写入)是一个释放操作。这两种操作都发生在同一个原子上，所以不需要顺序一致。C++11标准保证释放与获取操作在同一原子上同步，并建立顺序约束。也就是，释放操作之后，不能移动之前的所有读和写操作，并且在获取操作之前不能移动之后的所有读和写操作。</p>
<p>这些都是实现线程安全单例的最低保证。</p>
<pre><code class="language-c++">// singletonAcquireRelease.cpp

#include &lt;chrono&gt;
#include &lt;iostream&gt;
#include &lt;future&gt;
#include &lt;mutex&gt;
#include &lt;thread&gt;

constexpr auto tenMill = 10000000;

class MySingleton {
public:
  static MySingleton&amp; getInstance() {
    MySingleton* sin = instance.load(std::memory_order_acquire);
    if (!sin) {
      std::lock_guard&lt;std::mutex&gt;myLock(myMutex);
      sin = instance.load(std::memory_order_release);
      if (!sin) {
        sin = new MySingleton();
        instance.store(sin);
      }
    }
    volatile int dummy{};
    return *instance;
  }
private:
  MySingleton() = default;
  ~MySingleton() = default;
  MySingleton(const MySingleton&amp;) = delete;
  MySingleton&amp; operator=(const MySingleton&amp;) = delete;

  static std::atomic&lt;MySingleton*&gt; instance;
  static std::mutex myMutex;
};


std::atomic&lt;MySingleton*&gt; MySingleton::instance;
std::mutex MySingleton::myMutex;

std::chrono::duration&lt;double&gt; getTime() {

  auto begin = std::chrono::system_clock::now();
  for (size_t i = 0; i &lt;= tenMill; ++i) {
    MySingleton::getInstance();
  }
  return std::chrono::system_clock::now() - begin;

}

int main() {

  auto fut1 = std::async(std::launch::async, getTime);
  auto fut2 = std::async(std::launch::async, getTime);
  auto fut3 = std::async(std::launch::async, getTime);
  auto fut4 = std::async(std::launch::async, getTime);

  const auto total = fut1.get() + fut2.get() + fut3.get() + fut4.get();

  std::cout &lt;&lt; total.count() &lt;&lt; std::endl;

}
</code></pre>
<p>获取-释放语义与顺序一致内存序有相似的性能。</p>
<p><img src="content/The-Details/Case-Studies/../../../images/detail/Case-Studies/36.png" alt="" /></p>
<p>x86体系结构中这并不奇怪，这两个内存顺序非常相似。我们可能会在<a href="https://en.wikipedia.org/wiki/ARM_architecture">ARMv7</a>或<a href="https://en.wikipedia.org/wiki/PowerPC">PowerPC架构</a>上的看到性能数字上的明显差异。对这方面比较感兴趣的话，可以阅读Jeff Preshings的博客<a href="http://preshing.com">Preshing on Programming</a>，那里有更详细的内容。</p>
<p>##各种线程安全单例实现的性能表现总结</p>
<p>数字很明确，Meyers 单例模式是最快的。它不仅是最快的，也是最容易实现的。如预期的那样，Meyers单例模式比原子模式快两倍。锁的量级最重，所以最慢。<code>std::call_once</code>在Windows上比在Linux上慢得多。</p>
<table><thead><tr><th align="center">操作系统(编译器)</th><th align="center">单线程</th><th align="center">Meyers单例</th><th align="center"><code>std::lock_guard</code></th><th align="center"><code>std::call_once</code></th><th align="center">顺序一致</th><th align="center">获取-释放语义</th></tr></thead><tbody>
<tr><td align="center">Linux(GCC)</td><td align="center">0.03</td><td align="center">0.04</td><td align="center">12.48</td><td align="center">0.22</td><td align="center">0.09</td><td align="center">0.07</td></tr>
<tr><td align="center">Windows(cl.exe)</td><td align="center">0.02</td><td align="center">0.03</td><td align="center">15.48</td><td align="center">1.74</td><td align="center">0.07</td><td align="center">0.07</td></tr>
</tbody></table>
<p>关于这些数字，我想强调一点：这是四个线程的性能总和。因为Meyers单例模式几乎与单线程实现一样快，所以并发Meyers单例模式具有最佳的性能。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="使用cppmem进行优化-1"><a class="header" href="#使用cppmem进行优化-1">使用CppMem进行优化</a></h1>
<p>我们从一个简单的程序开始，然后对其不断地进行改进。这里，使用CppMem验证的每个步骤。<a href="http://svr-pes20-cppmem.cl.cam.ac.uk/cppmem">CppMem</a>是一个交互式工具，用于研究小代码段中C++内存模型的行为。</p>
<p>首先，来写个简单的程序：</p>
<pre><code class="language-c++">// ongoingOptimisation.cpp

#include &lt;iostream&gt;
#include &lt;thread&gt;

int x = 0;
int y = 0;

void writing() {
  x = 2000;
  y = 11;
}

void reading() {
  std::cout &lt;&lt; &quot;y: &quot; &lt;&lt; y &lt;&lt; &quot; &quot;;
  std::cout &lt;&lt; &quot;x: &quot; &lt;&lt; x &lt;&lt; std::endl;
}

int main() {
  std::thread thread1(writing);
  std::thread thread2(reading);
  thread1.join();
  thread2.join();
}
</code></pre>
<p>程序很简单，由两个线程<code>thread1</code>和<code>thread2</code>构成。<code>thread1</code>写入x和y，<code>thread2</code>以相反的顺序读取值y和x。这看起来很简单，但这个简单的程序，却会给了我们三个不同的结果:</p>
<p><img src="content/The-Details/Case-Studies/../../../images/detail/Case-Studies/37.png" alt="" /></p>
<p>对程序优化之前，需要确定两个问题：</p>
<ol>
<li>程序的定义都明确吗？是否存在数据竞争？</li>
<li>x和y可能是哪些值?</li>
</ol>
<p>第一个问题往往很难回答。首先，考虑第一个问题的答案；其次，使用CppMem验证推理。当我想到了第一个问题的答案，就可以很容易地确定第二个问题的答案。我在一个表中给出了x和y的可能值。</p>
<p>但是，还没有解释持续优化是什么意思。其实很简单，通过弱化C++的内存序来不断优化程序。以下是优化步骤：</p>
<ul>
<li>非原子变量</li>
<li>锁</li>
<li>使用顺序一致语义的原子变量</li>
<li>使用获取-释放语义的原子变量</li>
<li>使用自由语义的原子变量</li>
<li>Volatile变量</li>
</ul>
<p>开始持续优化之旅之前，应该先对CppMem有一个基本的了解。在CppMem章节中，会提供了一个简单的介绍。</p>
<h2 id="cppmem-非原子变量"><a class="header" href="#cppmem-非原子变量">CppMem: 非原子变量</a></h2>
<p>使用<code>run</code>按钮可以立即显示数据竞争。更准确地说，上面的程序有两个数据竞争，因为变量<code>x</code>和<code>y</code>的访问都不受保护。因此，该程序具有未定义行为。在C++术语中，这意味着程序在玩火，你的电脑甚至会着火(笑)。</p>
<p>因此，我们不能得到x和y的准确值。</p>
<blockquote>
<p><strong>关于int型的变量</strong></p>
<p>只要int变量是自然对齐的，那么大多数主流架构对int变量的访问都是原子性的。自然对齐意味着在32位或64位体系结构中，32位int变量必须有一个能被4整除的地址。这是因为，C++11中可以调整数据类型的对齐方式。</p>
<p>必须强调的是，我并不是建议你像使用原子int那样使用int型变量。我只是想指出，在这种情况下，编译器比C++11标准提供了更多保证。如果过于依赖于编译器，那么程序就很可能不符合C++标准，因此可能会在其他硬件平台上运行出错。</p>
</blockquote>
<p>这就是我的推理内容。现在，我们应该看看CppMem关于程序未定义行为的报告。</p>
<p>CppMem允许我将程序剪裁到最小。</p>
<pre><code class="language-c++">int main() {
  int x = 0;
  int y = 0;
  { { { {
        x = 2000;
        y = 11;
        }
    |||{
        y;
        x;
       }
  } } }
}
</code></pre>
<p>可以使用大括号(第4行和第12行)和管道符号(第8行)在CppMem中定义一个线程。因为我对变量x和y的输出不感兴趣，所以只在第9行和第10行读取它们。</p>
<p>这是CppMem的理论部分，下面就来实践一下。</p>
<p><strong>分析</strong></p>
<p>执行程序时，CppMem会在(1)处提示，线程交错有四种可能性，其中有一种有竞争的。只有在第一次执行时，结果是一致的。现在，我可以使用CppMem在四个执行(2)之间进行切换，并分析示意图(3)。</p>
<p><img src="content/The-Details/Case-Studies/../../../images/detail/Case-Studies/38.png" alt="" /></p>
<p>通过分析图表，可以最大程度地利用CppMem。</p>
<p><strong>第一次执行</strong></p>
<p><img src="content/The-Details/Case-Studies/../../../images/detail/Case-Studies/39.png" alt="" /></p>
<p>节点表示程序的表达式，箭头表示表达式之间的关系。从图中的注释中我可以得出什么结论呢?</p>
<ul>
<li>a:Wna x = 0：第一个表达式(a)，向非原子变量x中写入0。</li>
<li>sb (前序，sequenced-before)：第一个表达式(a)执行的顺序在第二个表达式(b)之前就能确定。表达式(c)和(d)、(e)和(f)之间也存在这种关系。</li>
<li>rf (读取，read from)：(e)从(b)中读取y的值，(f)从(a)中读取x的值。</li>
<li>sw (同步，synchronizes-with)：因为表达式(f)在一个单独的线程中执行，所以(a)与(f)同步。线程创建之前发生的所有事情都是可见的，而线程的创建可以看作是一个同步点。由于对称性，(b)和(e)之间也存在同样的关系。</li>
<li>dr (数据竞争，data race)：变量x和y的读写之间有数据竞争，所以程序有未定义行为。</li>
</ul>
<blockquote>
<p><strong>为什么顺序一致的执行?</strong></p>
<p>因为x和y在主线程中初始化(a)和(b)，所以执行顺序一致。(c)和(d)中的x和y在内存模型上不是顺序一致的。</p>
</blockquote>
<p>接下来的三次执行，都不是顺序一致的。</p>
<p><strong>第二次执行</strong></p>
<p><img src="content/The-Details/Case-Studies/../../../images/detail/Case-Studies/40.png" alt="" /></p>
<p>(e)从(d)中读取“不一致”的y值，并且(d)的写入与(e)的读取同时发生。</p>
<p><strong>第三次执行</strong></p>
<p><img src="content/The-Details/Case-Studies/../../../images/detail/Case-Studies/41.png" alt="" /></p>
<p>与前一个执行对称，(f)同时从(c)中读取x。</p>
<p><strong>第四次执行</strong></p>
<p><img src="content/The-Details/Case-Studies/../../../images/detail/Case-Studies/42.png" alt="" /></p>
<p>现在，就开始乱套了。(e)和(f)同时从表达式(d)和(c)中读出x和y。</p>
<p><strong>简单的总结一下</strong></p>
<p>虽然我只是使用了CppMem的默认配置，但是获得了很多有价值的信息。特别是CppMem的图形化显示：</p>
<ul>
<li>x和y的所有可能的组合：(0,0)、(11,0)、(0,2000)和(11,2000)。</li>
<li>该程序至少有一个数据竞争，因此会触发未定义行为。</li>
<li>四种可能的执行方式中，只有一种是顺序一致的。</li>
</ul>
<blockquote>
<p><strong>使用volatile</strong></p>
<p>从内存模型的角度来看，对x和y使用限定符volatile与x和y的非同步访问没有区别。</p>
<p>CppMem: 使用volatile的不同步访问</p>
<pre><code class="language-c++">int main() {
volatile int x = 0;
volatile int y = 0;
  { { { 
    {
      x = 2000;
      y = 11;
    }
  ||| 
    {
      y;
      x;
    }
  } } }
}
</code></pre>
<p>CppMem生成与前一个示例相同的图。原因很简单，C++中volatile不具备多线程语义功能。</p>
</blockquote>
<p>这个例子中，x和y的访问没有同步，因此会出现数据竞争，产生未定义行为。最直接的同步方式，当然是使用锁。</p>
<h2 id="cppmem-锁"><a class="header" href="#cppmem-锁">CppMem: 锁</a></h2>
<p>两个线程<code>thread1</code>和<code>thread2</code>都使用了相同的互斥锁，且包装在<code>std::lock_guard</code>中。</p>
<pre><code class="language-c++">// ongoingOptimisationLock.cpp

#include &lt;iostream&gt;
#include &lt;mutex&gt;
#include &lt;thread&gt;

int x = 0;
int y = 0;

std::mutex mut;

void writing() {
  std::lock_guard&lt;std::mutex&gt; guard(mut);
  x = 2000;
  y = 11;
}

void reading() {
  std::lock_guard&lt;std::mutex&gt; guard(mut);
  std::cout &lt;&lt; &quot;y: &quot; &lt;&lt; y &lt;&lt; &quot; &quot;;
  std::cout &lt;&lt; &quot;x: &quot; &lt;&lt; x &lt;&lt; std::endl;
}

int main() {
  std::thread thread1(writing);
  std::thread thread2(reading);
  thread1.join();
  thread2.join();
}
</code></pre>
<p>程序没啥问题，根据(thread1与thread2)执行顺序，要么是读后写，要么是先写后读。下面展示了x和y值的几种可能：</p>
<table><thead><tr><th align="center">y</th><th align="center">x</th><th align="center">有可能吗？</th></tr></thead><tbody>
<tr><td align="center">0</td><td align="center">0</td><td align="center">有</td></tr>
<tr><td align="center">11</td><td align="center">0</td><td align="center"></td></tr>
<tr><td align="center">0</td><td align="center">2000</td><td align="center"></td></tr>
<tr><td align="center">11</td><td align="center">2000</td><td align="center">有</td></tr>
</tbody></table>
<blockquote>
<p><strong>CppMem中使用<code>std::lock_guard</code></strong></p>
<p>我没找到在CppMem中使用<code>std::lock_guard</code>的方法。如果你知道如何实现它，请告诉我一下 ：）</p>
</blockquote>
<p>锁的易用性比较好，但同步性价比太低。接下来使用原子变量，并尝试一种更轻量级的策略。</p>
<h2 id="cppmem-顺序一致语义的原子变量"><a class="header" href="#cppmem-顺序一致语义的原子变量">CppMem: 顺序一致语义的原子变量</a></h2>
<p>如果没有指定的内存序，则使用顺序一致。顺序一致保证每个线程按照源代码顺序执行，并且所有线程都遵循相同的全局序。</p>
<p>这里有个使用原子的优化版本。</p>
<pre><code class="language-c++">// ongoingOptimisationSequentialConsistency.cpp

#include &lt;atomic&gt;
#include &lt;iostream&gt;
#include &lt;thread&gt;

std::atomic&lt;int&gt; x{ 0 };
std::atomic&lt;int&gt; y{ 0 };

void writing(){
  x.store(2000);
  y.store(11);
}

void reading() {
  std::cout &lt;&lt; y.load() &lt;&lt; &quot; &quot;;
  std::cout &lt;&lt; x.load() &lt;&lt; std::endl;
}

int main() {
  std::thread thread1(writing);
  std::thread thread2(reading);
  thread1.join();
  thread2.join();
}
</code></pre>
<p>我们来分析一下这段代码。因为x和y是原子变量，所以没有数据竞争。因此，只剩下一个问题需要回答。x和y可能的值是什么？这个问题也不难，由于顺序一致，所有线程都必须遵循相同的全局序。</p>
<p>实际执行的情况：</p>
<ul>
<li><code>x.store(2000);</code>先行于<code> y.store(11);</code></li>
<li><code>std::cout &lt;&lt; y.load() &lt;&lt; &quot; &quot;;</code>先行于<code>std::cout &lt;&lt; x.load() &lt;&lt; std::endl;</code></li>
</ul>
<p>因此，如果<code>y.load()</code>的值为11，则<code>x.load()</code>的值肯定不能为0，因为<code>x.store(2000)</code>在<code>y.store(11)</code>之前已经执行了。</p>
<p>x和y的其他所有值都是有可能，下面是导致x和y有三组不同值的原因：</p>
<ol>
<li><code>thread1</code>先行完成于<code>thread2 </code></li>
<li><code>thread2</code>先行完成于<code>thread1</code></li>
<li><code>thread1</code> 执行<code>x.store(2000)</code>先行于<code>thread2</code>执行完成</li>
</ol>
<p>那么x和y的所有可能性：</p>
<table><thead><tr><th align="center">y</th><th align="center">x</th><th align="center">有可能吗？</th></tr></thead><tbody>
<tr><td align="center">0</td><td align="center">0</td><td align="center">有</td></tr>
<tr><td align="center">11</td><td align="center">0</td><td align="center"></td></tr>
<tr><td align="center">0</td><td align="center">2000</td><td align="center">有</td></tr>
<tr><td align="center">11</td><td align="center">2000</td><td align="center">有</td></tr>
</tbody></table>
<p>接下来使用CppMem验证一下我的猜想。</p>
<p><strong>CppMem</strong></p>
<pre><code class="language-c++">int main() {
  atomic_int x = 0; 
  atomic_int y = 0;
  {{{ {
        x.store(2000);
        y.store(11);
      }
  |||{
        y.load();
        x.load();
      }
  }}};
  return 0; }
</code></pre>
<p>首先介绍一些语法知识，CppMem为<code>std::atomic&lt;int&gt;</code>专门定义有<code>atomic_int</code>类型。</p>
<p>执行程序时，我被候选执行程序的数量(384个)吓了一跳。</p>
<p><img src="content/The-Details/Case-Studies/../../../images/detail/Case-Studies/43.png" alt="" /></p>
<p>有384个可能的执行候选，只有6个是顺序一致的，没有候选有数据竞争。不过，我只对6个顺序一致的候选感兴趣。</p>
<p>我使用选项(2)获得六个带注解的示意图。</p>
<p>我们已经知道，因为顺序一致，除了<code>y = 11</code>和<code>x = 0</code>外，其他可能值都是可能的。现在我很好奇，哪些线程交错会产生不同的x和y呢?</p>
<p><strong>(y = 0, x = 0)</strong></p>
<p><img src="content/The-Details/Case-Studies/../../../images/detail/Case-Studies/44.png" alt="" /></p>
<p><strong>(y = 0, x = 2000)</strong></p>
<p><img src="content/The-Details/Case-Studies/../../../images/detail/Case-Studies/45.png" alt="" /></p>
<p><img src="content/The-Details/Case-Studies/../../../images/detail/Case-Studies/46.png" alt="" /></p>
<p><img src="content/The-Details/Case-Studies/../../../images/detail/Case-Studies/47.png" alt="" /></p>
<p><img src="content/The-Details/Case-Studies/../../../images/detail/Case-Studies/48.png" alt="" /></p>
<p><strong>(y = 11, x = 2000)</strong></p>
<p><img src="content/The-Details/Case-Studies/../../../images/detail/Case-Studies/49.png" alt="" /></p>
<p>分析还没结束，我感兴趣的是：指令序列与这六个图如何对应?</p>
<p><strong>指令序列</strong></p>
<p>我给每个指令序列分配了相应的图示。</p>
<p><img src="content/The-Details/Case-Studies/../../../images/detail/Case-Studies/50.png" alt="" /></p>
<p>让我们从简单的例子开始分析：</p>
<ul>
<li>(1)：x和y的值为0，因为<code>y.load()</code>和<code>x.load()</code>在操作<code>x.store(2000)</code>和<code>y.store(11)</code>之前完成。</li>
<li>(6): 所有的加载操作都发生在存储操作之后，所以y的值是11，x的值是2000。</li>
<li>(2), (3), (4), (5): 这几个是更有趣的例子，y的值是0，x的值是2000。图中的黄色箭头(sc)是我推理的关键，它们代表指令序列。让我们看看(2)是怎么执行的：
<ul>
<li>(2)中黄色箭头(sc)的顺序是：<code>写入x = 2000</code> ⇒ <code>读取 y = 0 </code>⇒ <code>写入 y = 11</code> ⇒ <code>读取 x = 2000</code>。该序列对应于第二次线程交错(2)时的指令序列。</li>
</ul>
</li>
</ul>
<p>接下来，让我们打破顺序一致的束缚，使用获取-释放语义。</p>
<h2 id="cppmem获取-释放语义的原子变量"><a class="header" href="#cppmem获取-释放语义的原子变量">CppMem：获取-释放语义的原子变量</a></h2>
<p>与线程之间进行同步的顺序一致不同，获取-释放语义的同步，发生在同一原子变量的(原子)操作之间。基于这个前提，获取-释放语义更轻，也更快。</p>
<p>展示一段使用获取-释放语义的代码。</p>
<pre><code class="language-c++">// ongoingOptimisationAcquireRelease.cpp

#include &lt;atomic&gt;
#include &lt;iostream&gt;
#include &lt;thread&gt;

std::atomic&lt;int&gt;x{ 0 };
std::atomic&lt;int&gt; y{ 0 };

void writing() {
  x.store(2000, std::memory_order_relaxed);
  y.store(11, std::memory_order_release);
}

void reading() {
  std::cout &lt;&lt; y.load(std::memory_order_acquire) &lt;&lt; &quot; &quot;;
  std::cout &lt;&lt; x.load(std::memory_order_relaxed) &lt;&lt; std::endl;
}

int main() {
  std::thread thread1(writing);
  std::thread thread2(reading);
  thread1.join();
  thread2.join();
}
</code></pre>
<p>所有的操作都是原子的，所以程序没啥问题。再多看几眼，你会发现更多东西，<code>y</code>上的原子操作附加了<code>std::memory_order_release</code>(第12行)和<code>std::memory_order_acquire</code>标记(第16行)。与之相反，<code>x</code>上的原子操作是用<code>std::memory_order_relax</code>标记(第11行和第17行)，所以<code>x</code>没有同步和顺序约束。<code>x</code>和<code>y</code>可能值，只能由<code>y</code>给出答案了。</p>
<ul>
<li><code>y.store(11,std::memory_order_release)</code>同步于<code>y.load(std::memory_order_acquire)</code></li>
<li><code>x.store(2000,std::memory_order_relaxed)</code>先见于<code>y.store(11, std::memory_order_release)</code></li>
<li><code>y.load(std::memory_order_acquire)</code>先见于<code>x.load(std::memory_order_relaxed)</code></li>
</ul>
<p>进行更详细的描述：关键点在于，第12行<code>y</code>的存储与第16行<code>y</code>的加载是同步的。因为操作发生在相同的原子变量上，所以使用的是获取-释放语义。<code>y</code>在第12行中使用<code>std::memory_order_release</code>，第16行中使用<code>std::memory_order_acquire</code>，因此<code>x.store(2000, std:: memory_order_relax)</code>不能在<code>y.store (std::memory_order_release)</code>之后执行，而<code>x.load()</code>也不能在<code>y.load()</code>之前执行。</p>
<p>获取-释放语义的推理比之前的顺序一致的推理复杂许多，但是<code>x</code>和<code>y</code>的可能值是相同的。只有<code>y == 11</code>和<code>x == 0</code>的组合是不可能的。</p>
<p>有三种可能的线程交错，它们会产生不同<code>x</code>和<code>y</code>：</p>
<ul>
<li><code>thread1</code>先于 <code>thread2</code>执行</li>
<li><code>thread2</code>先于<code> thread1</code>执行</li>
<li><code>thread1</code>执行<code> x.store(2000)</code>先于<code>thread2</code>执行</li>
</ul>
<p>以下是x和y的所有可能值：</p>
<table><thead><tr><th align="center">y</th><th align="center">x</th><th align="center">有可能吗？</th></tr></thead><tbody>
<tr><td align="center">0</td><td align="center">0</td><td align="center">有</td></tr>
<tr><td align="center">11</td><td align="center">0</td><td align="center"></td></tr>
<tr><td align="center">0</td><td align="center">2000</td><td align="center">有</td></tr>
<tr><td align="center">11</td><td align="center">2000</td><td align="center">有</td></tr>
</tbody></table>
<p>继续使用CppMem验证猜想。</p>
<p><strong>CppMem</strong></p>
<pre><code class="language-c++">int main() {
  atomic_int x = 0; 
  atomic_int y = 0;
  {{{ {
        x.store(2000,memory_order_relaxed);
        y.store(11,memory_order_release);
      }
  |||{
        y.load(memory_order_acquire);
        x.load(memory_order_relaxed);
      }
  }}};
}
</code></pre>
<p>我们已经知道，除了(y = 11, x = 0)之外，其他结果都有可能。</p>
<p><strong>可能的执行顺序</strong></p>
<p>这里只引用执行一致的三个图。从图中可以看出，<code>y</code>的存储-释放操作与<code>y的</code>加载- 获取操作之间，有获取-释放语义存在。在主线程或单独的线程中读取<code>y</code>(rf)是没有区别的。图中显示了同步关系，是用一个带sw注释的箭头进行表示的。</p>
<p><strong>(y = 0, x = 0)</strong></p>
<p><img src="content/The-Details/Case-Studies/../../../images/detail/Case-Studies/51.png" alt="" /></p>
<p><strong>(y = 0, x = 2000)</strong></p>
<p><img src="content/The-Details/Case-Studies/../../../images/detail/Case-Studies/52.png" alt="" /></p>
<p><strong>(y = 11, x = 2000)</strong></p>
<p><img src="content/The-Details/Case-Studies/../../../images/detail/Case-Studies/53.png" alt="" /></p>
<p><code>x</code>不一定是原子的?! 好吧，这是我第一个错误的假设，来看下原因。</p>
<h2 id="cppmem原子变量和非原子变量混用"><a class="header" href="#cppmem原子变量和非原子变量混用">CppMem：原子变量和非原子变量混用</a></h2>
<p>获取-释放语义中，典型的误解是假定获取操作正在等待释放操作。基于这个错误的假设，你可能认为<code>x</code>不必是一个原子变量，从而可以进一步优化程序。</p>
<pre><code class="language-c++">// ongoingOptimisationAcquireReleaseBroken.cpp

#include &lt;atomic&gt;
#include &lt;iostream&gt;
#include &lt;thread&gt;

int x = 0;
std::atomic&lt;int&gt; y{ 0 };

void writing() {
  x = 2000;
  y.store(11, std::memory_order_release);
}

void reading() {
  std::cout &lt;&lt; y.load(std::memory_order_acquire) &lt;&lt; &quot; &quot;;
  std::cout &lt;&lt; x &lt;&lt; std::endl;
}

int main() {
  std::thread thread1(writing);
  std::thread thread2(reading);
  thread1.join();
  thread2.join();
}
</code></pre>
<p>该程序在<code>x</code>上有一个数据竞争，因此存在未定义行为。获取-释放语义能够保证<code>y.store(11, std::memory_order_release)</code>(第12行)在<code>y.load(std::memory_order_acquire)</code>(第16行)之前执行，即<code>x = 2000</code>在第17行读取x之前执行。如果没有，读取<code>x</code>的同时，对<code>x</code>进行写入。所以会并发访问一个共享变量，并且其中一个操作是写操作。从程序定义上来说，这就是一场数据争霸。</p>
<p>使用CppMem更清楚地展示我的观点。</p>
<p><strong>CppMem</strong></p>
<pre><code class="language-c++">int main() {
  int x = 0;
  atomic_int y = 0; 
  {{{ {
         x = 2000;
         y.store(11, memory_order_release);
      }
  ||| {
         y.load(memory_order_acquire);
         x;
      }
  }}}
}
</code></pre>
<p>当一个线程正在写<code>x = 2000</code>，而另一个线程正在读x时，就会发生数据竞争。我们在相应的黄色箭头上得到一个dr(数据竞争)。</p>
<p><img src="content/The-Details/Case-Studies/../../../images/detail/Case-Studies/54.png" alt="" /></p>
<p>接下来，就是优化过程中的最后一步了——自由语序。</p>
<h2 id="cppmem-自由语序的原子变量"><a class="header" href="#cppmem-自由语序的原子变量">CppMem: 自由语序的原子变量</a></h2>
<p>宽松的语义对原子操作没有同步和排序约束，仅保证操作的原子性。</p>
<pre><code class="language-c++">// ongoingOptimisationRelaxedSemantic.cpp

#include &lt;atomic&gt;
#include &lt;iostream&gt;
#include &lt;thread&gt;

std::atomic&lt;int&gt; x{ 0 };
std::atomic&lt;int&gt; y{ 0 };

void writing() {
  x.store(2000, std::memory_order_relaxed);
  y.store(11, std::memory_order_relaxed);
}

void reading() {
  std::cout &lt;&lt; y.load(std::memory_order_relaxed) &lt;&lt; &quot; &quot;;
  std::cout &lt;&lt; x.load(std::memory_order_relaxed) &lt;&lt; std::endl;
}

int main() {
  std::thread thread1(writing);
  std::thread thread2(reading);
  thread1.join();
  thread2.join();
}
</code></pre>
<p>对于自由语义，之前的基本问题很容易回答。还记得问题是什么吗</p>
<ol>
<li>程序是否有定义良好的行为?</li>
<li><code>x</code>和<code>y</code>有哪些可能?</li>
</ol>
<p>一方面，<code>x</code>和<code>y</code>的所有操作都是原子的，所以程序是定义良好的。另一方面，对线程可能的交错没有限制。结果可能是<code>thread2</code>以不同的顺序看到<code>thread1</code>上的操作。这是在我们在优化过程中，<code>thread2</code>第一次可以显示<code>x == 0</code>和<code>y == 11</code>，因此所有x和y的组合都有可能。</p>
<table><thead><tr><th align="center">y</th><th align="center">x</th><th align="center">有可能吗？</th></tr></thead><tbody>
<tr><td align="center">0</td><td align="center">0</td><td align="center">有</td></tr>
<tr><td align="center">11</td><td align="center">0</td><td align="center">有</td></tr>
<tr><td align="center">0</td><td align="center">2000</td><td align="center">有</td></tr>
<tr><td align="center">11</td><td align="center">2000</td><td align="center">有</td></tr>
</tbody></table>
<p>我想知道<code>x = 0</code>和<code>y = 11</code>时，CppMem的示意图是怎样的?</p>
<p><strong>CppMem</strong></p>
<pre><code class="language-c++">int main() {
  atomic_int x = 0;
  atomic_int y = 0; 
  {{{ {
         x.store(2000, memory_order_relaxed);
         y.store(11, memory_order_release);
      }
  ||| {
         y.load(memory_order_acquire);
         x.load(memory_order_relaxed);
      }
  }}}
}
</code></pre>
<p>这就是CppMem的程序段，现在来看看产生的关系图表。</p>
<p><img src="content/The-Details/Case-Studies/../../../images/detail/Case-Studies/55.png" alt="" /></p>
<p>尽管<code>x</code>(第5行)的写入顺序排在<code>y</code>(第6行)的写入顺序之前，但仍然会发生<code>x</code>读取值0(第10行)，<code>y</code>读取值11(第9行)的情况。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="总结"><a class="header" href="#总结">总结</a></h1>
<p>使用一个简单的程序，并不断对其进行改进。首先，每一次改进都可能有更多的线程交错，x和y的可能性也会更多。其次，挑战随着每一次改进而增加。CppMem对每次的改进，提供了非常宝贵的参考。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="新特性c2023"><a class="header" href="#新特性c2023">新特性：C++20/23</a></h1>
<p>这章并不像其他章节那样准确。原因有两个：首先，并不是所有的特性都符合C++20/23标准；其次，如果某个特性符合C++20/23标准，那么该特性的接口很可能会改变。我将定期更新这本书，会将C++标准的最新动态和新的建议在这一章进行更新。</p>
<p>本章的目的很简单：让大家了解一下C++中，将会出现的并发特性。</p>
<p><img src="content/The-Details/The-Future-CPP-20-23/../../../images/detail/The-Future-CPP-20-23/1.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="关于执行"><a class="header" href="#关于执行">关于执行</a></h1>
<p>Executor是C++中执行的基本构造块，在执行中扮演如同容器分配器的角色。异步、标准模板库的并行算法、future的协同、任务块的运行、<a href="https://en.cppreference.com/w/cpp/experimental">网络TS(技术规范，technical specification)</a>的提交、调度或延迟调用等功能都会使用到异步执行。此外，因为没有标准化的执行方式，所以“执行”是编程时的基本关注点。</p>
<p>下面是提案<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0761r2.pdf">P0761</a>的示例。</p>
<p>parallel_for的实现</p>
<pre><code class="language-c++">void parallel_for(int facility, int n, function&lt;void(int)&gt; f) {
	if(facility == OPENMP) {
		#pragma omp parallel for
		for(int i = 0; i &lt; n; ++i) {
			f(i);
		}
	}
	else if(facility == GPU) {
		parallel_for_gpu_kernel&lt;&lt;&lt;n&gt;&gt;&gt;(f);
	}
	else if(facility == THREAD_POOL) {
		global_thread_pool_variable.submit(n, f);
	}
}
</code></pre>
<p>这个parallel_for有一些问题：</p>
<ul>
<li>parallel_for这样看起来简单的函数，维护起来其实非常复杂。如果支持新的算法或新的并行范例，会变得越来越复杂。(译者：这里指的是分支中不同平台的实现，如果有新算法或新平台，则函数体会变得越来越臃肿。)</li>
<li>函数的每个分支的同步属性也不同。OpenMP可能会阻塞运行，直到所有的派生线程完成，GPU通常异步运行的，线程池可能阻塞或不阻塞。不完全的同步可能会导致数据竞争或死锁。</li>
<li>parallel_for的限制太多。例如，没有办法使用自定义的线程池替换全局线程池：<code>global_thread_pool_variable.submit(n, f); </code></li>
</ul>
<h2 id="路漫漫其修远兮"><a class="header" href="#路漫漫其修远兮">路漫漫其修远兮</a></h2>
<p>2018年10月，已经提交了很多关于executor的提案了，许多设计非常开放，真期望它们能成为C++23的一部分，或有可能用C++20对单向执行进行标准化。本章主要是基于对executor的<a href="content/The-Details/The-Future-CPP-20-23/%5D(http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0761r2.pdf)">P0761号提案</a>的设计建议，和在<a href="http://open-std.org/JTC1/SC22/WG21/docs/papers/2018/p0443r7.html">P0443</a>和<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1244r0.html">P1244</a>提案中的描述进行的。P0443(统一的executor)中提出了单向执行，它可能是C++20的一部分，P1244(统一的executor的从属执行)提出了从属执行，它可能是C++23的一部分。本章还提到了相对较新的<a href="http://open-std.org/JTC1/SC22/WG21/docs/papers/2018/p1055r0.pdf">P1055</a>提案，“适当executor提案”。</p>
<h2 id="executor是什么"><a class="header" href="#executor是什么">Executor是什么?</a></h2>
<p>什么是executor?executor由一组关于在何处、何时以及如何运行可调用单元的规则组成。</p>
<ul>
<li>何处: 可调用项可以在内部或外部处理器上运行，并且结果是从内部或外部处理器中进行读取。</li>
<li>何时: 可调用项可以立即运行，也可以延迟运行。</li>
<li>如何: 可调用项的可以在CPU或GPU上运行，甚至可以以向量化的方式执行。</li>
</ul>
<p>更正式地说，每个executor都具有与所执行函数相关联的属性。</p>
<p><strong>Executor属性</strong></p>
<p>可以通过两种方式，将这些属性与executor关联起来：<code>execution::require</code>或<code>execution::prefer </code></p>
<ol>
<li>方向性：执行函数可以是“触发即忘”(<code>execution::oneway</code>)、返回一个future(<code>execution::twoway</code>)或返回一个continuation(<code>execution::then</code>)。</li>
<li>基数性：执行函数可以创建一个(<code>execution::single</code>)或多个执行代理(<code>execution::bulk</code>)。</li>
<li>阻塞性：函数可阻塞也可不阻塞，有三个互斥的阻塞属性:<code>execution::blocking.never</code>，<code>execution::blocking.possibly</code>和<code>execution::blocking.always</code>。</li>
<li>持续性：任务可能是由客户端上的线程执行(<code>execution::continuation</code>)，也可能不执行(<code>execution::not_continuation</code>)。</li>
<li>可溯性：指定跟踪未完成的工作(<code>exection::outstanding_work</code>),或不跟踪(<code>execution::outstanding_work.untracked</code>)。</li>
<li>批量进度保证：指定在批量属性，<code>execution::bulk_sequenced_execution</code>、<code>execution::bulk_parallel_execution</code>和<code>execution::bulk_unsequenced_execution</code>，这些属性是互斥的，通过使用这些属性创建的执行代理，可以保证任务的进度。</li>
<li>执行线程映射：将每个执行代理映射到一个新线程(<code>execution::new_thread_execution_mapping</code>)，或者不映射(<code>execution::thread_execution_mapping</code>)。</li>
<li>分配器：将分配器(<code>execution::allocator</code>)与executor关联起来。</li>
</ol>
<p>也可以自己来定义属性。</p>
<blockquote>
<p>Executor是基础构建块</p>
<p>因为executor是执行的构建块，C++的并发性和并行性特性在很大程度上依赖于它们。这也适用于扩展future，网络的<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/n4734.pdf">N4734</a>扩展，甚至是适用于STL的并行算法，以及C++20/23中的新并发特性，如门闩和栅栏、协程、事务性内存和任务块。</p>
</blockquote>
<h2 id="举个例子"><a class="header" href="#举个例子">举个例子</a></h2>
<p><strong>使用Executor</strong></p>
<p>下面的代码片段，展示了executor的用法:</p>
<p><strong>std::async</strong></p>
<pre><code class="language-c++">// get an executor through some means
my_executor_type my_executor = ...
  
// launch an async using my executor
auto future = std::async(my_executor, [] {
	std::cout &lt;&lt; &quot;Hello world, from a new execution agent!&quot; &lt;&lt; std::endl;
});
</code></pre>
<p><strong>STL算法std::for_each</strong></p>
<pre><code class="language-c++">// get an executor through some means
my_executor_type my_executor = ...
  
// execute a parallel for_each &quot;on&quot; my executor
std::for_each(std::execution::par.on(my_executor),
							 data.begin(), data.end(), func);
</code></pre>
<p><strong>网络技术规范：允许客户端连接默认系统Executor</strong></p>
<pre><code class="language-c++">// obtain an acceptor (a listening socket) through some means
tcp::acceptor my_acceptor = ...
  
// perform an asynchronous operation to accept a new connection
acceptor.async_accept(
  [](std::error_code ec, tcp::socket new_connection)
    {
    	...
    }
  );
</code></pre>
<p><strong>网络技术规范：允许客户端连接带有线程池的Executor</strong></p>
<pre><code class="language-c++">// obtain an acceptor (a listening socket) through some means
tcp::acceptor my_acceptor = ...
  
// obtain an executor for a specific thread pool
auto my_thread_pool_executor = ...
  
// perform an asynchronous operation to accept a new connection
acceptor.async_accept(
    std::experimental::net::bind_executor(my_thread_pool_executor,
    [](std::error_code ec, tcp::socket new_connection)
      {
      	...
      }
    )
  );
</code></pre>
<p>网络技术规范<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/n4734.pdf">N4734</a>的<code>std::experimental::net::bind_executor</code>函数允许使用特定的executor。本例中，程序在线程池中执行Lambda函数。</p>
<p>要使用executor ，必须进行获取。</p>
<p><strong>获取Executor</strong></p>
<p>获取Executor的方法有很多。</p>
<p><strong>源于自执行上下文static_thread_pool</strong></p>
<pre><code class="language-c++">// create a thread pool with 4 threads
static_thread_pool pool(4);

// get an executor from the thread pool
auto exec = pool.executor();

// use the executor on some long-running task
auto task1 = long_running_task(exec);
</code></pre>
<p><strong>源自执行策略std:: Execution::par</strong></p>
<pre><code class="language-c++">// get par's associated executor
auto par_exec = std::execution::par.executor();

// use the executor on some long-running task
auto task2 = long_running_task(par_exec);
</code></pre>
<p>**源于系统的Executor **</p>
<p>通常使用线程执行的默认程序。如果有变量没有指定，那就可以使用它。</p>
<p><strong>源于Executor适配器</strong></p>
<pre><code class="language-c++">// get an executor from a thread pool
auto exec = pool.executor();

// wrap the thread pool's executor in a logging_executor
logging_executor&lt;decltype(exec)&gt; logging_exec(exec);

// use the logging executor in a parallel sort
std::sort(std::execution::par.on(logging_exec), my_data.begin(), my_data.end());
</code></pre>
<p>logging_executo是循环executor的包装器。</p>
<h2 id="executor的目标"><a class="header" href="#executor的目标">Executor的目标</a></h2>
<p>提案<a href="http://open-std.org/JTC1/SC22/WG21/docs/papers/2018/p1055r0.pdf">P1055</a>中，executor的目的是什么呢?</p>
<ol>
<li>批量化：权衡可调用单元的转换成本和大小。</li>
<li>异构化：允许可调用单元在异构上下文中运行，并能返回结果。</li>
<li>有序化：可指定调用顺序，可选的顺序有：后进先出<a href="https://en.wikipedia.org/wiki/Stack_(abstract_data_type)">LIFO</a>、先进先出<a href="https://en.wikipedia.org/wiki/FIFO_(computing_and_electronics)">FIFO</a> 、优先级或耗时顺序，甚至是串行执行。</li>
<li>可控化：可调用的对象必须是特定计算资源的目标，可以延迟，也可以取消。</li>
<li>持续化：需要可调用信号来控制异步，这些信号必须指示结果是否可用、是否发生了错误、何时完成或调用方是否希望取消，并且显式启动或停止可调用项也应该是可以的。</li>
<li>层级化：层次结构允许在不增加用例复杂性的情况下添加功能。</li>
<li>可用化：易实现和易使用，应该是主要目标。</li>
<li>组合化：允许用户扩展executor的功能。</li>
<li>最小化：executor中不应该存在任何库外添加的内容。</li>
</ol>
<h2 id="术语"><a class="header" href="#术语">术语</a></h2>
<p>提案<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0761r2.pdf">P0761</a>为可执行单元定义了一些执行的新术语:</p>
<ul>
<li>执行资源：能够执行可调用的硬件和/或软件，执行单元可以是SIMD，也可以是管理大量线程集合的运行时。CPU或GPU的执行资源是异构的，所以它们有不同的限制。</li>
<li>执行上下文：是一个程序对象，表示特定的执行资源集合和这些资源中的执行代理。典型的例子是线程池、分布式运行时或异构运行时。</li>
<li>执行代理：特定执行单元的上下文，该上下文映射到执行资源上的单个可调用单元。典型的例子是CPU线程或GPU执行单元。</li>
<li>执行器：与特定上下文关联的执行对象。提供一个或多个执行函数，用于创建可调用函数对象的执行代理。</li>
</ul>
<h2 id="执行函数"><a class="header" href="#执行函数">执行函数</a></h2>
<p>执行程序可提供一个或多个执行函数，用于创建可调用对象的执行代理。执行程序至少支持以下六个功能中的一个。</p>
<table><thead><tr><th align="center">名称</th><th align="center">基数性</th><th align="center">方向性</th></tr></thead><tbody>
<tr><td align="center">execute</td><td align="center">单个</td><td align="center">oneway</td></tr>
<tr><td align="center">twoway_execute</td><td align="center">单个</td><td align="center">twoway</td></tr>
<tr><td align="center">then_execute</td><td align="center">单个</td><td align="center">then</td></tr>
<tr><td align="center">bulk_execute</td><td align="center">批量</td><td align="center">oneway</td></tr>
<tr><td align="center">bulk_twoway_execute</td><td align="center">批量</td><td align="center">twoway</td></tr>
<tr><td align="center">bulk_then_execute</td><td align="center">批量</td><td align="center">then</td></tr>
</tbody></table>
<p>每个执行函数都有两个属性：基数性和方向性。</p>
<ul>
<li>基数性
<ul>
<li>单个: 创建一个执行代理</li>
<li>批量 : 创建一组执行代理</li>
</ul>
</li>
<li>方向性
<ul>
<li>oneway : 创建执行代理，但不返回结果</li>
<li>twoway : 创建一个执行代理，并返回一个可用于等待执行完成的future</li>
<li>then : 创建一个执行代理，并返回一个可用于等待执行完成的future。给定的future准备好后，执行代理开始执行。</li>
</ul>
</li>
</ul>
<p>让我更简单的解释一下执行功能，他们都有一个可执行单元。</p>
<p><strong>基数性：单个</strong></p>
<p>单个基数性很简单，单向执行函数是以“触发即忘”的方式执行，返回void。它非常类似于“触发即忘”的future，但它不会自动阻止future的销毁。twoway执行函数返回future，可以使用它来获取结果。类似于<code>std::promise</code>，它将返回关联<code>std::future</code>的句柄。这种情况下，执行代理仅在提供的future准备好时才运行。</p>
<p><strong>基数性：批量</strong></p>
<p>批量基数性的情况比较复杂。这些函数创建一组执行代理，每个执行代理调用给定的可调用单元<code>f</code>，它们返回一个结果代理。<code>f</code>的第一个参数是<code>shape</code>参数，它是一个整型，代表代理类型的索引。进一步的参数是结果代理，如果是twoway执行器，那么就和所有代理共享<code>shape</code>代理。用于创建共享代理的参数，其生存期与代理的生存期绑定在一起。因为它们能够通过执行可调用单元产生相应的价值，所以称为代理。客户端负责通过这个结果代理，消除结果的歧义。</p>
<p>使用bulk_then_execute函数时，可调用单元<code>f</code>将其之前的future作为附加参数。因为没有代理是所有者，所以可调用单元<code>f</code>可通过引用获取结果、共享参数和前次结果。</p>
<p><strong>execution::require</strong></p>
<p>如何确保执行程序支持特定的执行功能?</p>
<p>在特殊情况下，你需要对其有所了解。</p>
<pre><code class="language-c++">void concrete_context(const my_oneway_single_executor&amp; ex)
{
  auto task = ...;
  ex.execute(task);
}
</code></pre>
<p>通常情况下，可以使用函数<code>execution::require</code>来申请。</p>
<pre><code class="language-c++">template&lt;class Executor&gt;
void generic_context(const Executor&amp; ex)
{
  auto task = ...;
  // ensure .toway_execute() is available with execution::require()
  execution::require(ex, execution::single, execution::twoway).toway_execute(task);
}
</code></pre>
<h2 id="实现原型"><a class="header" href="#实现原型">实现原型</a></h2>
<p>基于提案<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0443r5.html">P0443R5</a>，executor提案有了具体的实现原型。这个实现原型，可以帮助我们更深入地了解了批量基数。</p>
<pre><code class="language-c++">// executor.cpp

#include &lt;atomic&gt;
#include &lt;experimental/thread_pool&gt;
#include &lt;iostream&gt;
#include &lt;utility&gt;

namespace execution = std::experimental::execution;
using std::experimental::static_thread_pool;
using std::experimental::executors_v1::future;

int main() {

  static_thread_pool pool{ 4 };
  auto ex = pool.executor();

  // One way, single
  ex.execute([] {std::cout &lt;&lt; &quot;We made it!&quot; &lt;&lt; std::endl; });

  std::cout &lt;&lt; std::endl;

  // Two way, single
  future&lt;int&gt; f1 = ex.twoway_execute([] {return 42; });
  f1.wait();
  std::cout &lt;&lt; &quot;The result is: &quot; &lt;&lt; f1.get() &lt;&lt; std::endl;

  std::cout &lt;&lt; std::endl;

  // One way, bulk.
  ex.bulk_execute([](int n, int&amp; sha) {
    std::cout &lt;&lt; &quot;part &quot; &lt;&lt; n &lt;&lt; &quot;: &quot; &lt;&lt; &quot;shared: &quot; &lt;&lt; sha &lt;&lt; &quot;\n&quot;;
    }, 8,
    [] {return 0; }
    );

  std::cout &lt;&lt; std::endl;

  // Two way, bulk, void result
  future&lt;void&gt; f2 = ex.bulk_twoway_execute(
    [](int n, std::atomic&lt;short&gt;&amp; m) {
      std::cout &lt;&lt; &quot;async part &quot; &lt;&lt; n;
      std::cout &lt;&lt; &quot; atom: &quot; &lt;&lt; m++ &lt;&lt; std::endl;
    }, 8,
    [] {},
      [] {
      std::atomic&lt;short&gt; atom(0);
      return std::ref(atom);
    }
    );
  f2.wait();
  std::cout &lt;&lt; &quot;bulk result available&quot; &lt;&lt; std::endl;

  std::cout &lt;&lt; std::endl;

  // Two way, bulk, non-void result.
  future&lt;double&gt; f3 = ex.bulk_twoway_execute(
    [](int n, double&amp;, int&amp;) {
      std::cout &lt;&lt; &quot;async part &quot; &lt;&lt; n &lt;&lt; &quot; &quot;;
      std::cout &lt;&lt; std::this_thread::get_id() &lt;&lt; std::endl;
    }, 8,
    [] {
      std::cout &lt;&lt; &quot;Result factory: &quot;
        &lt;&lt; std::this_thread::get_id() &lt;&lt; std::endl;
      return 123.456; },
      [] {
        std::cout &lt;&lt; &quot;Shared Parameter: &quot;
          &lt;&lt; std::this_thread::get_id() &lt;&lt; std::endl;
        return 0; }
      );
  f3.wait();
  std::cout &lt;&lt; &quot;bulk result is &quot; &lt;&lt; f3.get() &lt;&lt; std::endl;
  
}
</code></pre>
<p>该程序使用具有四个线程的线程池进行执行(第14行和第15行)。第18行和第23行使用单基数的执行函数，并创建两个单基数的代理。第二个是twoway执行函数，因此返回一个结果。</p>
<p>第30、39和56行中的执行函数具有批量基数性。每个函数创建8个代理(第32、43和60行)。第一种情况中，可调用单元会显示索引<code>n</code>和共享值<code>sha</code>，<code>sha</code>是由共享代理在第33行创建的。下一个执行函数<code>bulk_twoway_execute</code>更有趣。虽然它的结果代理返回void，但共享状态是原子变量<code>atom</code>。每个代理将其值增加1(第42行)。通过结果代理，最后一个执行函数(第56到69行)返回123.456。有趣的是，在可调用的执行、结果和共享代理的执行中涉及到多少线程呢？程序的输出显示结果和共享代理运行在同一个线程中，而其他代理运行在不同的线程中。</p>
<p><img src="content/The-Details/The-Future-CPP-20-23/../../../images/detail/The-Future-CPP-20-23/2.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="可协作中断的线程"><a class="header" href="#可协作中断的线程">可协作中断的线程</a></h1>
<p><code>std::jthread</code>代表协作线程，除了C++11添加的<code>std::thread</code>外，<code>std::jthread</code>还可以自动汇入启动的线程，并发出中断信号。它的特性在提案<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p0660r8.pdf">P0660R8</a>中进行了详细描述：可中断的协程。</p>
<h2 id="自动汇入"><a class="header" href="#自动汇入">自动汇入</a></h2>
<p>下面<code>std::thread</code>的行为并不乐观。如果<code>std::thread</code>仍是可汇入的，则在其析构函数中调用<code>std::terminate</code>。如果调用了<code>thre .join()</code>或<code>thre .detach()</code>，则线程<code>thr</code>是可汇入的。</p>
<pre><code class="language-c++">// threadJoinable.cpp

#include &lt;iostream&gt;
#include &lt;thread&gt;

int main() {

  std::cout &lt;&lt; std::endl;
  std::cout &lt;&lt; std::boolalpha;

  std::thread thr{ [] {std::cout &lt;&lt; &quot;Joinable std::thread&quot; &lt;&lt; std::endl; } };

  std::cout &lt;&lt; &quot;thr.joinable(): &quot; &lt;&lt; thr.joinable() &lt;&lt; std::endl;

  std::cout &lt;&lt; std::endl;

}
</code></pre>
<p>程序执行的时候，会崩溃掉。</p>
<p><img src="content/The-Details/The-Future-CPP-20-23/../../../images/detail/The-Future-CPP-20-23/3.png" alt="" /></p>
<p>运行了两次，<code>std::thread</code>都会非法终止。第二次运行时，线程<code>thr</code>有显示了消息:“Joinable std::thread”。</p>
<p>下一个示例中，我将头文件<code>&lt;thread&gt;</code>替换为<code>“jthread.hpp”</code>。并使用C++20标准中的<code>std::jthread</code>。</p>
<pre><code class="language-c++">// jthreadJoinable.cpp

#include &lt;iostream&gt;
#include &quot;jthread.hpp&quot;

int main() {

  std::cout &lt;&lt; std::endl;
  std::cout &lt;&lt; std::boolalpha;

  std::jthread thr{ [] {std::cout &lt;&lt; &quot;Joinable std::thread&quot; &lt;&lt; std::endl; } };

  std::cout &lt;&lt; &quot;thr.joinable(): &quot; &lt;&lt; thr.joinable() &lt;&lt; std::endl;

  std::cout &lt;&lt; std::endl;

}
</code></pre>
<p>现在，如果线程<code>thr</code>会在调用析构时还是可汇入的，则会自动汇入。</p>
<p><img src="content/The-Details/The-Future-CPP-20-23/../../../images/detail/The-Future-CPP-20-23/4.png" alt="" /></p>
<h2 id="中断stdjthread"><a class="header" href="#中断stdjthread">中断std::jthread</a></h2>
<p>为了理解其中的思想，我举一个简单的例子。</p>
<pre><code class="language-c++">// interruptJthread.cpp

#include &quot;jthread.hpp&quot;
#include &lt;chrono&gt;
#include &lt;iostream&gt;

using namespace ::std::literals;

int main() {

  std::cout &lt;&lt; std::endl;

  std::jthread nonInterruptable([] {
    int counter{ 0 };
    while (counter &lt; 10) {
      std::this_thread::sleep_for(0.2s);
      std::cerr &lt;&lt; &quot;nonInterruptable: &quot; &lt;&lt; counter &lt;&lt; std::endl;
      ++counter;
    }
    });

  std::jthread interruptable([](std::stop_token stoken) {
    int counter{ 0 };
    while (counter &lt; 10) {
      std::this_thread::sleep_for(0.2s);
      if (stoken.stop_requested()) return;
      std::cerr &lt;&lt; &quot;interruptable: &quot; &lt;&lt; counter &lt;&lt; std::endl;
      ++counter;
    }
    });

  std::this_thread::sleep_for(1s);

  std::cerr &lt;&lt; std::endl;
  std::cerr &lt;&lt; &quot;Main thread interrupts both jthreads&quot; &lt;&lt; std::endl;
  nonInterruptable.request_stop();
  interruptable.request_stop();

  std::cout &lt;&lt; std::endl;

}
</code></pre>
<p>主程序中启动了两个线程<code>nonInterruptable</code>和<code>interruptable</code>(第13行和第22行)。与线程<code>nonInterruptable</code>不同，线程<code>interruptable </code>会获取一个<code>std::stop_token</code>，并在26行使用它来检查线程是否被中断:<code>stoken.stop_requested()</code>。在中断的情况下返回Lambda函数，然后线程结束。<code>interruptable.request_stop() </code>(第37行)触发线程的结束。而<code>nonInterruptable.request_stop()</code>并没有什么效果。</p>
<p><img src="content/The-Details/The-Future-CPP-20-23/../../../images/detail/The-Future-CPP-20-23/5.png" alt="" /></p>
<p>下面来了解停止令牌、汇入线程和条件变量的更多细节。</p>
<h2 id="停止令牌"><a class="header" href="#停止令牌">停止令牌</a></h2>
<p><code>jthread</code>的附加功能基于<code>std::stop_token</code>、<code>std::stop_callback</code>和<code>std::stop_source</code>。</p>
<p><strong>std::stop_token , std::stop_source 和std::stop_callback</strong></p>
<p><code>std::stop_token</code>、<code>std::stop_callback</code>或<code>std::stop_source</code>使其能够异步请求执行停止，或查询执行是否收到了停止信号。可以将<code>std::stop_token</code>传递给操作，然后使用它来主动轮询停止请求的令牌，或者通过<code>std::stop_callback</code>注册回调。停止请求由<code>std::stop_source</code>发送，这个信号影响所有相关的<code>std::stop_token</code>。<code>std::stop_source</code>、<code>std::stop_token</code>和<code>std::stop_callback</code>共享停止状态的所有权，其中<code>request_stop()</code>、<code>stop_requested()</code>和<code>stop_possible()</code>是原子操作。</p>
<p><code>std::stop_source</code>和<code>std::stop_token</code>组件为停止处理提供了以下属性。</p>
<p><code>std::stop_source src</code>的成员函数</p>
<table><thead><tr><th align="center">成员函数</th><th align="center">功能描述</th></tr></thead><tbody>
<tr><td align="center">src.get_token()</td><td align="center">如果!stop_possible()，则构造一个不共享stop的stop_token对象状态；否则，构造一个stop_token对象，并共享使用*this的停止状态</td></tr>
<tr><td align="center">src.stop_possible()</td><td align="center">如果停止源可以用于请求停止，则为true</td></tr>
<tr><td align="center">src.stop_requested()</td><td align="center">如果其中一个所有者调用了stop_possible()和request_stop()，则为true。</td></tr>
<tr><td align="center">src.request_stop()</td><td align="center">如果!stop_possible()或stop_requested()，则调用没有效果；否则，提出一个停止请求，以便同步调用stop_requested() == true和所有已注册的回调。</td></tr>
</tbody></table>
<p><code> std::stop_token stoken</code>的成员函数</p>
<table><thead><tr><th align="center">成员函数</th><th align="center">功能描述</th></tr></thead><tbody>
<tr><td align="center">stoken.stop_possible()</td><td align="center">如果后续调用stop_required()将永远不会返回true</td></tr>
<tr><td align="center">stoken.stop_requested()</td><td align="center">如果在相关的std::stop_source上调用了request_stop()，则为true，否则为false</td></tr>
</tbody></table>
<p>如果<code>std::stop_token</code>临时禁用了，那么可以用默认构造的令牌替换它。默认构造的令牌无效。下面的代码片段展示了，如何禁用和启用线程接受信号的功能。</p>
<p>临时禁用一个<code>std::stop_token</code></p>
<pre><code class="language-c++">std::jthread jthr([](std::stop_token stoken){
 ...
 std::stop_token interruptDisabled;
 std::swap(stoken, interruptDisabled);
 ...
 std::swap(stoken, interruptDisabled);
 ...
}
</code></pre>
<p><code>std::stop_token interruptDisabled</code>是无效的。这意味着，从第4行到第5行停止令牌被禁用，第6行才启用。</p>
<p>下面的示例展示了回调的用法。</p>
<pre><code class="language-c++">// invokeCallback.cpp

#include &quot;jthread.hpp&quot;
#include &lt;chrono&gt;
#include &lt;iostream&gt;
#include &lt;vector&gt;

using namespace ::std::literals;

auto func = [](std::stop_token stoken) {
  int counter{ 0 };
  auto thread_id = std::this_thread::get_id();
  std::stop_callback callBack(stoken, [&amp;counter, thread_id] {
    std::cout &lt;&lt; &quot;Thread id: &quot; &lt;&lt; thread_id
      &lt;&lt; &quot;; counter : &quot; &lt;&lt; counter &lt;&lt; std::endl;
    });
  while (counter &lt; 10) {
    std::this_thread::sleep_for(0.2s);
    ++counter;
  }
};

int main() {

  std::cout &lt;&lt; std::endl;

  std::vector&lt;std::jthread&gt; vecThreads(10);
  for (auto&amp; thr : vecThreads)thr = std::jthread(func);

  std::this_thread::sleep_for(1s);

  for (auto&amp; thr : vecThreads)thr.request_stop();

  std::cout &lt;&lt; std::endl;

}
</code></pre>
<p>这10个线程中的每个都调用Lambda函数func(第10 - 21行)。第13 - 16行中的回调显示线程id和计数器。由于主线程的睡眠时间为1秒，子线程的睡眠时间为1秒，所以调用回调时计数器为4。<code>request_stop()</code>会在每个线程上触发回调。</p>
<p><img src="content/The-Details/The-Future-CPP-20-23/../../../images/detail/The-Future-CPP-20-23/6.png" alt="" /></p>
<p><strong>汇入线程</strong></p>
<p><code>std::jhread</code>是一个<code>std::thread</code>变种，它具有发出中断信号，并自动汇入的附加功能。为了支持这个功能，它需要一个<code>std::stop_token</code>。</p>
<p><code>std::jthread jthr</code>停止令牌的成员函数</p>
<table><thead><tr><th align="center">成员函数</th><th align="center">功能描述</th></tr></thead><tbody>
<tr><td align="center">jthr.get_stop_source()</td><td align="center">返回stop_token</td></tr>
<tr><td align="center">jthr.request_stop()</td><td align="center">与src.request_stop()相同</td></tr>
</tbody></table>
<p><strong>condition_variable_any成员函数wait的新重载</strong></p>
<p><code>std::condition_variable_any</code>的三个<code>wait</code>变体<code>wait_for</code>和<code>wait_until</code>将有新的重载，新的重载会使用<code>std::stop_token</code>。</p>
<pre><code class="language-c++">template &lt;class Predicate&gt;
 bool wait_until(Lock&amp; lock,
 Predicate pred,
 stop_token stoken);

template &lt;class Clock, class Duration, class Predicate&gt;
 bool wait_until(Lock&amp; lock,
 const chrono::time_point&lt;Clock, Duration&gt;&amp; abs_time,
 Predicate pred,
 stop_token stoken);

template &lt;class Rep, class Period, class Predicate&gt;
 bool wait_for(Lock&amp; lock,
 const chrono::duration&lt;Rep, Period&gt;&amp; rel_time,
 Predicate pred,
 stop_token stoken);
</code></pre>
<p>这个新的重载需要一个谓词函数。该版本在传入的<code>std::stop_token stoken</code>发出中断信号时，得到通知。这三个重载相当于下面的表达式：</p>
<pre><code class="language-c++">// wait_until in lines 1 - 4
while(!pred() &amp;&amp; !stoken.stop_requested()) {
  wait(lock, [&amp;pred, &amp;stoken] {
  	return pred() || stoken.stop_requested();
  });
}
return pred();

// wait_until in lines 6 - 10
while(!pred() &amp;&amp; !stoken.stop_requested() &amp;&amp; Clock::now() &lt; abs_time) {
  cv.wait_until(lock,
  abs_time,
  [&amp;pred, &amp;stoken] {
  	return pred() || stoken.stop_requested();
  });
}
return pred();

// wait_for in lines 12 - 16
return wait_until(lock, chrono::steady_clock::now() + rel_time, std::move(pred), std\
::move(stoken));
</code></pre>
<p>调用<code>wait</code>之后，可以对停止请求进行检查。</p>
<pre><code class="language-c++">cv.wait_until(lock, predicate, stoken);
if (stoken.stop_requested()){
	// interrupt occurred
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="原子智能指针-1"><a class="header" href="#原子智能指针-1">原子智能指针</a></h1>
<p><code>std::shared_ptr</code>由控制块和相关资源组成。<code>std::shared_ptr</code>能够保证控制块是线程安全的，但是对相关资源的访问就不是了。这意味着，修改引用计数器是一个原子操作，可以确保资源删除一次。</p>
<blockquote>
<p><strong>线程安全的重要性</strong> </p>
<p>这里只说明<code>std::shared_ptr</code>具有定义良好的多线程语义是有多么重要。乍一看，使用<code>std::shared_ptr</code>并不是多线程程序的明智选择。根据定义，它是共享和可变的，是数据竞争和未定义行为的理想对象。另一方面，现代C++中有一条准则：不要接触内存。这意味着在多线程程序中，要尽可能使用智能指针。</p>
</blockquote>
<p>关于原子智能指针的<a href="http://wg21.link/n4162">N4162</a>提议，直接解决了当前智能指针实现的缺陷。这些缺陷可以归结为以下三点：一致性、正确性和高效性。下面将概述这三点，详系内容可参见提案N4162。</p>
<ul>
<li>一致性：<code>std::shared_ptr</code>对非原子数据类型，只能进行原子操作。</li>
<li>正确性：因为正确的使用方式是基于严格的规则，所以使用全局性的原子操作非常容易出错。很容易忘记使用原子操作——例如，使用<code>ptr = localPtr</code>代替<code>std::atomic_store(&amp;ptr, localPtr)</code>。由于数据竞争，结果是未定义的。如果使用原子智能指针，系统将不允许数据竞争的出现。</li>
<li>高效性：与<code>atomic_*</code>函数相比，原子智能指针有很大的优势。原子版本是为特殊用例设计的，可以在内部使用<code>std::atomic_flag</code>作为一种低开销的自旋锁。如果将指针函数的非原子版设计为线程安全的，并用于单线程场景，那就太大材小用了，并且还会受到性能上的惩罚。</li>
</ul>
<p>对我来说，正确性是最重要的。为什么?答案就在提案中。这个建议提供了一个线程安全的单链表，它支持插入、删除和搜索元素，并且这个单链表以无锁的方式实现。</p>
<h2 id="线程安全的单链表"><a class="header" href="#线程安全的单链表">线程安全的单链表</a></h2>
<p><img src="content/The-Details/The-Future-CPP-20-23/../../../images/detail/The-Future-CPP-20-23/7.png" alt="" /></p>
<p>需要使用C++11编译器编译的地方都用红色标记。这个链表，使用原子智能指针实现要容易得多，也不容易出错。C++20的类型系统不允许在原子智能指针上使用非原子操作。</p>
<p><a href="http://wg21.link/n4162">N4162</a>提议将<code>std::atomic_shared_ptr</code>和<code>std::atomic_weak_ptr</code>作为原子智能指针。将它们合并到主流的ISO C++标准中，就变成了<code>std::atomic</code>: <code>std::atomicstd::shared_ptr&lt;T&gt;</code>和<code>std::atomicstd::weak_ptr&lt;T&gt;</code>偏特化模板。</p>
<p>因此，<code>std::shared_ptr</code>的原子操作在C++20中是废弃的。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="扩展特性"><a class="header" href="#扩展特性">扩展特性</a></h1>
<p>promise和future形式的任务在C++11中的名声很微妙。一方面，它们比线程或条件变量更容易使用；另一方面，也有明显的不足——不能合成。C++20/23中弥补了这个缺陷。</p>
<p>我曾经以<code>std::async</code>、<code>std::packaged_task</code>或<code>std::promise</code>和<code>std::future</code>的形式，写过关于任务的文章。C++20/23中，我们可以使用加强版的future。</p>
<h2 id="并发技术标准-v1"><a class="header" href="#并发技术标准-v1">并发技术标准 v1</a></h2>
<p><strong>std::future</strong></p>
<p>扩展future很容易解释。首先，扩展了C++11的<code>std::future</code>接口；其次，一些新功能可组合创建特殊的future。先从第一点开始说起：</p>
<p>扩展future有三种新特性:</p>
<ul>
<li>展开构造函数，可用于展开已包装的外部future(<code>future&lt;future&lt;T&gt;&gt;</code>)。</li>
<li>如果共享状态可用，则返回谓词is_ready。</li>
<li>添加了可延续附加到future的方法。</li>
</ul>
<p>起初，future的状态可以是valid或ready。</p>
<p><strong>valid与ready</strong></p>
<ul>
<li>valid: 如果future具有共享状态(带有promise)，那么它就是有效的。这并不是必须的，因为可以默认构造一个没有promise的<code>std::future</code>。</li>
<li>ready: 如果共享状态可用，future就已经准备好了。换句话说，如果promise已经完成，则future就已经准备好了。</li>
</ul>
<p>因此，<code>(valid == true)</code>是<code>(ready == true)</code>的一个必要不充分条件。</p>
<p>我对promise和future的建模就是数据通道的两个端点。</p>
<p><img src="content/The-Details/The-Future-CPP-20-23/../../../images/detail/The-Future-CPP-20-23/8.png" alt="" /></p>
<p>现在，valid和ready的区别就非常自然了。如果有一个数据通道的promise，则future的状态是valid。如果promise已经将其结果放入数据通道中，则future的状态是ready。</p>
<p>现在，为了延迟future，我们来了解一下then。</p>
<p><strong>使用then的延迟</strong></p>
<p>then具有将一个future附加到另一个future的能力，这样一个future就能被另一个future所嵌套。展开构造函数的任务是对外部future进行展开的。</p>
<blockquote>
<p><strong>N3721提案</strong></p>
<p>迎来第一个代码段之前，必须介绍一下<a href="https://isocpp.org/files/papers/N3721.pdf">N3721</a>提案。本节的大部分内容是关于“<code>std::future&lt;T&gt;</code>和相关API”的改进建议。奇怪的是，提案作者最初没有使用<code>get</code>获取future最后的结果。因此，我在示例添加了<code>res.get</code>，并将结果保存在变量<code>myResult</code>中，并修正了一些错别字。</p>
</blockquote>
<pre><code class="language-c++">#include &lt;future&gt;
using namespace std;
int main() {

  future&lt;int&gt; f1 = async([]() {return123; });
  future&lt;string&gt; f2 = f1.then([](future&lt;int&gt; f) {
    return to_string(f.get()); // here .get() won't block
    });

  auto myResult = f2.get();

}
</code></pre>
<p><code>to_string(f.get())</code>(第7行)和<code>f2.get()</code>(第10行)之间有细微的区别。正如我在代码片段中已经提到的：第一个调用是非阻塞/异步的，第二个调用是阻塞/同步的。<code>f2.get() </code>会一直等待，直到future链的结果可用。这种方法也适用于长链似的调用：<code>f1.then(…).then(…).then(…).then(…).then(…)</code>。最后，阻塞式调用<code>f2.get()</code>获取结果。</p>
<p><strong>std::async , std::packaged_task和std::promise</strong></p>
<p>关于<code>std::async</code>、<code>std::package_task</code>和<code>std::promise</code>的扩展没有太多可说的。那为什么还要提一下，是因为在C++ 20/23中这三种扩展都会返回扩展了的future。</p>
<p>future的构成令人越来越兴奋了，现在我们可以组合异步任务了。</p>
<p><strong>创建新future</strong></p>
<p>C++20获得了四个用于创建新future的新函数。这些函数是<code>std::make_ready_future</code>、<code>std::make_execptional_future</code>、<code>std::when_all</code>和<code>std::when_any</code>。首先，让我们看看<code>std::make_ready_future</code>和<code>std::make_exceptional_future</code>。</p>
<p><strong>std::make_ready_future和std::make_exceptional_future</strong></p>
<p>这两个功能都立即创建了一个处于ready状态的future 。第一种情况下，future是有价值的；第二种情况下是出现了异常。一开始看起来很奇怪的事情，但细想却很有道理。C++11中，创建一个future需要promise。即使共享状态可用，这也是必要的。</p>
<p>使用make_ready_future创建future</p>
<pre><code class="language-c++">future&lt;int&gt; compute(int x) {
  if (x &lt; 0) return make_ready_future&lt;int&gt;(-1);
  if (x == 0) return make_ready_future&lt;int&gt;(0);
  future&lt;int&gt; f1 = async([]() { return do_work(x); });
  return f1;
}
</code></pre>
<p>因此，如果(x &gt; 0)保持不变，则只能通过promise来计算结果。</p>
<p>简短说明一下：这两个函数都是单子(monad)中返回的函数挂件。现在，让我们从future的合成开始说起。</p>
<p><strong>std::when_any和std::when_all</strong></p>
<p>这两种功能有很多共同之处。首先，来看看输入：</p>
<pre><code class="language-c++">template &lt; class InputIt &gt;
auto when_any(InputIt first, InputIt last)
	-&gt; future&lt;when_any_result&lt;
		std::vector&lt;typename std::iterator_traits&lt;InputIt&gt;::value_type&gt;&gt;&gt;;

template &lt; class... Futures &gt;
auto when_any(Futures&amp;&amp;... futures)
	-&gt; future&lt;when_any_result&lt;std::tuple&lt;std::decay_t&lt;Futures&gt;...&gt;&gt;&gt;;

template &lt; class InputIt &gt;
auto when_all(InputIt first, InputIt last)
	-&gt; future&lt;std::vector&lt;typename std::iterator_traits&lt;InputIt&gt;::value_type&gt;&gt;;

template &lt; class... Futures &gt;
auto when_all(Futures&amp;&amp;... futures)
	-&gt; future&lt;std::tuple&lt;std::decay_t&lt;Futures&gt;...&gt;&gt;;
</code></pre>
<p>这两个函数都接受一对关于future范围的迭代器，或任意数量的future迭代器。二者最大的区别是，在使用迭代器对的情况下，future必须是相同类型的；而对于任意数量的future，可以使用不同类型的future，甚至可以混用<code>std::future</code>和<code>std::shared_future</code>。</p>
<p>函数的输出，取决于是否使用了一对迭代器或任意数量的future(可变参数模板)。这两个函数都返回一个future。如果使用一对迭代器，将得到<code>std::vector</code>: <code>future&lt;vector&lt;future&lt;R&gt;&gt;&gt;</code>中的future。如果使用可变参数模板，会得到<code>std::tuple</code>: <code>future&lt;tuple&lt;future&lt;R0&gt;, future&lt;R1&gt;,…&gt;&gt;</code>。</p>
<p>已经了解了它们的共性。如果所有输入future(when_all)或任何输入future(when_any)都处于ready状态，那么这两个函数返回的future也就处于ready状态。</p>
<p>接下来的两个例子，会展示<code>std::when_all</code>和<code>std::when_any</code>的用法。</p>
<p><strong>std::when_all</strong></p>
<p>Future的组合与<code>std::when_all</code></p>
<pre><code class="language-c++">#include &lt;future&gt;

using namespace std;

int main() {

  shared_future&lt;int&gt; shared_future1 = async([] {return intResult(123); });
  future&lt;string&gt; future2 = async([]() {return stringResult(&quot;hi&quot;); });

  future&lt;tuple&lt;shared_future&lt;int&gt;, future&lt;string&gt;&gt;&gt;all_f =
    when_all(shared_future1, future2);

  future&lt;int&gt; result = all_f.then(
    [](future&lt;tuple&lt;shared_future&lt;int&gt;, future&lt;string&gt;&gt;&gt; f) {
      return doWork(f.get());
    });

  auto myResult = result.get();
}
</code></pre>
<p><code>future all_f</code>(第10行)由future的<code>shared_future1</code>(第7行)和<code>future2</code>(第8行)组成。如果所有future都准备好了，则执行第13行获取future的结果。本例中，将执行第15行中的<code>all_f</code>。结果保存在future中，可以在第18行进行获取。</p>
<p><strong>std::when_any</strong></p>
<p>Future的组合与std::when_any</p>
<pre><code class="language-c++">#include &lt;future&gt;
#include &lt;vector&gt;

using namespace std;

int main() {

  vector&lt;future&lt;int&gt;&gt; v{ ..... };
  auto future_any = when_any(v.begin(), v.end());

  when_any_result&lt;vector&lt;future&lt;int&gt;&gt;&gt; result = future_any.get();

  future&lt;int&gt;&amp; read_future = result.futures[result.index];

  auto myResult = ready_future.get();
}
</code></pre>
<p>when_any中的future可以在第11行中获取结果。<code>result</code>会提供已经准备就绪future的信息。如果不使用when_any_result，就没必要查询每个future是否处于ready状态了。</p>
<p>如果它的某个输入future处于ready状态，那么future_any就处于ready状态。第11行中的<code>future_any.get()</code>会返回future的结果。通过使用<code>result.futures[result.index]</code>(第13行)，可以获取ready_future，并且由于使用<code>ready_future.get()</code>，也可以对任务的结果进行查询。</p>
<p>如<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0701r1.html">P0701r1</a>中描述，“它们没想象的那样通用、有表现力或强大”，其既不是标准化的future，也不是并发的<a href="http://en.cppreference.com/w/cpp/experimental/concurrency">TS v1 future</a>。此外，执行者作为执行的基本构件，必须与新的future相统一。</p>
<h2 id="统一的future"><a class="header" href="#统一的future">统一的Future</a></h2>
<p>标准化和并发TSv1的future有什么缺点吗?</p>
<p><strong>缺点</strong></p>
<p>上述文件(P0701r1)很好地说明了future的不足之处。</p>
<p><strong>future/promise不应该耦合到std::thread执行代理中</strong></p>
<p>C++11只有一个executor:<code>std::thread</code>。因此，future和<code>std::thread</code>是不可分割的。这种情况在C++17和STL的并行算法中得到了改变，新的executor中变化更大，并可以使用它来配置future。例如，future可以在单独的线程中运行，也可以在线程池中运行，或者只是串行运行。</p>
<p><strong>在哪里持续调用了.then ?</strong></p>
<p>下面的例子中，有一个简单的延续。</p>
<p>使用<code>std::future</code>的延续</p>
<pre><code class="language-c++">future&lt;int&gt; f1 = async([]() { return 123; });
future&lt;string&gt; f2 = f1.then([](future&lt;int&gt; f) {
	return to_string(f.get());
});
</code></pre>
<p>问题是：延续应该在哪里运行?有一些可能性:</p>
<ol>
<li>消费端：消费者执行代理总是执行延续。</li>
<li>生产端：生产者执行代理总是执行延续。</li>
<li>inline_executor语义：如果在设置延续时，共享状态已就绪，则使用者线程将执行该延续。如果在设置延续时，共享状态还没有准备好，则生产者线程将执行该延续。</li>
<li>thread_executor语义：使用新<code>std::thread</code>执行延续。</li>
</ol>
<p>前两种可能性有一个显著的缺点：它们会阻塞。第一种情况下，使用者阻塞，直到生产者准备好为止。第二种情况下，生产者阻塞，直到消费者准备好。</p>
<p>下面是文档<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0701r1.html">P0701r1</a>中的一些不错的executor传播用例:</p>
<pre><code class="language-c++">auto i = std::async(thread_pool, f).then(g).then(h);
// f, g and h are executed on thread_pool.

auto i = std::async(thread_pool, f).then(g, gpu).then(h);
// f is executed on thread_pool, g and h are executed on gpu.

auto i = std::async(inline_executor, f).then(g).then(h);
// h(g(f())) are invoked in the calling execution agent.
</code></pre>
<p><strong>将future传递给.then的延续是不明智的</strong></p>
<p>因为传递给continuation的是future，而不是它的值，所以语法非常复杂。越多的传递会让表达式变得非常复杂。</p>
<pre><code class="language-c++">std::future&lt;int&gt; f1 = std::async([]() { return 123; });
std::future&lt;std::string&gt; f2 = f1.then([](std::future&lt;int&gt; f) {
	return std::to_string(f.get());
});
</code></pre>
<p>现在，我假设这个值可以传递，因为<code>std::future&lt;int&gt;</code>重载了<code>to_string</code>。</p>
<p>使用<code>std::future</code>传递值的延续</p>
<pre><code class="language-c++">std::future&lt;int&gt; f1 = std::async([]() { return 123; });
std::future&lt;std::string&gt; f2 = f1.then(std::to_string);
</code></pre>
<p><strong>when_all和when_any的返回类型让人费解</strong></p>
<p>介绍<code>std::when_all</code>和<code>std::when_any</code>的这两章，展示了它们相当复杂的使用方法。</p>
<p><strong>future析构中的条件块必须去掉</strong></p>
<p>触发即忘的future看起来非常有用，但也有一个很大的限制。由<code>std::async</code>创建的future会等待它的析构函数，直到对应的promise完成。看起来并发的东西，实际是串行运行的。根据文档P0701r1的观点，这是不可接受的，并且非常容易出错。</p>
<p>我在参考章节中描述了触发即忘future的特殊行为。</p>
<p><strong>当前值和future值应该易于组合</strong></p>
<p>C++11中，没有简易的方法来创建future，必须从promise开始。</p>
<p>在当前标准中创造future </p>
<pre><code class="language-c++">std::promise&lt;std::string&gt; p;
std::future&lt;std::string&gt; fut = p.get_future();
p.set_value(&quot;hello&quot;);
</code></pre>
<p>这可能会因为并发技术规范v1中的<code>std::make_ready_future</code>函数而改变。</p>
<p>使用并发TS v1标准创建future</p>
<pre><code class="language-c++">std::future&lt;std::string&gt; fut = make_ready_future(&quot;hello&quot;);
</code></pre>
<p>使用future和非future参数将使我们的工作更加舒服。</p>
<pre><code class="language-c++">bool f(std::string, double, int);

std::future&lt;std::string&gt; a = /* ... */;
std::future&lt;int&gt; c = /* ... */;

std::future&lt;bool&gt; d1 = when_all(a, make_ready_future(3.14), c).then(f);
// f(a.get(), 3.14, c.get())

std::future&lt;bool&gt; d2 = when_all(a, 3.14, c).then(f);
// f(a.get(), 3.14, c.get())
</code></pre>
<p>并发技术标准v1中，<code>d1</code>和<code>d2</code>都是不可能的。</p>
<p><strong>五个新概念</strong></p>
<p>提案<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1054r0.html">1054R0</a>提出了future和promise的5个新概念。</p>
<ul>
<li>FutureContinuation：使用future的值或异常作为参数调用的可调用对象。</li>
<li>SemiFuture：它可以被绑定到一个执行器上，并产生一个<code>ContinuableFuture</code>的操作<code>(f = sf.via(exec))</code>。</li>
<li>ContinuableFuture：它细化了SemiFuture，实例可以在<code>(f.then(c))</code>上附加一个<code>FutureContinuation</code>。当future处于ready状态时，就会在future关联执行器上执行。</li>
<li>SharedFuture：它细化了ContinuableFuture，实例可以附加多个FutureContinuation。</li>
<li>Promise：每一个promise都与一个future相关联，当future中设置好一个值或一个异常时，future处于ready状态。</li>
</ul>
<p>文章还对这些新概念进行了详细描述。</p>
<p>future和promise的五个新概念</p>
<pre><code class="language-c++">template &lt;typename T&gt;
struct FutureContinuation
{
  // At least one of these two overloads exists:
  auto operator()(T value);
  auto operator()(exception_arg_t, exception_ptr exception);
};

template &lt;typename T&gt;
struct SemiFuture
{
  template &lt;typename Executor&gt;
  ContinuableFuture&lt;Executor, T&gt; via(Executor&amp;&amp; exec) &amp;&amp;;
};

template &lt;typename Executor, typename T&gt;
struct ContinuableFuture
{
  template &lt;typename RExecutor&gt;
  ContinuableFuture&lt;RExecutor, T&gt; via(RExecutor&amp;&amp; exec) &amp;&amp;;
  
  template &lt;typename Continuation&gt;
  ContinuableFuture&lt;Executor, auto&gt; then(Continuation&amp;&amp; c) &amp;&amp;;
};

template &lt;typename Executor, typename T&gt;
struct SharedFuture
{
  template &lt;typename RExecutor&gt;
  ContinuableFuture&lt;RExecutor, auto&gt; via(RExecutor&amp;&amp; exec);
  
  template &lt;typename Continuation&gt;
  SharedFuture&lt;Executor, auto&gt; then(Continuation&amp;&amp; c);
};

template &lt;typename T&gt;
struct Promise
{
  void set_value(T value) &amp;&amp;;
  
  template &lt;typename Error&gt;
  void set_exception(Error exception) &amp;&amp;;
  
  bool valid() const;
};
</code></pre>
<p>根据这些概念，提出一些意见:</p>
<ul>
<li>可以使用值或异常调用FutureContinuation。它是一个可调用的单元，使用future的值或异常。</li>
<li>所有future(SemiFuture 、ContinuableFuture和SharedFuture)都有一个方法，可以通过该方法指定一个执行器并返回一个ContinuableFuture，并且可以通过使用不同的执行程序将一种future类型转换为另一种类型。</li>
<li>只有一个ContinuableFuture或SharedFuture有then方法用来继续。then方法可以接受FutureContinuation，并返回ContinuableFuture。</li>
<li>SharedFuture是一个可复制的future 。</li>
<li>Promise可以设置值或异常。</li>
</ul>
<p><strong>未完成的工作</strong></p>
<p><a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1054r0.html">提案1054R0</a>中为未来留下了几个需要完成的工作：</p>
<ul>
<li>future和promise还有前进空间。</li>
<li>非并发执行代理使用future和promise时需要同步。</li>
<li><code>std::future/std::promise</code>的互操作性.</li>
<li>future的展开，支持包括<code>future&lt;future&lt;T&gt;&gt;</code>的更高级形式。</li>
<li>when_all/when_any/when_n </li>
<li>async </li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="门闩和栅栏-1"><a class="header" href="#门闩和栅栏-1">门闩和栅栏</a></h1>
<p>门闩和栅栏是比较简单的线程同步机制，其能使一些线程阻塞，直到计数器变为零时解除阻塞。首先，不要把栅栏和内存栅栏混为一谈。C++ 20/23中，我们假设有三种门闩和栅栏：<code>std::latch</code>、<code>std::barrier</code>和<code>std::flex_barrier</code>。</p>
<p>首先，要回答两个问题:</p>
<ol>
<li>这三种同步线程的机制有什么不同?<code>std::latch</code>只能使用一次，但是<code>std::barrier</code>和<code>std::flex_barrier</code>可以使用多次。此外，<code>std::flex_barrier</code>允许计数器变为0时执行一个函数。</li>
<li>哪些支持的门闩和栅栏的用例，在C++11和C++14中无法通过future、线程或条件变量与锁结合来实现呢?门闩和栅栏并不涉及新的用例，但它们使用起来要容易得多。通常是在内部使用无锁机制，所以它们还具有更高的性能。</li>
</ol>
<p>##std::latch</p>
<p><code>std::latch</code>门闩是一个倒计时器，该值可以在构造函数中设置。门闩可以通过使用<code>latch.count_down_and_wait</code>来减小计数，并阻塞线程，直到计数器变为0。另外，<code>latch.count_down(n)</code>可以将计数器减少n，而不进行阻塞。如果没有给出参数，n默认为1。门闩也有<code>latch.is_ready</code>可以用来检查计数器是否为零，以及<code>latch.wait</code>会阻塞线程，直到计数器变为零。<code>std::latch</code>的计数器不能增加或重置，因此不能复用。</p>
<p>下面是来自<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4204.html">N4204提案</a>的一个简短代码段。</p>
<pre><code class="language-c++">void DoWork(threadpool *pool){
  latch completion_latch(NTASKS);
  for (int i = 0; i &lt; NTASKS; ++i){
    pool-&gt;add_task([&amp;]{
      // perform work
    	...
    	completion_latch.count_down();
    }); 
  }
  // Block until work is done
  completion_latch.wait();
}
</code></pre>
<p><code>std::latch completion_latch</code>在其构造函数中将计数器设置为NTASKS (第2行)，线程池执行NTASKS(第4 - 8行)个任务。每个任务结束时(第7行)，计数器递减。第11行是运行DoWork函数的线程，以及工作流的栅栏。这样，线程就会阻塞，直到所有任务都完成。</p>
<p><code>std::barrier</code>与<code>std::latch</code>非常相似。</p>
<p>##std::barrier</p>
<p><code>std::latch</code>和<code>std::barrier</code>之间的区别是，<code>std::barrier</code>计数器可以重置，所以可以多次地使用。计数器变为零之后，立即进入完成阶段。与<code>std::flex_barrier</code>有关，<code>std::barrier</code>有一个空的完成阶段。<code>std::barrier</code>有两个有趣的成员函数：<code>std::arrive_and_wait</code>和<code>std::arrive_and_drop</code>。当<code>std::arrive_and_wait</code>在同步点阻塞时，<code>std::arrive_and_drop</code>会从相关线程集中，删除自己的线程。未指定此函数是否阻塞，直到完成阶段结束。这里没有对函数块进行指定，是否到完成阶段才算结束。</p>
<blockquote>
<p><strong>N4204提案</strong></p>
<p>该建议使用<code>vector&lt;thread*&gt;</code>，并将动态分配的线程推给vector：<code>workers.push_back(new thread([&amp;]{ ... }))</code>。这会产生内存泄漏。应该将线程放到<code>std::unique_ptr</code>中，或者直接在vector中进行创建: <code>workers.emplace_back([&amp;]{ ... })</code>，这个适用于<code>std::barrier</code>和<code>std::flex_barrier</code>。本例中使用<code>std::flex_barrier</code>的名称有点迷，例如：<code>std::flex_barrier</code>被称为<code>notifying_barrier</code>。所以我把名字改成<code>flex_barrier</code>，会更容易理解一些。此外，代表线程数量的<code>n_threads</code>没有初始化，我把它初始化为NTASKS。</p>
</blockquote>
<p>深入研究<code>std::flex_barrier</code>和完成阶段之前，这里给出一个简短的示例，演示<code>std::barrier</code>的用法。</p>
<p><strong>std::barrier</strong></p>
<pre><code class="language-c++">void DoWork(){
  Tasks&amp; tasks;
  int n_threads{NTASKS};
  vector&lt;thread*&gt; workes;
  
  barrier task_barrier(n_threads);
  
  for (int i = 0; i &lt; n_threads; ++i){
    workers.push_back(new thread([&amp;]{
      bool active = ture;
      while(active){
        Task task = tasks.get();
        // perform task
        ...
        task_barrier.arrive_and_wait();
      }
    });
  }
  // Read each stage of the task until all stages are complete.
  while(!finished()){
    GetNextStage(tasks);
  }
}
</code></pre>
<p>第6行中的<code>barrier</code>用于协调多个执行线程，线程的数量是<code>n_threads</code>(第3行)，每个线程通过<code>tasks.get()</code>获取(第12行中)任务，执行该任务并阻塞(第15行)，直到所有线程完成其任务为止。之后，在第12行接受一个新任务，<code>active</code>在第11行返回true。</p>
<p>与<code>std::barrier</code>不同，<code>std::flex_barrier</code>多一个构造函数。</p>
<h2 id="stdflex_barrier"><a class="header" href="#stdflex_barrier">std::flex_barrier</a></h2>
<p>此构造函数接受在完成阶段调用可调用单元。可调用单元必须返回一个数字，使用这个数字设置计数器的值，返回-1意味着计数器在下一次迭代中保持相同的计数器值，而小于-1的数字是不允许的。</p>
<p>完成阶段会执行以下步骤:</p>
<ol>
<li>阻塞全部线程</li>
<li>任意个线程解除阻塞，并执行可调用单元。</li>
<li>如果完成阶段已经完成，那么所有线程都将解除阻塞。</li>
</ol>
<p>下面的段代码展示了<code>std::flex_barrier</code>的用法</p>
<pre><code class="language-c++">void DoWork(){
  Tasks&amp; tasks;
  int initial_threads;
  int n_threads{NTASKS};
  atomic&lt;int&gt; current_threads(initial_threads);
  vector&lt;thread*&gt; workers;
  
  // Create a flex_barrier, and set a lambda that will be
  // invoked every time the barrier counts down. If one or more
  // active threads have completed, reduce the number of threads.
  std::function rf = [&amp;]{return current_threads;};
  flex_barrier task_barrier(n_threads, rf);
  
  for (int i = 0; i &lt; n_threads; ++i){
   workers.push_back(new thread([&amp;]{
     bool active = true;
     while(active) {
       Task task = tasks.get();
       // perform task
     	 ...
       if (finished(task)){
         current_threads--;
         active = false;
       }
       task_barrier.arrive_and_wait();
     }     
    }))； 
  }
  
  // Read each stage of the task until all stages are cpmplete.
  while(!finished()){
    GetNextStage(tasks);
  }
}
</code></pre>
<p>这个例子采用了与<code>std::barrier</code>类似的策略，不同的是这次<code>std::flex_barrier</code>计数器是在运行时进行调整，所以<code>std::flex_barrier task_barrier</code>在第11行获得一个Lambda函数。这个Lambda函数通过引用获取变量current_thread：<code> [&amp;] { return current_threads; }</code>。变量在第21行进行递减，如果线程完成了任务，则将<code>active</code>设置为false。因此，计数器在完成阶段是递减的。</p>
<p>与<code>std::barrier</code>或<code>std::latch</code>相比，<code>std::flex_barrier</code>可以增加计数器。</p>
<p>可以在cppreference.com上阅读关于<a href="http://en.cppreference.com/w/cpp/experimental/latch">std::latch</a>、<a href="http://en.cppreference.com/w/cpp/experimental/barrier">std::barrier</a>、<a href="http://en.cppreference.com/w/cpp/experimental/flex_barrier">std::flex_barrier</a>的更多细节。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="协程-1"><a class="header" href="#协程-1">协程</a></h1>
<p>协程是可以挂起，保持函数执行状态，并可以在之后继续执行的方式。这种方式的演化在C++中算是一种进步，协程大概率是C++20标准的一部分。</p>
<p>本节中介绍的C++20中的新思想，其实已经已经相当古老了。“coroutine”这个词是由<a href="https://en.wikipedia.org/wiki/Melvin_Conway">Melvin Conway</a>创造的，他在1963年关于编译器的出版物中使用了这个词。<a href="https://en.wikipedia.org/wiki/Donald_Knuth">Donald Knuth</a>称程序是协程的一个特例。有时候，有些想法需要一段时间才能被世人接受。</p>
<p>C++20用两个新的关键字co_await和co_yield，扩展了C++函数的执行。</p>
<p>co_await可以挂起表达式，如果在函数<code>func</code>中使用co_await，当调用<code>auto getResult = func()</code>不阻塞时，函数的结果不可用。不是资源消耗式的阻塞，而是资源友好式的等待。</p>
<p>co_yield允许编写一个生成器，生成器每次返回一个新值。生成器是一种数据流，并可以从中选择相应的值。数据流可以是无限的，这样我们就可以使用C++进行惰性求值了。</p>
<h2 id="生成器"><a class="header" href="#生成器">生成器</a></h2>
<p>下面的程序不太难，函数<code>getNumbers</code>返回所有的整数，从开始到结束递增为<code>inc</code>。<code>begin</code>必须小于<code>end</code>，且<code>inc</code>必须是正数。</p>
<p>贪婪生成器</p>
<pre><code class="language-c++">// greedyGenerator.cpp

#include &lt;iostream&gt;
#include &lt;vector&gt;

std::vector&lt;int&gt; getNumbers(int begin, int end, int inc = 1) {

  std::vector&lt;int&gt; numbers;
  for (int i = begin; i &lt; end; i += inc) {
    numbers.push_back(i);
  }
  
  return numbers;

}

int main() {

  std::cout &lt;&lt; std::endl;

  const auto numbers = getNumbers(-10, 11);

  for (auto n : numbers) std::cout &lt;&lt; n &lt;&lt; &quot; &quot;;

  std::cout &lt;&lt; &quot;\n\n&quot;;

  for (auto n : getNumbers(0, 101, 5)) std::cout &lt;&lt; n &lt;&lt; &quot; &quot;;

  std::cout &lt;&lt; &quot;\n\n&quot;;

}
</code></pre>
<p>当然，这里用<code>getNumbers</code>重新发明轮子了，自从C++11以来，这项工作可以使用<a href="http://en.cppreference.com/w/cpp/algorithm/iota">std::iota</a>来完成。</p>
<p>下面是输出：</p>
<p><img src="content/The-Details/The-Future-CPP-20-23/../../../images/detail/The-Future-CPP-20-23/9.png" alt="" /></p>
<p>对这个程序的两个观察结果比较重要：一方面，即使我只对一个有1000个元素的vector的前5个元素感兴趣，第8行的vector也会存放这1000个值。另一方面，很容易将函数<code>getNumbers</code>转换为惰性生成器。</p>
<p>惰性生成器</p>
<pre><code class="language-c++">// lazyGenerator.cpp

#include &lt;iostream&gt;
#include &lt;vector&gt;

generator&lt;int&gt; generatorForNumbers(int begin, int end, int inc = 1) {

  for (int i = begin; i &lt; end; i += inc) {
    co_yield i;
  }

}

int main() {

  std::cout &lt;&lt; std::endl;

  const auto numbers = generatorForNumbers(-10);

  for (int i = 1; i &lt;= 20; ++i) std::cout &lt;&lt; numbers &lt;&lt; &quot; &quot;;

  std::cout &lt;&lt; &quot;\n\n&quot;;

  for (auto n : generatorForNumbers(0, 5)) std::cout &lt;&lt; n &lt;&lt; &quot; &quot;;

  std::cout &lt;&lt; &quot;\n\n&quot;;

}
</code></pre>
<p>当greedyGenerator.cpp中的函数<code>getNumbers</code>返回<code>std::vector&lt;int&gt;</code>时，lazyGenerator.cpp中的协程<code>generatorForNumbers</code>返回生成器。第18行中的生成器编号或第24行的<code>generatorForNumbers(0,5)</code>在请求时，会返回一个新编号，并基于for循环触发查询。更准确地说，协程的查询通过<code>co_yield i</code>返回值<code>i</code>，并立即暂停执行。如果请求一个新值，协程将在该位置恢复执行。</p>
<p>第24行中的<code>generatorForNumbers(0,5)</code>是生成器的直接使用的一种方式。</p>
<p>我想强调一点，协程<code>generatorForNumbers</code>会创建无限的数据流，因为第8行中的for循环没有结束条件。如果值的数量有限(第20行)是可以的，但因为没有结束条件，第24行不会停下来，而会一直运行。</p>
<p>因为协程是C++添加的一个新概念，所以我想聊一聊它的细节。</p>
<h2 id="其他细节"><a class="header" href="#其他细节">其他细节</a></h2>
<p><strong>典型用例</strong></p>
<p>协程是编写<a href="https://en.wikipedia.org/wiki/Event-driven_programming">事件驱动应用</a>的常用方法，可以是模拟、游戏、服务器、用户界面，甚至是算法。协同程序通常用于协作的<a href="https://de.wikipedia.org/wiki/Multitasking">多任务处理</a>，协作式的多任务处理的关键是，每个任务需要多少时间就花多少时间。这与抢占式的多任务形成了对比，我们可以有计划的决定每个任务占用CPU的时间。</p>
<p>协程还有很多种。</p>
<p><strong>基础概念</strong></p>
<p>C++20中的协程是不对称的、优秀的、无堆栈的。</p>
<p>非对称协程的工作流，会返回给调用者，这并不适用于对称协程。对称协同程序，可以将其工作流委托给另一个协同程序。</p>
<p>优秀的协程类似于优秀的函数，因为协序的行为类似于数据。这意味着可以将它们作为函数的参数或返回值，将它们存储在变量中。</p>
<p>无堆栈协程使其能够挂起，并恢复上级协同程序，但此协程不能调用另一个协程。所以，无堆栈协程通常称为可恢复函数。</p>
<p><strong>设计目的</strong></p>
<p>Gor Nishanov描述了协同程序的设计目的：</p>
<p>协程应该具有的能力：</p>
<ul>
<li>高度可扩展性(可到数十亿并发协程)。</li>
<li>具有高效的恢复和挂起，其成本不高于函数的开销。</li>
<li>与现有特性进行无缝，无开销交互。</li>
<li>具有开放的协同程序机制，允许库设计人员开发使用各种高级语义(如生成器、<a href="https://tour.golang.org/concurrency/1">goroutines</a>、任务等)。</li>
</ul>
<p>由于可扩展性和与现有设施的无缝交互的设计理念，所以协同程序是无堆栈的。相反，对于堆栈式协程，在Windows上会保留默认堆栈为1MB，在Linux上会保留默认堆栈为2MB。</p>
<p>将函数变成协程有四种方式。</p>
<p><strong>成为协程</strong></p>
<p>函数使用了协程，就变成了协程：</p>
<ul>
<li>co_return</li>
<li>co_await</li>
<li>co_yield</li>
<li>co_await基于for循环的表达式。</li>
</ul>
<p>这个解释源自提案N4628。</p>
<p>最后，讨论下新的关键字co_return、co_yield和co_await。</p>
<p><strong>co_return , co_yield和co_await</strong></p>
<p>co_return：协程使用co_return作为其返回语句。</p>
<p>co_yield：可以实现一个生成器。这意味着可以创建一个生成器，并生成一个无限的数据流，可以连续地查询值。生成器<code>generator&lt;int&gt; generatorForNumbers(int begin, int inc= 1)</code>的返回类型是<code>generator&lt;int&gt;</code>。<code>generator&lt;int&gt;</code>内部包含一个特殊的<code>promise p</code>，这样调用<code>co_yield i</code>就等于调用<code>co_await p.yield_value(i)</code>。<code>co_yield i</code>可以调用任意次。调用之后，协程立即暂停。</p>
<p>co_await：会让协程挂起，并在之后恢复。<code>co_await exp</code>中的<code>exp</code>必须是可等待的表达式。<code>exp</code>必须实现一个特定的接口，这个接口由<code>await_ready</code>、<code>await_suspend</code>和<code>wait_resume</code>三个函数组成。</p>
<p>co_await的典型用例是事件等待服务器。</p>
<p>阻塞式服务器</p>
<pre><code class="language-c++">Acceptor acceptor{443};
while (true){
  Socket socket= acceptor.accept(); // blocking
  auto request= socket.read(); // blocking
  auto response= handleRequest(request);
  socket.write(response); // blocking
}
</code></pre>
<p>这个服务器非常简单，因为会在同一个线程中依次响应每个请求。服务器监听端口443(第1行)，接受连接(第3行)，读取来自客户机的数据(第4行)，并将应答信息传回客户机(第6行)。第3、4和6行中的所有调用都被阻塞。</p>
<p>由于co_await，阻塞调用现在可以暂停并恢复。</p>
<p>等待式服务器</p>
<pre><code class="language-c++">Acceptor acceptor{443};
while (true){
  Socket socket= co_await acceptor.accept();
  auto request= co_await socket.read();
  auto response= handleRequest(request);
  co_await socket.write(response);
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="事务性内存"><a class="header" href="#事务性内存">事务性内存</a></h1>
<p>事务性内存是基于数据库理论中的事务概念。事务性内存可让使用线程变得更加容易，原因有二：第一，避免数据竞争和死锁；第二，可以组合事务。</p>
<p>事务具有以下属性的操作：原子性(Atomicity)、一致性(Consistency)、独立性(Isolation)和持久性(Durability)(ACID)。除了持久性和存储操作结果之外，所有的属性都适用于C++的事务性内存。现在还有三个问题。</p>
<h2 id="acid"><a class="header" href="#acid">ACI(D)</a></h2>
<p>ACID是数据库事务正确执行的四个基本要素的缩写。</p>
<p>对于由一些语句组成的原子块，原子性、一致性和独立性意味着什么呢?</p>
<p>原子块</p>
<pre><code class="language-c++">atomic{
  statement1;
  statement2;
  statement3;
}
</code></pre>
<p>原子性：执行块中的所有语句或不执行块中任何语句。</p>
<p>一致性：系统始终处于一致的状态，所有事务确定统一的顺序。</p>
<p>独立性：每个事务在完全独立的情况下运行。</p>
<p>如何应用这些属性?事务会记住初始状态，并且在不同步的情况下执行。如果在执行过程中发生冲突，事务将中断，并恢复到初始状态，此回滚操作将再次执行事务。如果事务结束时，初始状态仍然存在，则为提交事务。冲突通常可以通过标记状态的引用来检测。</p>
<p>事务是一种推测行为，只有在初始状态时才会提交。与互斥锁相比，它是一种相对乐观的方法。事务在不同步的情况下执行，只有在没有冲突的情况下才会释放。互斥是一种较为悲观的方法。首先，互斥确保没有其他线程可以进入临界区。接下来，如果线程是互斥量的独占所有者，那么它将进入临界区，从而阻塞其他线程。</p>
<p>C++以两种方式支持事务性内存：同步块和原子块。</p>
<h2 id="同步块和原子块"><a class="header" href="#同步块和原子块">同步块和原子块</a></h2>
<p>目前为止，只聊了事务，现在来聊下同步块和原子块，两者可以相互封装。更具体地说，同步块不是事务，因为它们可以执行不安全事务。事务不安全的例子，类似于控制台输出的代码无法撤消。因此，同步块通常也称为自由块。</p>
<p><strong>同步块</strong></p>
<p>同步块的行为就像全局锁一样，这意味着所有同步块都遵循相同的顺序，特别对同步块的所有更改，都可以在之后的同步块中使用。由于事务的提交与启动是同步的，所以在同步的块之间存在着同步关系。它们会建立一个总顺序，所以同步块不会死锁。互斥锁保护的是程序的关键区域，而同步块的则是保护整个程序。</p>
<p>这也就是为什么下面的程序定义良好的原因。</p>
<p>一个同步块</p>
<pre><code class="language-c++">// synchronized.cpp

#include &lt;iostream&gt;
#include &lt;vector&gt;
#include &lt;thread&gt;

int i = 0;

void increment() {
  synchronized{
    std::cout &lt;&lt; ++i &lt;&lt; &quot; ,&quot;;
  }
}

int main() {

  std::cout &lt;&lt; std::endl;

  std::vector&lt;std::thread&gt; vecSyn(10);
  for (auto&amp; thr : vecSyn)
    thr = std::thread([] {for (int n = 0; n &lt; 10; ++n)increment(); });
  for (auto&amp; thr : vecSyn)thr.join();

  std::cout &lt;&lt; &quot;\n\n&quot;;

}
</code></pre>
<p>第7行中的变量<code>i</code>是一个全局变量，同步块中的操作是事务不安全的，但是程序是定义良好的。10个线程并发调用函数<code>increment</code>(第21行)，10次增加第11行的变量<code>i</code>，对<code>i</code>和<code>std::cout</code>的访问是完全按顺序进行的，这就是同步块的特性。</p>
<p>程序返回预期的结果。<code>i</code>的值是按递增的顺序写的，中间用逗号隔开。下面是输出。</p>
<p><img src="content/The-Details/The-Future-CPP-20-23/../../../images/detail/The-Future-CPP-20-23/10.png" alt="" /></p>
<p>那么数据竞争呢?可以把它们与同步块放在一起。对源代码的一个小修改就可以引入数据竞争。</p>
<p>同步块的数据竞争</p>
<pre><code class="language-c++">// nonsynchronized.cpp

#include &lt;chrono&gt;
#include &lt;iostream&gt;
#include &lt;vector&gt;
#include &lt;thread&gt;

using namespace std::chrono_literals;


int i = 0;

void increment() {
  synchronized{
    std::cout &lt;&lt; ++i &lt;&lt; &quot; ,&quot;;
    this_thread::sleep_for(1ns);
  }
}

int main() {

  std::cout &lt;&lt; std::endl;

  std::vector&lt;std::thread&gt; vecSyn(10);
  std::vector&lt;std::thread&gt; vecUnsyn(10);

  for (auto&amp; thr : vecSyn)
    thr = std::thread([] {for (int n = 0; n &lt; 10; ++n)increment(); });
  for (auto&amp; thr : vecUnsyn)
    thr = std::thread([] {for (int n = 0; n &lt; 10; ++n)increment(); });

  for (auto&amp; thr : vecSyn)thr.join();
  for (auto&amp; thr : vecSvecUnsynyn)thr.join();

  std::cout &lt;&lt; &quot;\n\n&quot;;

}
</code></pre>
<p>为了观察到数据竞争，我让同步块休眠了1纳秒(第16行)。同时，在没有没有同步块(第30行)时，访问输出流<code>std::cout</code>。总共有20个线程增加了全局变量<code>i</code>，其中一半没有同步，所以输出显示就出问题了。</p>
<p><img src="content/The-Details/The-Future-CPP-20-23/../../../images/detail/The-Future-CPP-20-23/11.png" alt="" /></p>
<p>我在有输出的问题的输出周围画上红色的圆圈。这些是<code>std::cout</code>由至少两个线程同时写入的位置。C++11保证字符是自动编写的，而这并不是问题的原因。更糟糕的是，变量<code>i</code>是由多于两个线程进行修改的，这就是一场数据竞赛。因此，程序会出现未定义行为。计数器的最终结果应该是200，但结果是199。这意味着，计数中有值被覆盖了。</p>
<p>同步块的顺序也适用于原子块。</p>
<p><strong>原子块</strong></p>
<p>可以在同步块中执行事务不安全代码，但不能在原子块中执行。原子块有三种形式：<code>atomic_noexcept</code>、<code>atomic_commit</code>和<code>atomic_cancel</code>。三个后缀<code>_noexcept</code>、<code>_commit</code>和<code>_cancel</code>定义了原子块如何对异常进行管理：</p>
<p>atomic_noexcept：如果抛出异常，将调用<code>std::abort</code>中止程序。</p>
<p>atomic_cancel：默认情况下，会调用<code>std::abort</code>。如果抛出一个终止事务的安全异常，则不存在这种情况。在这种情况下，事务将取消，并进入初始状态并抛出异常。</p>
<p>atomic_commit：如果抛出异常，则提交事务。</p>
<p>具有事务安全异常的有: <a href="http://en.cppreference.com/w/cpp/memory/new/bad_alloc">std::bad_alloc</a>, <a href="https://www.cs.helsinki.fi/group/boi2016/doc/cppreference/reference/en.cppreference.com/w/cpp/memory/new/bad_array_length.html">std::bad_array_length</a>, <a href="http://en.cppreference.com/w/cpp/memory/new/bad_array_new_length">std::bad_array_new_length</a>, <a href="http://en.cppreference.com/w/cpp/types/bad_cast">std::bad_cast</a>, <a href="http://en.cppreference.com/w/cpp/types/bad_typeid">std::bad_typeid</a>, <a href="http://en.cppreference.com/w/cpp/error/bad_exception">std::bad_exception</a>, <a href="http://en.cppreference.com/w/cpp/error/exception">std::exception</a>, 以及所有(从这些异常中)派生出来的异常。</p>
<h2 id="transaction_safe与transaction_unsafe的代码比较"><a class="header" href="#transaction_safe与transaction_unsafe的代码比较">transaction_safe与transaction_unsafe的代码比较</a></h2>
<p>可以将函数声明为transaction_safe，或者将transaction_unsafe属性附加到它。</p>
<p>transaction_safe与transaction_unsafe</p>
<pre><code class="language-c++">int transactionSafeFunction() transaction_safe;

[[transaction_unsafe]] int transactionUnsafeFunction();
</code></pre>
<p>transaction_safe属于函数类型，但transaction_safe是什么意思?根据<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4265.html">N4265</a>, transaction_safe函数是一个具有transaction_safe定义的函数。如果不出现下列属性定义，则该定义成立:</p>
<ul>
<li>有volatile参数或变量。</li>
<li>有事务不安全的语句。</li>
<li>当函数体中使用一个类的构造和析构函数，而这个类具有volatile的非静态成员。</li>
</ul>
<p>当然，这个transaction_safe定义是不稳定的，你可以阅读提案<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4265.html">N4265</a> ，了解更多细节。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="任务块-1"><a class="header" href="#任务块-1">任务块</a></h1>
<p>任务块使用fork-join范型来并行执行任务，其已经是<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/n4742.html">C++扩展并行性2版技术规范</a>的一部分。因此，我们很有可能在C++20中看到它们。</p>
<p>谁在C++中发明了任务块?微软的<a href="https://en.wikipedia.org/wiki/Parallel_Patterns_Library">Parallel Patterns Library (PPL)</a>和英特尔的<a href="https://en.wikipedia.org/wiki/Threading_Building_Blocks">Threading Building Blocks (TBB)</a>都参与了<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4411.pdf">N4441提案</a>。另外，Intel使用了他们的<a href="https://en.wikipedia.org/wiki/Cilk">Cilk Plus语言库</a>。</p>
<p>fork-join这个很容易理解。</p>
<h2 id="fork和join"><a class="header" href="#fork和join">Fork和Join</a></h2>
<p>解释fork-join范式最直接的方法是使用图形。</p>
<p><img src="content/The-Details/The-Future-CPP-20-23/../../../images/detail/The-Future-CPP-20-23/12.png" alt="" /></p>
<p>它是如何工作的?</p>
<p>创建者调用<code>define_task_block</code>或<code>define_task_block_restore_thread</code>，此调用会创建一个任务块，该任务块可以创建任务，也可以等待任务完成，同步位于任务块的末尾。创建新任务是fork阶段，任务块的同步是工作流的联接阶段，这只是一个简单的描述。让我们来看一段代码。</p>
<p>定义一个任务块</p>
<pre><code class="language-c++">template &lt;typename Func&gt;
int traverse(node&amp; n, Func &amp;&amp;f){
  int left = 0, right = 0;
  define_task_block(
  	[&amp;](task_block&amp; tb){
      if (n.left) tb.run([&amp;]{left = traverse(*n.left, f);});
      if (n.right) tb.run([&amp;]{right = traverse(*n.right, f);});
    }
  );
  return f(n) + left + right;
}
</code></pre>
<p>traverse是一个函数模板，它在树的每个节点上调用函数<code>f</code>。关键字<code>define_task_block</code>定义了任务块，任务块<code>tb</code>可以在任务块中启动一个新任务，这发生在第6行和第7行树的左右分支上。第9行是任务块的末端，因此是同步点。</p>
<blockquote>
<p><strong>HPX(高性能ParalleX)</strong></p>
<p>上面的例子来自<a href="http://stellar.cct.lsu.edu/projects/hpx/">HPX (High-Performance ParalleX)</a>框架的文档，它是一个通用的C++运行时，适用于任何规模的并行和分布式应用程序。HPX已经实现了许多本章介绍的，即将发布的C++ 20/23标准中的特性。</p>
</blockquote>
<p>可以使用<code>define_task_block</code>函数或<code>define_task_block_restore_thread</code>函数定义一个任务块。</p>
<h2 id="define_task_block与define_task_block_restore_thread"><a class="header" href="#define_task_block与define_task_block_restore_thread">define_task_block与define_task_block_restore_thread</a></h2>
<p>区别在于，<code>define_task_block_restore_thread</code>函数保证任务块的创建者线程与任务块完成后运行的线程是相同的，而<code>define_task_block</code>函数则相反。</p>
<p>define_task_block与define_task_block_restore_thread</p>
<pre><code class="language-c++">  ...
  define_task_block([&amp;](auto&amp; tb){
    tb.run([&amp;]{[]fun();});
    define_task_block_restore_thread([&amp;](auot&amp; tb){
      tb.run([&amp;]{[]{func2();}); 
      define_task_block([&amp;](auto&amp; tb){
        tb.run([&amp;]{func3();});
      });
      ...
      ...
    });
    ...
    ...
  });
  ...
  ...
</code></pre>
<p>任务块确保最外层任务块(第2 - 14行)的创建者线程，与完成任务块后运行语句的线程完全相同。这意味着执行第2行的线程与执行第15和16行的线程相同。这种保证不适用于嵌套的任务块，第6 - 8行任务块的创建者线程不会自动执行第9行和第10行。现在执行第4行的创建者线程与执行第12行和第13行的线程是相同的，如果需要嵌套，则应该使用define_task_block_restore_thread函数(第4行)。</p>
<h2 id="接口"><a class="header" href="#接口">接口</a></h2>
<p>任务块的接口非常有限，不能构造、销毁、复制或移动task_block类的实例。只能对其使用define_task_block函数或define_task_block_restore_thread函数。<code>task_block tb</code>在定义的任务块范围内活动，因此可以启动新任务(<code>tb.run</code>)或等待(<code>tb.wait</code>)直到任务完成。</p>
<p>任务块的最小接口</p>
<pre><code class="language-c++">define_task_block([&amp;](auto&amp; tb){
  tb.run([&amp;]{process(x1, x2)});
  if(x2==x3) tb.wait();
  process(x3, x4);
});
</code></pre>
<p>这段代码在做什么呢?第2行启动了一个新任务，这个任务需要数据<code>x1</code>和<code>x2</code>才能进行，第4行使用数据<code>x3</code>和<code>x4</code>。如果<code>x2 == x3</code>为真，则必须保护变量不受共享访问。这就是任务块<code>tb</code>等待第2行任务完成的原因。</p>
<p>如果函数<code>task_block::run</code>或<code>task_block::wait</code>检测到当前任务块中有异常，则会抛出一个类似于<code>task_cancelled_exception</code>的异常。</p>
<h2 id="调度器"><a class="header" href="#调度器">调度器</a></h2>
<p>调度器管理线程运行，这意味着决定谁执行任务不再是程序开发者的责任。线程只是一个实现细节。</p>
<p>执行新创建的任务有两种策略。父线程表示创建者线程，子线程表示新任务。</p>
<p>窃取子任务：调度程序窃取其任务并执行它。</p>
<p>窃取父任务：现在调度器窃取任务块<code>tb</code>本身执行任务。</p>
<p><a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4411.pdf">提案N4441</a>支持这两种策略。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="模式和最佳实践-1"><a class="header" href="#模式和最佳实践-1">模式和最佳实践</a></h1>
<p>本章的目标是了解模式是什么，以及模式有什么好处。我的实用主义观点有些非正式的，并且还戴了C++的眼镜。为了更全面地讨论这个主题，我会提供一些文献的链接，供大家进一步的了解细节。</p>
<p>首先，什么是模式?</p>
<p>用<a href="https://en.wikipedia.org/wiki/Christopher_Alexander">Christopher Alexander</a>的话来说，“每个模式都是由三部分组成其规则，它描述了特定的上下文、问题和解决方案之间的关系。“</p>
<p>更通俗地说，模式是对特定(文档完善的)解决方案的设计挑战。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="相关历史"><a class="header" href="#相关历史">相关历史</a></h1>
<p>Cristopher Alexander是模式之父，他的模式本质是以人为本的设计，其中是关于城镇、房屋和建筑物的设计。总的来说，这中方式对软件设计有很大的影响。1994年，“风尘四侠”(Eric Gamma、Richard Helm、Ralph Johnson和John Vlissides)出版了他们的书<a href="https://en.wikipedia.org/wiki/Design_Patterns">《Design Patterns: Elements of Reusable Object-Oriented Software》</a>。这本书包括23个针对面向对象软件设计的模式，这些模式可分为三类：创造型、结构型和行为型。书中定义了软件行业的用语，以下是一些最著名的设计模式:</p>
<ul>
<li>Creational 创建型模式
<ul>
<li>Factory method pattern 工厂模式</li>
<li>Singleton pattern 单例模式</li>
</ul>
</li>
<li>Structural 结构型模式</li>
<li>Adapter 适配器模式</li>
<li>Bridge 桥接模式</li>
<li>Composite 组合模式</li>
<li>Decorator 装饰器模式</li>
<li>Facade 外观模式</li>
<li>Proxy 代理模式</li>
<li>Behavioural 行为型模式
<ul>
<li>Command 命令模式</li>
<li>Iterator 迭代器模式</li>
<li>Observer 观察者模式</li>
<li>Strategy 策略模式</li>
<li>Template method 模板模式</li>
<li>Visitor 访问者模式</li>
</ul>
</li>
</ul>
<p>一年后，Frank Buschmann、Regine Meunier、Hans Rohnert、Peter Sommerlad和Michael Stal出版了他们非常有影响力的 <a href="https://www.wiley.com/WileyCDA/Section/id-406899.html">《Pattern-Oriented Software-Architecture: A System of Patterns》</a>一书，简写为POSA，这本书是系列五部曲的第一部。它在1995年出版，有三类模式：架构模式、设计模式和习惯用法。许多模式都是现在的通用术语:</p>
<ul>
<li>Architectural Patterns 架构模式
<ul>
<li>Layers 层模式</li>
<li>Pipes and Filters 管道和过滤器模式</li>
<li>Broker 经纪人模式</li>
<li>Model-View-Controller 模型-视图-控制器模式</li>
</ul>
</li>
<li>Design Patterns 设计模式
<ul>
<li>Master-Slave 主从模式</li>
<li>Publish-Subscriber 发布和订阅者模式</li>
</ul>
</li>
<li>Idioms 习惯用法
<ul>
<li>Counted-Pointer 计数器模式</li>
</ul>
</li>
</ul>
<p>这三个类别有什么区别呢?体系结构模式的重点是整个软件系统，比定义相互作用的设计模式更加抽象。习惯用法是特定编程语言中体系结构或设计模式的实现，也是三者中抽象层次最低的。</p>
<p>POSA系列的第2卷至第5卷都有不同的关注点。他们处理并发”模式和网络对象”(第2卷)，“资源管理模式”(第3卷)，“分布式计算的模式语言”(第4卷)，“模式和模式语言”(第5卷)。本书的同步模式和并行架构部分，深受系列的第2卷的影响。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="价值所在"><a class="header" href="#价值所在">价值所在</a></h1>
<p>模式通常为软件开发增加了价值，这对于并发性尤为适用。附加值可以归结为三点：良好的术语，改进的文档，学习的榜样。</p>
<p>良好的术语意味着，软件开发人员可以使用通用且明确的词汇表，这样误解或冗长的解释都是成为过去式。如果一个软件开发人员询问，如何实现在运行时对类似的算法簇进行交换时，答案可能很简单：使用策略模式。如果软件开发人员知道策略模式，就可以立即考虑如何使用策略模式；如果没有，他就需要查阅文献。</p>
<p>文档在两个方面可以改进。首先，关于软件系统的文档，可以进行图形化或文本化，因为在文档中读到“使用了观察者模式”，就知道系统有一种主题/观察者结构。这意味着观察员将登记或注销，如有必要则会向所有观察员发出通知。第二，对具体实现的了解，这样就可以直接跳到源代码并搜索关键字，如observer、subject或notify。</p>
<p>模式就是向榜样学习，从最好的人那里学习已有经验，不要重复他们的错误。了解它们为哪些典型的问题提供经过已验证的解决方案，并是如何控制复杂性的。每个模式都会提供相应的信息，什么时候应该使用它，使用它的会有什么后果，以及如何实现和已知用法。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="模式与最佳实践"><a class="header" href="#模式与最佳实践">模式与最佳实践</a></h1>
<p>这个章节挺奇怪的，感觉重复，但又不重复。如果不可变值或纯函数之类的实践是模式或最佳实践，那么我经常会参与这类话题的争论。模式是文档化的最佳实践，并且我从数场&quot;战斗&quot;中学到了一些东西。</p>
<ul>
<li>这两个术语不能完全区别开来。</li>
<li>如果实践是定义良好的模式，那么会我将它放到模式桶中。</li>
<li>如果实践具有技巧特征，并且没有正式的结构，我将它放到最佳实践桶中。</li>
<li>今天的最佳实践，可能成为明天的模式。</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="反模式"><a class="header" href="#反模式">反模式</a></h1>
<p>如果模式代表了最佳实践，那么反模式就代表经验教训，或者用<a href="https://en.wikipedia.org/wiki/Andrew_Koenig_(programmer)">Andrew Koenig</a>的话来说：“对于问题的糟糕描述，导致了糟糕的解决方案。”如果仔细阅读并发模式的文献，就会看到双重检查锁定模式。双重检查锁定模式的基本思想，简言之，以优化的方式对共享状态进行线程安全初始化，这种共享状态通常是<a href="https://en.wikipedia.org/wiki/Singleton_pattern">单例</a>。我将双重检查锁定模式放在本书的案例研究一章中，以明确强调：使用双重检查锁定模式可能会导致未定义行为。双重检查锁定模式的问题，本质上可以归结为单例模式的问题。</p>
<p>如果使用单例模式，必须考虑以下挑战:</p>
<ul>
<li>单例对象是一个全局对象。基于这个事实，单例的使用在(大多数情况下)接口中是不可见的。其结果是在使用单例的代码中隐藏了一个依赖项。</li>
<li>单例对象是静态的，因此一旦创建就不会被销毁。它的生命周期和程序的生命周期相同。</li>
<li>如果类的静态成员(如单例)依赖于在另一个单元中定义的静态成员，则不能保证先初始化哪个静态成员，那么每个静态成员初始化失败的概率是50%。</li>
<li>当类的实例可以完成任务时，通常会使用单例。许多开发者使用单例来证明自己了解设计模式。</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="同步模式"><a class="header" href="#同步模式">同步模式</a></h1>
<p>处理并发时，尤其要注意共享变量、可变状态或<a href="https://github.com/tvaneerd">Tony Van Eerd</a>(在CppCon 2014)提及的“无锁示例”：“你需要忘记在幼儿园学到的那点玩意儿(即：阻止共享)”。</p>
<p><img src="content/Pattrns/Synchronisation-Patterns/../../../images/Patterns/Synchronisation-Patterns/1.png" alt="" /></p>
<p>共享数据特别容易产生竞争。如果是仅处理共享或突变，则不会发生数据竞争。这正是本章的两个重点：处理共享和处理突变。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="处理共享"><a class="header" href="#处理共享">处理共享</a></h1>
<p>如果使用不共享数据，就没有竞争。不共享意味着线程只处理本地变量，可以通过值复制、特定的线程存储，也可以通过受保护的数据通道将结果传输到future来实现。本节中的模式非常直观，我会给出一些简单的解释。</p>
<h2 id="值复制"><a class="header" href="#值复制">值复制</a></h2>
<p>线程通过值复制，而不是引用来获取参数时，就不需要对任何数据的访问进行同步，也就没有数据竞争的条件和数据生命周期的问题。</p>
<p><strong>使用引用的数据竞争</strong></p>
<p>下面的程序启动三个线程：一个线程通过复制获取参数，另一个线程通过引用获取参数，最后一个线程通过常量引用获取参数。</p>
<pre><code class="language-c++">// copiedValueDataRace.cpp

#include &lt;functional&gt;
#include &lt;iostream&gt;
#include &lt;string&gt;
#include &lt;thread&gt;

using namespace std::chrono_literals;

void byCopy(bool b) {
  std::this_thread::sleep_for(1ms);
  std::cout &lt;&lt; &quot;byCopy: &quot; &lt;&lt; b &lt;&lt; std::endl;
}

void byReference(bool&amp; b) {
  std::this_thread::sleep_for(1ms);
  std::cout &lt;&lt; &quot;byReference: &quot; &lt;&lt; b &lt;&lt; std::endl;
}

void byConstReference(const bool&amp; b) {
  std::this_thread::sleep_for(1ms);
  std::cout &lt;&lt; &quot;byConstReference: &quot; &lt;&lt; b &lt;&lt; std::endl;
}

int main() {

  std::cout &lt;&lt; std::boolalpha &lt;&lt; std::endl;

  bool shared(false);

  std::thread t1(byCopy, shared);
  std::thread t2(byReference, std::ref(shared));
  std::thread t3(byConstReference, std::cref(shared));

  shared = true;

  t1.join();
  t2.join();
  t3.join();

  std::cout &lt;&lt; std::endl;

}
</code></pre>
<p>每个线程在显示布尔值之前会休眠1毫秒(第11、16和21行)，其中只有线程<code>t1</code>具有布尔值的副本，因此没有数据竞争。程序显示线程<code>t2</code>和<code>t3</code>中的布尔值，而且布尔值在没有同步的情况下进行修改。</p>
<p><img src="content/Pattrns/Synchronisation-Patterns/../../../images/Patterns/Synchronisation-Patterns/2.png" alt="" /></p>
<p>copiedValueDataRace.cpp例子中，我做了一个假设，这个假设对于布尔值来说很简单，但是对于更复杂的类型来说就不一定了。如果参数是“值对象”，那么通过复制传递参数必然就是无数据竞争。</p>
<blockquote>
<p><strong>值对象</strong></p>
<p>“值对象”是一个对象，相等性基于状态。值对象是不可变的，以便在创建为“相等”的情况下，保持同等的生命周期。如果通过复制将值对象传递给线程，则不需要同步访问。<a href="https://martinfowler.com/bliki/ValueObject.html">ValueObject</a>源于Martin Fowler的文章，“考虑两类对象：值对象和引用对象”。</p>
</blockquote>
<p><strong>当引用为拷贝时</strong></p>
<p>示例copyedValueDataRace.cpp中的线程<code>t3</code>可能可以替换为<code>std::thread t3(byConstReference, shared)</code>。 该程序可以编译并运行，但是只是看起来像是引用而已， 原因是<a href="https://en.cppreference.com/w/cpp/types/decay"><code>std::decay</code></a>会应用于线程的每个参数。 <code>std::decay</code>对类型T的执行是从左值到右值，数组到指针和函数到指针的隐式转换。这种用例中，对类型T使用的是<code>[std :: remove_reference]</code> 。</p>
<p>perConstReference.cpp使用不可复制类型NonCopyableClass。</p>
<p>线程引用参数的&quot;隐式&quot;复制</p>
<pre><code class="language-c++">// perConstReference.cpp

#include &lt;thread&gt;

class NonCopyableClass {
public:

  // the compiler generated default constructor
  NonCopyableClass() = default;

  // disallow copying
  NonCopyableClass&amp; operator=(const NonCopyableClass&amp;) = delete;
  NonCopyableClass(const NonCopyableClass&amp;) = delete;

};

void perConstReference(const NonCopyableClass&amp; nonCopy){}

int main() {

  NonCopyableClass nonCopy;

  perConstReference(nonCopy);

  std::thread t(perConstReference, nonCopy);
  t.join();
}
</code></pre>
<p>对象<code>nonCopy</code>(第21行)是不可复制的， 如果使用参数<code>nonCopy</code>调用函数<code>perConstReference</code>则没什么问题，因为该函数接受常量引用参数。线程<code>t</code>(第25行)中使用相同的函数，会导致GCC 6生成300多行冗长的编译器错误：</p>
<p><img src="content/Pattrns/Synchronisation-Patterns/../../../images/Patterns/Synchronisation-Patterns/3.png" alt="" /></p>
<p>因为复制构造函数在NonCopyableClass类中是不可用的，所以错误消息的重要部分位于屏幕截图中间的红色部分：“错误：使用已删除的功能”。 </p>
<p><img src="content/Pattrns/Synchronisation-Patterns/../../../images/Patterns/Synchronisation-Patterns/4.png" alt="" /></p>
<p><strong>引用参数的生命周期问题</strong></p>
<p>如果分离通过引用获取参数的线程，则必须格外小心。 copyValueValueLifetimeIssues.cpp中就有未定义行为。</p>
<p>使用引用引发的生命周期问题</p>
<pre><code class="language-c++">// copiedValueLifetimeIssues.cpp

#include &lt;iostream&gt;
#include &lt;string&gt;
#include &lt;thread&gt;

void executeTwoThreads() {

  const std::string localString(&quot;local string&quot;);

  std::thread t1([localString] {
    std::cout &lt;&lt; &quot;Per Copy: &quot; &lt;&lt; localString &lt;&lt; std::endl;
    });

  std::thread t2([&amp;localString] {
    std::cout &lt;&lt; &quot;Per Reference: &quot; &lt;&lt; localString &lt;&lt; std::endl;
    });

  t1.detach();
  t2.detach();
}

using namespace std::chrono_literals;

int main() {

  std::cout &lt;&lt; std::endl;

  executeTwoThreads();

  std::this_thread::sleep_for(1s);

  std::cout &lt;&lt; std::endl;

}
</code></pre>
<p>executeTwoThreads(第7 - 21行)启动了两个线程，且两个线程都被分离(第19行和第20行)，并且线程在执行时会打印局部变量<code>localString</code>(第9行)。第一个线程通过复制捕获局部变量，第二个线程通过引用捕获局部变量。为了让程序看起来简单，我使用Lambda函数来绑定参数。</p>
<p>因为executeTwoThreads函数不会等待两个线程完成，所以线程<code>t2</code>引用本地字符串，而该字符串与函数的生命周期绑定，这就会导致未定义行为的发生。奇怪的是，在GCC 6中以最大优化<code>-O3</code>编译连接的可执行文件似乎可以工作，而非优化的可执行文件却崩溃了。</p>
<p><img src="content/Pattrns/Synchronisation-Patterns/../../../images/Patterns/Synchronisation-Patterns/5.png" alt="" /></p>
<p><strong>扩展阅读</strong></p>
<ul>
<li><a href="http://www.dre.vanderbilt.edu/%7Eschmidt/POSA/POSA4/">Pattern-Oriented Software Architecture: A Pattern Language for Distributed Computing</a></li>
</ul>
<h2 id="线程特定的存储器"><a class="header" href="#线程特定的存储器">线程特定的存储器</a></h2>
<p>线程的本地存储，允许多个线程通过全局访问使用本地存储。通过使用存储说明符<code>thread_local</code>，变量变成了线程的局部变量。这意味着，可以在不同步的情况下，使用线程局部变量。</p>
<p>下面是一个典型的用例。假设想要计算一个向量<code>randValues</code>的元素和，使用for循环执行此任务非常简单。</p>
<pre><code class="language-c++">// calculateWithLoop.cpp
...
unsigned long long sum = {};
for (auto n: randValues) sum += n;
</code></pre>
<p>不过，电脑有四个核心，也可以使串行程序变成一个并发程序。</p>
<pre><code class="language-c++">// threadLocalSummation.cpp
...
thread_local unsigned long long tmpSum = 0;
void sumUp(std::atomic&lt;unsigned long long&gt;&amp; sum, const std::vector&lt;int&gt;&amp; val,
unsigned long long beg, unsigned long long end){
for (auto i = beg; i &lt; end; ++i){
tmpSum += val[i];
}
sum.fetch_add(tmpSum, std::memory_order_relaxed);
}
...
std::atomic&lt;unsigned long long&gt; sum{};
std::thread t1(sumUp, std::ref(sum), std::ref(randValues), 0, fir);
std::thread t2(sumUp, std::ref(sum), std::ref(randValues), fir, sec);
std::thread t3(sumUp, std::ref(sum), std::ref(randValues), sec, thi);
std::thread t4(sumUp, std::ref(sum), std::ref(randValues), thi, fou);
</code></pre>
<p>将for循环放入函数中，让每个线程计算线程局部变量<code>tmpSum</code>中总和的四分之一。<code>sum.fetch_add(tmpSum, std::memory_order_relaxed)</code>最后以原子的方式汇总所有值。</p>
<blockquote>
<p><strong>使用标准模板库的算法</strong></p>
<p>如果有算法标准模板库可以做这项工作，就用不着循环了。本例中，<a href="https://en.cppreference.com/w/cpp/algorithm/accumulate">std::accumulate</a>就可以完成这项工作，以汇总向量加和：<code>sum = std::accumulate(randValues.begin(), randValues.end(), 0) </code>。在C++17中，可以使用<code>std::accumulate</code>的并行版本<code>std::reduce</code>：<code>sum = std::reduce(std::execution::par, randValues.begin(), randValues.end(), 0)</code>。</p>
</blockquote>
<p><strong>扩展阅读</strong></p>
<ul>
<li><a href="https://martinfowler.com/bliki/ValueObject.html">ValueObject</a></li>
<li><a href="https://www.dre.vanderbilt.edu/%7Eschmidt/POSA/POSA2/">Pattern-Oriented Software Architecture: Patterns for Concurrent and Networked Objects</a></li>
</ul>
<h2 id="future"><a class="header" href="#future">Future</a></h2>
<p>C++11提供了三种类型的future和promise：<code>std::async</code>、<code>std::packaged_task</code>和<code>std::promise</code>与<code>std::future</code>对。promise这个词可以追溯到70年代。future是可写promise设置的只读占位符。从同步的角度来看，promise/future对的关键属性是两者都由受保护的数据通道进行连接。</p>
<p>实现future时需要做出一些决策：</p>
<ul>
<li>future可以通过get调用隐式或显式地获取值。</li>
<li>future可以积极地或消极地启动计算，只有<code>std::async</code>可以通过启动策略控制是否支持延迟计算。</li>
</ul>
<pre><code class="language-c++">auto lazyOrEager = std::async([]{ return &quot;LazyOrEager&quot;; });
auto lazy = std::async(std::launch::deferred, []{ return &quot;Lazy&quot;; });
auto eager = std::async(std::launch::async, []{ return &quot;Eager&quot;; });

lazyOrEager.get();
lazy.get();
eager.get();
</code></pre>
<p>如果没有指定启动策略，则由系统决定是立即启动还是延迟启动。通过使用启动策略<code>std::launch::async</code>，创建一个新线程，promise会立即开始它的工作。这与启动策略<code>std::launch::async</code>不同，<code>eager.get()</code>会启动promise，而promise是在创建线程中执行的。</p>
<ul>
<li>如果promise的值不可用，则future阻塞或抛出异常。C++11阻塞了wait或get，也可以等待promise的超时(<code>wait_for</code>和<code>wait_until</code>)。</li>
<li>有多种方法实现future：<a href="https://en.wikipedia.org/wiki/Coroutine">协程</a>、<a href="https://en.wikipedia.org/wiki/Generator_(computer_programming)">生成器</a>或<a href="https://en.wikipedia.org/wiki/Channel_(programming)">通道</a>。</li>
</ul>
<p><strong>扩展阅读</strong></p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Futures_and_promises">Futures and promises</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="处理突变"><a class="header" href="#处理突变">处理突变</a></h1>
<p>如果不同时读写数据，就没有数据竞争，最简单的方法是使用不可变值。除此之外，还有两种典型的策略。首先，用锁来保护临界区，例如：范围锁或策略锁。在面向对象设计中，关键部分的通常是对象(包括它的接口)，线程安全的接口会保护整个对象。其次，修改线程只是在工作完成时发出信号，这就是<em>保护性暂挂</em>模式。</p>
<h2 id="范围锁"><a class="header" href="#范围锁">范围锁</a></h2>
<p>范围锁是将RAII(资源获取即初始化)应用于互斥锁，这个用法的关键思想是将资源获取和释放绑定到对象的生存期。顾名思义，对象的生命周期范围是确定的。这里的范围意味着，C++运行时会负责调用对象的析构函数，从而释放资源。</p>
<p>ScopedLock类实现了范围锁。</p>
<pre><code class="language-c++">// scopedLock.cpp

#include &lt;iostream&gt;
#include &lt;mutex&gt;
#include &lt;new&gt;
#include &lt;string&gt;
#include &lt;utility&gt;

class ScopedLock{
private:
  std::mutex&amp; mut;
public:
	explicit ScopedLock(std::mutex&amp; m) :mut(m) {
		mut.lock();
		std::cout &lt;&lt; &quot;Lock the mutex: &quot; &lt;&lt; &amp;mut &lt;&lt; std::endl;
	}
	~ScopedLock() {
		std::cout &lt;&lt; &quot;Release the mutex: &quot; &lt;&lt; &amp;mut &lt;&lt; std::endl;
		mut.unlock();
	}
};

int main() {

	std::cout &lt;&lt; std::endl;

	std::mutex mutex1;
	ScopedLock scopedLock1{ mutex1 };

	std::cout &lt;&lt; &quot;\nBefore local scope&quot; &lt;&lt; std::endl;
	{
		std::mutex mutex2;
		ScopedLock scopedLock2{ mutex2 };
	}
	std::cout &lt;&lt; &quot;After local scope&quot; &lt;&lt; std::endl;

	std::cout &lt;&lt; &quot;\nBefore try-catch block&quot; &lt;&lt; std::endl;
	try {
		std::mutex mutex3;
		ScopedLock scopedLoack3{ mutex3 };
		throw std::bad_alloc();
	}
	catch (std::bad_alloc&amp; e) {
		std::cout &lt;&lt; e.what();
	}
	std::cout &lt;&lt; &quot;\nAfter try-catch block&quot; &lt;&lt; std::endl;

	std::cout &lt;&lt; std::endl;

}
</code></pre>
<p>ScopedLock通过引用的方式获取互斥对象(第13行)。互斥量在构造函数(第15行)中锁定，在析构函数(第19行)中进行解锁。由于RAII的使用习惯，对象在销毁时，会自动对互斥量进行解锁。</p>
<p><img src="content/Pattrns/Synchronisation-Patterns/../../../images/Patterns/Synchronisation-Patterns/6.png" alt="" /></p>
<p><code>scopedLock1</code>的作用域在主函数体中。因此，<code>mutex1</code>最后才解锁，<code>mutex2</code>(第34行)和<code>mutex3</code>(第42行)也是同理。对于<code>mutex3</code>而言，如果触发异常，也会调用<code>scopedLock3</code>的析构函数。有趣的是，<code>mutex3</code>重用了<code>mutex2</code>的内存，因为两者的地址相同。</p>
<p>C++17支持四种类型的锁：<code>std::lock_guard</code>/<code>std::scoped_lock</code>用于简单场景，<code>std::unique_lock</code>/<code>std::shared_lock</code>用于高级场景，可以在关于锁的章节中了解更多的细节。</p>
<p><strong>拓展阅读</strong></p>
<ul>
<li><a href="https://www.dre.vanderbilt.edu/%7Eschmidt/POSA/POSA2/">Pattern-Oriented Software Architecture: Patterns for Concurrent and Networked Objects</a></li>
</ul>
<h2 id="策略锁"><a class="header" href="#策略锁">策略锁</a></h2>
<p>编写代码库时，这个库可用于各种领域，包括并发。为了安全起见，要用锁来保护关键部分。倘若库在单线程环境中运行，因为实现使用了重量级同步机制，则会存在性能问题。那么，现在就轮到策略锁登场了。</p>
<p>策略锁是将策略模式的思想应用于锁。这意味着，会将锁定策略放到实例对象中，并使其成为一个可热插拔的组件。那么，什么是策略模式呢?</p>
<p><strong>Strategy Pattern</strong></p>
<p><img src="content/Pattrns/Synchronisation-Patterns/../../../images/Patterns/Synchronisation-Patterns/7.png" alt="" /></p>
<p>策略模式是<a href="https://en.wikipedia.org/wiki/Design_Patterns">《设计模式：可重用的面向对象软件元素》</a>一书中经典的行为模式之一。其关键思想是定义一系列算法，将它们封装在一个对象中，从而使其成为可热插拔的组件。</p>
<p>策略模式</p>
<pre><code class="language-c++">// strategy.cpp

#include &lt;iostream&gt;
#include &lt;memory&gt;

class Strategy {
public:
  virtual void operator()() = 0;
  virtual ~Strategy() = default;
};

class Context {
  std::shared_ptr&lt;Strategy&gt; _start;
public:
  explicit Context() : _start(nullptr) {}
  void setStrategy(std::shared_ptr&lt;Strategy&gt; start) { _start = start; }
  void strategy() { if (_start)(*_start)(); }
};

class Strategy1 :public Strategy {
  void operator()() override {
    std::cout &lt;&lt; &quot;Foo&quot; &lt;&lt; std::endl;
  }
};

class Strategy2 : public Strategy {
  void operator()() override {
    std::cout &lt;&lt; &quot;Bar&quot; &lt;&lt; std::endl;
  }
};

class Strategy3 :public Strategy {
  void operator()() override {
    std::cout &lt;&lt; &quot;FooBar&quot; &lt;&lt; std::endl;
  }
};

int main() {

  std::cout &lt;&lt; std::endl;

  Context con;

  con.setStrategy(std::shared_ptr&lt;Strategy&gt;(new Strategy1));
  con.strategy();

  con.setStrategy(std::shared_ptr&lt;Strategy&gt;(new Strategy2));
  con.strategy();

  con.setStrategy(std::shared_ptr&lt;Strategy&gt;(new Strategy3));
  con.strategy();

  std::cout &lt;&lt; std::endl;

}
</code></pre>
<p>第6至10行中的抽象类<code>Strategy</code>定义了策略。每个特定的策略，如<code>Strategy1</code>(第20行)、<code>Strategy2</code>(第26行)或<code>Strategy3</code>(第32行)，都必须支持函数调用操作符(第8行)。使用者在<code>Context</code>中集合了各种策略，在第16行设置特定的策略，并在第17行执行它。因为<code>Context</code>通过一个指向<code>Strategy</code>类的指针来执行，所以<code>Strategy1</code>、<code>Strategy2</code>和<code>Strategy3</code>的执行方法是私有的。</p>
<p><img src="content/Pattrns/Synchronisation-Patterns/../../../images/Patterns/Synchronisation-Patterns/8.png" alt="" /></p>
<p><strong>具体实现</strong></p>
<p>实现策略锁有两种经典的方法：运行时多态性(面向对象)和编译时多态性(模板)。两种方式各有利弊。</p>
<ul>
<li>优点：</li>
<li>运行时多态
<ul>
<li>允许在运行时配置策略锁。</li>
<li>了解有面向对象的开发人员，更容易理解。</li>
</ul>
</li>
<li>编译时多态
<ul>
<li>无抽象的惩罚。</li>
<li>扁平的层次结构。</li>
</ul>
</li>
<li>缺点：
<ul>
<li>运行时多态</li>
<li>额外需要一个指针。</li>
<li>可能有很深的派生层次。</li>
<li>编译时多态
<ul>
<li>出错时会有非常详细的信息。</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>讨论了理论之后，我在两个程序中实现了策略锁。示例中，策略锁可支持无锁、独占锁和共享锁。简单起见，我在内部使用了互斥锁。此外，策略锁的模型也限定了其锁定的范围。</p>
<p><strong>运行时多态</strong></p>
<p>strategizedLockingRuntime.cpp程序中展示了三种互斥锁。</p>
<p>运行时的多态性策略锁</p>
<pre><code class="language-c++">// strategizedLockingRuntime.cpp

#include &lt;iostream&gt;
#include &lt;mutex&gt;
#include &lt;shared_mutex&gt;

class Lock {
public:
  virtual void lock() const = 0;
  virtual void unlock() const = 0;
};

class StrategizedLocking {
  Lock&amp; lock;
public:
  StrategizedLocking(Lock&amp; l) :lock(l) {
    lock.lock();
  }
  ~StrategizedLocking() {
    lock.unlock();
  }
};

struct NullObjectMutex {
  void lock() {};
  void unlock() {};
};

class NoLock :public Lock {
  void lock() const override {
    std::cout &lt;&lt; &quot;NoLock::lock: &quot; &lt;&lt; std::endl;
    nullObjectMutex.lock();
  }
  void unlock() const override {
    std::cout &lt;&lt; &quot;NoLock::unlock: &quot; &lt;&lt; std::endl;
    nullObjectMutex.unlock();
  }
  mutable NullObjectMutex nullObjectMutex;
};

class ExclusiveLock : public Lock {
  void lock() const override {
    std::cout &lt;&lt; &quot;  ExclusiveLock::lock: &quot; &lt;&lt; std::endl;
    mutex.lock();
  }
  void unlock() const override {
    std::cout &lt;&lt; &quot;  ExclusiveLock::unlock: &quot; &lt;&lt; std::endl;
    mutex.unlock();
  }
  mutable std::mutex mutex;
};

class SharedLock : public Lock {
  void lock() const override {
    std::cout &lt;&lt; &quot; SharedLock::lock_shared: &quot; &lt;&lt; std::endl;
    sharedMutex.lock_shared();
  }
  void unlock() const override {
    std::cout &lt;&lt; &quot; SharedLock::unlock_shared: &quot; &lt;&lt; std::endl;
    sharedMutex.unlock_shared();
  }
  mutable std::shared_mutex sharedMutex;
};

int main() {

  std::cout &lt;&lt; std::endl;

  NoLock noLock;
  StrategizedLocking stratLock1{ noLock };

  {
    ExclusiveLock exLock;
    StrategizedLocking stratLock2{ exLock };
    {
      SharedLock sharLock;
      StrategizedLocking startLock3{ sharLock };
    }
  }

  std::cout &lt;&lt; std::endl;

}
</code></pre>
<p><code>StrategizedLocking</code>类中有一把锁(第14行)。<code>StrategizedLocking</code>模型是范围锁，因此在构造函数(第16行)中进行锁定，在析构函数(第19行)中进行解锁。<code>Lock</code>(第7 - 11行)是一个抽象类，定义了所有接口。派生类分别是<code>NoLock</code> (第29行)、<code>ExclusiveLock</code>(第41行)和<code>SharedLock</code>(第53行)。<code>SharedLock</code>在<code>std::shared_mutex</code>上可使用<code>lock_shared</code>(第56行)和<code>unlock_shared</code>进行锁定和解锁。每个锁持有一个互斥对象<code>NullObjectMutex</code>(第38行)、<code>std::mutex</code>(第50行)或<code>std::shared_mutex</code>(第62行)。其实，<code>NullObjectMutex</code>就是一个无操作的占位符。互斥对象声明为可变，就意味着可以用在常量方法中使用，比如：lock和unlock中。</p>
<blockquote>
<p><strong>空对象</strong></p>
<p>类NullObjectMutex是<a href="https://en.wikipedia.org/wiki/Null_object_pattern">空对象模式</a>的一个例子，由空方法组成，算是一个占位符，这样便于优化器可以将它完全删除。</p>
</blockquote>
<p><strong>编译时多态</strong></p>
<p>基于模板的实现与基于面向对象的实现非常相似。</p>
<p>编译时多态性策略锁</p>
<pre><code class="language-c++">// StrategizedLockingCompileTime.cpp

#include &lt;iostream&gt;
#include &lt;mutex&gt;
#include &lt;shared_mutex&gt;


template &lt;typename LOCK&gt;
class StrategizedLocking {
  LOCK&amp; lock;
public:
  StrategizedLocking(LOCK&amp; l) :lock(l) {
    lock.lock();
  }
  ~StrategizedLocking() {
    lock.unlock();
  }
};

struct NullObjectMutex {
  void lock() {};
  void unlock() {};
};

class NoLock {
public:
  void lock() const {
    std::cout &lt;&lt; &quot;NoLock::lock: &quot; &lt;&lt; std::endl;
    nullObjectMutex.lock();
  }
  void unlock() const {
    std::cout &lt;&lt; &quot;NoLock::unlock: &quot; &lt;&lt; std::endl;
    nullObjectMutex.unlock();
  }
  mutable NullObjectMutex nullObjectMutex;
};

class ExclusiveLock {
public:
  void lock() const {
    std::cout &lt;&lt; &quot;  ExclusiveLock::lock: &quot; &lt;&lt; std::endl;
    mutex.lock();
  }
  void unlock() const {
    std::cout &lt;&lt; &quot;  ExclusiveLock::unlock: &quot; &lt;&lt; std::endl;
    mutex.unlock();
  }
  mutable std::mutex mutex;
};

class SharedLock {
public:
  void lock() const {
    std::cout &lt;&lt; &quot; SharedLock::lock_shared: &quot; &lt;&lt; std::endl;
    sharedMutex.lock_shared();
  }
  void unlock() const {
    std::cout &lt;&lt; &quot; SharedLock::unlock_shared: &quot; &lt;&lt; std::endl;
    sharedMutex.unlock_shared();
  }
  mutable std::shared_mutex sharedMutex;
};

int main() {

  std::cout &lt;&lt; std::endl;

  NoLock noLock;
  StrategizedLocking stratLock1{ noLock };

  {
    ExclusiveLock exLock;
    StrategizedLocking stratLock2{ exLock };
    {
      SharedLock sharLock;
      StrategizedLocking startLock3{ sharLock };
    }
  }

  std::cout &lt;&lt; std::endl;

}
</code></pre>
<p>这次<code>NoLock</code>(第25行)、<code>ExclusiveLock</code>(第38行)和<code>SharedLock</code>(第51行)没有抽象的基类了。结果<code>StrategizedLocking</code>可以用不支持相应接口的对象进行实例化，而这将导致编译时错误。C++20中，可以使用<code>Lockable : template &lt;Lockable Lock&gt; class StrategizedLocking</code>代替<code>template &lt;typename Lock&gt; class StrategizedLocking</code>。这意味着所有使用的锁必须支持Lockable<a href="https://en.cppreference.com/w/cpp/language/constraints">概念</a>。概念需要命名，并且<a href="https://en.cppreference.com/w/cpp/named_req">Lockable</a>已经在C++20中定义了。如果没有满足此要求，则编译将失败，并出现简单易懂的错误消息。</p>
<p>两个程序会生成相同的输出:</p>
<p><img src="content/Pattrns/Synchronisation-Patterns/../../../images/Patterns/Synchronisation-Patterns/9.png" alt="" /></p>
<p><strong>拓展阅读</strong></p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Design_Patterns">Design Patterns: Elements of Reusable Object-Oriented Software</a></li>
<li><a href="https://en.wikipedia.org/wiki/Strategy_pattern">Strategy Pattern</a></li>
<li><a href="https://en.wikipedia.org/wiki/Null_object_pattern">Null Object Pattern</a></li>
<li><a href="https://www.dre.vanderbilt.edu/%7Eschmidt/POSA/POSA2/">Pattern-Oriented Software Architecture: Patterns for Concurrent and Networked Objects</a></li>
</ul>
<h2 id="线程安全的接口"><a class="header" href="#线程安全的接口">线程安全的接口</a></h2>
<p>当程序的关键部分只是一个对象时，那么使用线程安全的接口就在合适不过了。用锁可能会导致性能问题，甚至会导致死锁。下面的伪代码可以清楚地阐明我的观点。</p>
<pre><code class="language-c++">struct Critical{
  void method1(){
    lock(mut);
    method2();
    ...
  }
  void method2(){
    lock(mut);
    ...
  }
  mutex mut;
};

Critical crit;
crit.method1();
</code></pre>
<p>使用<code>crit.method1</code>会使互斥锁锁定两次。为了简单起见，这个锁是一个范围锁。当然，这里还有两个问题：</p>
<ol>
<li>当<code>lock</code>是递归锁时，<code>method2</code>中的第二个<code>lock(mut)</code>是多余的。</li>
<li>当<code>lock</code>不是递归锁时，<code>method2</code>中的第二个<code>lock(mut)</code>会导致未定义行为。大多数情况下，会出现死锁。</li>
</ol>
<p>线程安全的接口可以避免这两个问题，因为：</p>
<ul>
<li>所有(public)接口都应该使用锁。</li>
<li>所有(保护的和私有的)方法都不使用锁。</li>
<li>接口只能使用保护的方法或私有方法调用，而公共方法则不能调用。</li>
</ul>
<p>threadSafeInterface.cpp程序显示了其用法。</p>
<pre><code class="language-c++">// threadSafeInterface.cpp

#include &lt;iostream&gt;
#include &lt;mutex&gt;
#include &lt;shared_mutex&gt;

class Critical {

public:
  void interface1() const {
    std::lock_guard&lt;std::mutex&gt; lockGuard(mut);
    implementation1();
  }
  void interface2() {
    std::lock_guard&lt;std::mutex&gt; lockGuard(mut);
    implementation2();
    implementation3();
    implementation1();
  }
private:
  void implementation1() const {
    std::cout &lt;&lt; &quot;implementation1: &quot;
      &lt;&lt; std::this_thread::get_id() &lt;&lt; std::endl;
  }
  void implementation2() const {
    std::cout &lt;&lt; &quot;  implementation2: &quot;
      &lt;&lt; std::this_thread::get_id() &lt;&lt; std::endl;
  }
  void implementation3() const {
    std::cout &lt;&lt; &quot;   implementation3: &quot;
      &lt;&lt; std::this_thread::get_id() &lt;&lt; std::endl;
  }


  mutable std::mutex mut;

};

int main() {

  std::cout &lt;&lt; std::endl;

  std::thread t1([] {
    const Critical crit;
    crit.interface1();
    });

  std::thread t2([] {
    Critical crit;
    crit.interface2();
    crit.interface1();
    });


  Critical crit;
  crit.interface1();
  crit.interface2();

  t1.join();
  t2.join();

  std::cout &lt;&lt; std::endl;

}
</code></pre>
<p>包括主线程在内的三个线程都使用了Critical实例。由于线程安全的接口，所有对公开API的调用都是同步的。第35行中的互斥对象是可变的，因此可以在const方法<code>implementation1</code>中使用。</p>
<p>线程安全的接口有三个好处：</p>
<ol>
<li>互斥锁不可能递归调用。在C++中，对非递归互斥对象的递归调用会导致未定义行为，通常都会死锁。</li>
<li>该程序使用最小范围的锁定，因此同步的代价最小。仅在关键类的公共或私有方法中使用<code>std::recursive_mutex</code>将产生重量级的同步，从而遭受性能惩罚。</li>
<li>从用户的角度来看，<code>Critical</code>很容易使用，而同步只是实现的一个细节而已。</li>
</ol>
<p>三个线程交错的输出：</p>
<p><img src="content/Pattrns/Synchronisation-Patterns/../../../images/Patterns/Synchronisation-Patterns/10.png" alt="" /></p>
<p>尽管线程安全的接口看起来很容易实现，但是也需要留意两个风险点。</p>
<p><strong>风险</strong></p>
<p>类中使用静态成员和使用虚接口时，需要特别小心。</p>
<p><strong>静态成员</strong></p>
<p>当类有静态成员时，就必须同步该类实例上的所有成员函数。</p>
<pre><code class="language-c++">class Critical {

public:
  void interface1() const {
    std::lock_guard&lt;std::mutex&gt; lockGuard(mut);
    implementation1();
  }
  void interface2() {
    std::lock_guard&lt;std::mutex&gt; lockGuard(mut);
    implementation2();
    implementation3();
    implementation1();
  }
  
private:
  void implementation1() const {
    std::cout &lt;&lt; &quot;implementation1: &quot;
      &lt;&lt; std::this_thread::get_id() &lt;&lt; std::endl;
    ++called;
  }
  void implementation2() const {
    std::cout &lt;&lt; &quot;  implementation2: &quot;
      &lt;&lt; std::this_thread::get_id() &lt;&lt; std::endl;
    ++called;
  }
  void implementation3() const {
    std::cout &lt;&lt; &quot;   implementation3: &quot;
      &lt;&lt; std::this_thread::get_id() &lt;&lt; std::endl;
    ++called;
  }

  inline static int called{ 0 };
  inline static std::mutex mut;

};
</code></pre>
<p><code>Critical</code>类使用了静态成员(第32行)来计算调用成员函数的频率。<code>Critical</code>的所有实例，都使用同一个静态成员，因此必须同步。本例中，临界区为<code>Critical</code>的所有实例。</p>
<blockquote>
<p>内联静态成员</p>
<p>C++17中，静态数据成员可以声明为内联。可以在类中定义，以及初始化内联静态数据成员。</p>
<pre><code class="language-c++">struct X
{
  	inline static int n = 1;
}
</code></pre>
</blockquote>
<p><strong>虚接口</strong></p>
<p>当重写虚接口函数时，即使重写的函数是私有的，也应该有锁。</p>
<pre><code class="language-c++">// threadSafeInterfaceVirtual.cpp

#include &lt;iostream&gt;
#include &lt;mutex&gt;
#include &lt;thread&gt;

class Base {

public:
  virtual void interface() {
    std::lock_guard&lt;std::mutex&gt; lockGuard(mut);
    std::cout &lt;&lt; &quot;Base with lock&quot; &lt;&lt; std::endl;
  }
private:
  std::mutex mut;
};

class Derived : public Base {

  void interface() override {
    std::cout &lt;&lt; &quot;Derived without lock&quot; &lt;&lt; std::endl;
  };

};

int main() {

  std::cout &lt;&lt; std::endl;

  Base* base1 = new Derived;
  base1-&gt;interface();

  Derived der;
  Base&amp; base2 = der;
  base2.interface();

  std::cout &lt;&lt; std::endl;

}
</code></pre>
<p><code>base1-&gt;interface</code>和<code>base2.interface</code>中，<code>base1</code>和<code>base2</code>是静态类型是<code>Base</code>，因此<code>interface</code>是一个公开接口。由于接口方法是虚函数，因此在运行时使用派生的动态类型Derived进行。最后，调用派生类Derived的私有接口。</p>
<p><img src="content/Pattrns/Synchronisation-Patterns/../../../images/Patterns/Synchronisation-Patterns/11.png" alt="" /></p>
<p>有两种方法可以避免风险：</p>
<ol>
<li>使接口成为非虚接口，这种技术称为<a href="https://en.wikibooks.org/wiki/More_C%2B%2B_Idioms/Non-Virtual_Interface">NVI(非虚拟接口)</a>。</li>
<li>将接口声明为<code>final</code>: <code>virtual void interface() final;</code>。</li>
</ol>
<p><strong>扩展阅读</strong></p>
<ul>
<li><a href="https://www.dre.vanderbilt.edu/%7Eschmidt/POSA/POSA2/">Pattern-Oriented Software Architecture: Patterns for Concurrent and Networked Objects</a></li>
</ul>
<h2 id="保护性暂挂模式"><a class="header" href="#保护性暂挂模式">保护性暂挂模式</a></h2>
<p>锁和一些先决条件的组合，是构成保护性暂挂模式的基础件。如果未满足先决条件，则线程将自己置为休眠状态。为了避免数据竞争或死锁，检查线程时会使用锁。</p>
<p>现在，来看看各种情况:</p>
<ul>
<li>处于等待状态的线程，会根据通知更改状态，也可以主动请求更改状态。我把这称为“推拉原则”。</li>
<li>等待可以有时限，也可以没有时限。</li>
<li>可以将通知发送给一个或所有正在等待的线程。</li>
</ul>
<p><strong>推拉原则</strong></p>
<p>先来说说推原则。</p>
<p><strong>推原则</strong></p>
<p>大多数情况下，使用条件变量或future/promise来进行线程同步。条件变量或promise将通知发送到正在等待的线程。promise没有<code>notify_one</code>或<code>notify_all</code>方法，而空的<code>set_value</code>调用通常用于模拟通知。下面的程序段展示发送通知的线程和等待的线程。</p>
<ul>
<li>条件变量</li>
</ul>
<pre><code class="language-c++">void waitingForWork(){
  std::cout &lt;&lt; &quot;Worker: Waiting for work.&quot; &lt;&lt; std::endl;
  std::unique_lock&lt;std::mutex&gt; lck(mutex_);
  condVar.wait(lck, []{ return dataReady; });
  doTheWork();
  std::cout &lt;&lt; &quot;Work done.&quot; &lt;&lt; std::endl;
}

void setDataReady(){
  {
    std::lock_guard&lt;std::mutex&gt; lck(mutex_);
    dataReady = true;
  }
  std::cout &lt;&lt; &quot;Sender: Data is ready.&quot; &lt;&lt; std::endl;
  condVar.notify_one();
}
</code></pre>
<ul>
<li>future/promise</li>
</ul>
<pre><code class="language-c++">void waitingForWork(std::future&lt;void&gt;&amp;&amp; fut){
  std::cout &lt;&lt; &quot;Worker: Waiting for work.&quot; &lt;&lt; std::endl;
  fut.wait();
  doTheWork();
  std::cout &lt;&lt; &quot;Work done.&quot; &lt;&lt; std::endl;
}
void setDataReady(std::promise&lt;void&gt;&amp;&amp; prom){
  std::cout &lt;&lt; &quot;Sender: Data is ready.&quot; &lt;&lt; std::endl;
  prom.set_value();
}
</code></pre>
<p><strong>拉原则</strong></p>
<p>线程也可以主动地要求改变状态，而不是被动地等待状态改变。C++中并不支持“拉原则”，但可以用原子变量来实现。</p>
<pre><code class="language-c++">std::vector&lt;int&gt; mySharedWork;
std::mutex mutex_;
std::condition_variable condVar;

bool dataReady{false};

void waitingForWork(){
  std::cout &lt;&lt; &quot;Waiting &quot; &lt;&lt; std::endl;
  std::unique_lock&lt;std::mutex&gt; lck(mutex_);
  condVar.wait(lck, []{ return dataReady; });
  mySharedWork[1] = 2;
  std::cout &lt;&lt; &quot;Work done &quot; &lt;&lt; std::endl;
}

void setDataReady(){
  mySharedWork = {1, 0, 3};
  {
    std::lock_guard&lt;std::mutex&gt; lck(mutex_);
    dataReady = true;
  }
  std::cout &lt;&lt; &quot;Data prepared&quot; &lt;&lt; std::endl;
  condVar.notify_one();
}
</code></pre>
<p><strong>有或无时限的等待</strong></p>
<p>条件变量和future有三个用于等待的方法:<code>wait</code>、<code>wait_for</code>和<code>wait_until</code>。<code>wait_for</code>需要一个时间段，<code>wait_until</code>需要一个时间点。</p>
<p>各种等待策略中，消费者线程等待时间为<code>steady_clock::now() + dur</code>。如果promise已经准备好了，就会获取值；如果没准备好，则只显示其id: <code>this_thread::get_it()</code>。</p>
<pre><code class="language-c++">void producer(promise&lt;int&gt;&amp;&amp; prom){
  cout &lt;&lt; &quot;PRODUCING THE VALUE 2011\n\n&quot;;
  this_thread::sleep_for(seconds(5));
  prom.set_value(2011);
}

void consumer(shared_future&lt;int&gt; fut,
steady_clock::duration dur){
  const auto start = steady_clock::now();
  future_status status= fut.wait_until(steady_clock::now() + dur);
  if ( status == future_status::ready ){
    lock_guard&lt;mutex&gt; lockCout(coutMutex);
    cout &lt;&lt; this_thread::get_id() &lt;&lt; &quot; ready =&gt; Result: &quot; &lt;&lt; fut.get()
    &lt;&lt; endl;
  }
  else{
    lock_guard&lt;mutex&gt; lockCout(coutMutex);
    cout &lt;&lt; this_thread::get_id() &lt;&lt; &quot; stopped waiting.&quot; &lt;&lt; endl;
  }
  const auto end= steady_clock::now();
  lock_guard&lt;mutex&gt; lockCout(coutMutex);
  cout &lt;&lt; this_thread::get_id() &lt;&lt; &quot; waiting time: &quot;
  		 &lt;&lt; getDifference(start,end) &lt;&lt; &quot; ms&quot; &lt;&lt; endl;
}
</code></pre>
<p><strong>通知一个或所有等待线程</strong></p>
<p><code>notify_one</code>可以唤醒一个等待的线程，<code>notify_all</code>可以唤醒所有等待的线程。使用<code>notify_one</code>时，不能确定哪一个线程会被唤醒，而其他条件变量则保持在等待状态。因为future和promise之间存在关联性，所以这种情况在<code>std::future</code>中是不可能发生的。如果想模拟一对多的关系，那么应该使用<code>std::shared_future</code>而不是<code>std::future</code>，因为<code>std::shared_future</code>是可以复制的。</p>
<p>下面的程序显示了一个简单的工作流，promise和future之间是一对一/一对多的关系。</p>
<pre><code class="language-c++">// bossWorker.cpp

#include &lt;future&gt;
#include &lt;chrono&gt;
#include &lt;iostream&gt;
#include &lt;random&gt;
#include &lt;string&gt;
#include &lt;thread&gt;
#include &lt;utility&gt;

int getRandomTime(int start, int end) {

  std::random_device seed;
  std::mt19937 engine(seed());
  std::uniform_int_distribution&lt;int&gt; dist(start, end);

  return dist(engine);
}

class Worker {
public:
  explicit Worker(const std::string&amp; n) :name(n) {}

  void operator()(std::promise&lt;void&gt;&amp;&amp; prepareWork,
    std::shared_future&lt;void&gt; boss2Worker) {

    // prepare the work and notify the boss
    int prepareTime = getRandomTime(500, 2000);
    std::this_thread::sleep_for(std::chrono::microseconds(prepareTime));
    prepareWork.set_value();
    std::cout &lt;&lt; name &lt;&lt; &quot;: &quot; &lt;&lt; &quot;Work prepared after &quot;
      &lt;&lt; prepareTime &lt;&lt; &quot; milliseconds.&quot; &lt;&lt; std::endl;

    // still waiting for the permission to start working
    boss2Worker.wait();
  }
private:
  std::string name;
};

int main() {

  std::cout &lt;&lt; std::endl;

  // define the std::promise = &gt; Instruction from the boss
  std::promise&lt;void&gt; startWorkPromise;

  // get the std::shared_future's from the std::promise
  std::shared_future&lt;void&gt; startWorkFuture = startWorkPromise.get_future();

  std::promise&lt;void&gt; herbPrepared;
  std::future&lt;void&gt; waitForHerb = herbPrepared.get_future();
  Worker herb(&quot; Herb&quot;);
  std::thread herbWork(herb, std::move(herbPrepared), startWorkFuture);

  std::promise&lt;void&gt; scottPrepared;
  std::future&lt;void&gt; waitForScott = scottPrepared.get_future();
  Worker scott(&quot; Scott&quot;);
  std::thread scottWork(scott, std::move(scottPrepared), startWorkFuture);

  std::promise&lt;void&gt; bjarnePrepared;
  std::future&lt;void&gt; waitForBjarne = bjarnePrepared.get_future();
  Worker bjarne(&quot; Bjarne&quot;);
  std::thread bjarneWork(bjarne, std::move(bjarnePrepared), startWorkFuture);

  std::cout &lt;&lt; &quot;BOSS: PREPARE YOUR WORK.\n &quot; &lt;&lt; std::endl;

  // waiting for the worker
  waitForHerb.wait(), waitForScott.wait(), waitForBjarne.wait();

  // notify the workers that they should begin to work
  std::cout &lt;&lt; &quot;\nBOSS: START YOUR WORK. \n&quot; &lt;&lt; std::endl;
  startWorkPromise.set_value();

  herbWork.join();
  scottWork.join();
  bjarneWork.join();

}
</code></pre>
<p>该程序的关键思想是boss(主线程)有三个员工：herb(第53行)、scott(第58行)和bjarne(第63行)，每个worker由一个线程表示。老板在第64行等待，直到所有的员工完成工作。这意味着，每个员工在任务下发后的任意时间点，都可以向老板发送完成通知。因为会转到<code>std::future</code>，所以员工到老板的通知是一对一的(第30行)。而从老板到员工的工作指令，则是一对多的通知(第73行)。对于这个一对多的通知，需要使用<code>std::shared_future</code>。</p>
<p><img src="content/Pattrns/Synchronisation-Patterns/../../../images/Patterns/Synchronisation-Patterns/12.png" alt="" /></p>
<p><strong>扩展阅读</strong></p>
<ul>
<li><a href="http://gee.cs.oswego.edu/dl/cpj/">Concurrent Programming in Java: Design Principles and Patterns (Doug Lea)</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="并发架构"><a class="header" href="#并发架构">并发架构</a></h1>
<p>本章介绍三种经典架构模式，在<a href="https://www.dre.vanderbilt.edu/%7Eschmidt/POSA/POSA2/">《面向模式的软件体系结构：并发和网络对象的模式》</a>中都有很好的解释。本章会简单概述一下活动对象、监控对象和半同步/半异步模式。在同步模式中，我会使用C++作为第一视角。在深入研究这三种模式之前，先做对这几个模式进行简单的介绍。</p>
<ul>
<li>活动对象的设计模式将执行与调用进行解耦，每个对象会留在自己的控制线程中，其目标是通过使用异步方法和调度器来引入并发。维基百科：<a href="https://en.wikipedia.org/wiki/Active_object">Active object</a></li>
<li>监控对象的设计模式，会同步并发方法的执行，以确保对象每次只运行一个成员函数。并且，还允许对象的成员函数协同调度序列的执行。</li>
</ul>
<p>这两种模式可以以同步和调度的方式运行。主要的区别是，活动对象在不同的线程中执行，而监控对象与客户端则是在相同的线程中执行。与关注子系统的活动对象和监控对象(因此通常称为设计模式)不同，以下的体系结构模式具有系统视角。</p>
<ul>
<li>半同步/半异步体系结构模式，在并发系统中对异步和同步服务处理进行解耦，从而在不降低太多性能的情况下简化编程。该模式引入了两个通信层，一个用于异步，另一个用于同步。</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="活动对象"><a class="header" href="#活动对象">活动对象</a></h1>
<p>活动对象模式将执行与对象的成员函数解耦，每个对象会留在在自己的控制线程中。其目标是通过使用异步方法，处理调度器的请求，从而触发并发。维基百科：<a href="https://en.wikipedia.org/wiki/Active_object">Active object</a>。所以，这种模式也称为并发对象模式。</p>
<p>客户端的调用会转到代理，代理表现为活动对象的接口。服务提供活动对象的实现，并在单独的线程中运行。代理在运行时将客户端的调用转换为对服务的调用，调度程序将方法加入到激活列表中。调度器与服务在相同的线程中活动，并将方法调用从激活列表中取出，再将它们分派到相应的服务上。最后，客户端可以通过future从代理处获取最终的结果。</p>
<h2 id="组件"><a class="header" href="#组件">组件</a></h2>
<p>活动对象模式由六个组件组成:</p>
<ol>
<li>代理为活动对象的可访问方法提供接口。代理将触发激活列表的方法，并请求对象的构造。并且，代理和客户端运行在相同的线程中。</li>
<li>方法请求类定义了执行活动对象的接口。</li>
<li>激活列表的目标是维护挂起的请求，激活列表将客户端线程与活动对象线程解耦。代理对入队请求的进行处理，而调度器将请求移出队列。</li>
<li>调度器与代理可在不同的线程中运行。调度器会在活动对象的线程中运行，并决定接下来执行激活列表中的哪个请求。</li>
<li>可以通过服务实现活动对象，并在活动对象的线程中运行，服务也支持代理接口。</li>
<li>future是由代理创造的，客户端可以从future上获取活动对象调用的结果。客户端可以安静等待结果，也可以对结果进行轮询。</li>
</ol>
<p>下面的图片显示了消息的顺序。</p>
<p><img src="content/Pattrns/Concurrent-Architecture/../../../images/Patterns/Concurrent-Architecture/1.png" alt="" /></p>
<blockquote>
<p><strong>代理</strong></p>
<p>代理设计模式是<a href="https://en.wikipedia.org/wiki/Design_Patterns">《设计模式:可重用的面向对象软件的元素》</a>中的经典模式，代理是其他对象的代表。典型的代理可以是远程代理<a href="https://en.wikipedia.org/wiki/Common_Object_Request_Broker_Architecture">CORBA</a>、安全代理、虚拟代理或智能指针，如<code>std::shared_ptr</code>。每个代理会为它所代表的对象添加额外的功能。远程代理代表远程对象，并使客户端产生本地对象的错觉。安全代理通过对数据进行加密和解密，将不安全的连接转换为安全的连接。虚拟代理以惰性的方式封装对象的创建，智能指针将接管底层内存的生存期。</p>
<p><img src="content/Pattrns/Concurrent-Architecture/../../../images/Patterns/Concurrent-Architecture/2.png" alt="" /></p>
<ul>
<li>代理具有与RealSubject相同的接口，用于管理引用，还有subject的生命周期。</li>
<li>与Subject具有相同的接口，如代理和RealSubject。</li>
<li>RealSubject用于提供具体的功能。</li>
</ul>
<p>关于代理模式的更多细节，可以参考<a href="https://en.wikipedia.org/wiki/Proxy_pattern">Wikipedia</a>页面。</p>
</blockquote>
<h2 id="优点和缺点"><a class="header" href="#优点和缺点">优点和缺点</a></h2>
<p>介绍Active Object模式的最小实现前，先了解一下它的优点和缺点。</p>
<ul>
<li>优点:
<ul>
<li>同步只需要在活动对象的线程上进行，不需要在客户端的线程上进行。</li>
<li>客户端(用户)和服务器(实现者)之间的解耦，同步的挑战则在实现者的一边。</li>
<li>由于客户端为异步请求，所以系统的吞吐量提高了，从而调用处理密集型方法不会阻塞整个系统。</li>
<li>调度器可以实现各种策略来执行挂起请求，因此可以按不同的顺序执行入队请求。</li>
</ul>
</li>
<li>缺点:
<ul>
<li>如果请求的粒度太细，则活动对象模式(如代理、激活列表和调度器)的性能开销可能过大。</li>
<li>由于调度器的调度策略和操作系统的调度互相影响，调试活动对象模式通常非常困难，尤其是以不同顺序执行请求的情况下。</li>
</ul>
</li>
</ul>
<h2 id="具体实现"><a class="header" href="#具体实现">具体实现</a></h2>
<p>下面的示例展示了活动对象模式的简单实现。我没有定义一个请求，这应该由代理和服务实现。而且，当请求调度程序执行下一个请求时，服务应该只执行这个请求。</p>
<p>所涉及的类型为<code>future&lt;vector&lt;future&lt;pair&lt;bool, int&gt;&gt;&gt;&gt;</code>，这个类型的标识有点长。为了提高可读性，我使用了声明(第16 - 37行)。</p>
<pre><code class="language-c++">// activeObject.cpp

#include &lt;algorithm&gt;
#include &lt;deque&gt;
#include &lt;functional&gt;
#include &lt;future&gt;
#include &lt;iostream&gt;
#include &lt;memory&gt;
#include &lt;mutex&gt;
#include &lt;numeric&gt;
#include &lt;random&gt;
#include &lt;thread&gt;
#include &lt;utility&gt;
#include &lt;vector&gt;

using std::async;
using std::boolalpha;
using std::cout;
using std::deque;
using std::distance;
using std::endl;
using std::for_each;
using std::find_if;
using std::future;
using std::lock_guard;
using std::make_move_iterator;
using std::make_pair;
using std::move;
using std::mt19937;
using std::mutex;
using std::packaged_task;
using std::pair;
using std::random_device;
using std::sort;
using std::thread;
using std::uniform_int_distribution;
using std::vector;

class IsPrime {
public:
  pair&lt;bool, int&gt; operator()(int i) {
    for (int j = 2; j * j &lt;= i; ++j) {
      if (i % j == 0)return std::make_pair(false, i);
    }
    return std::make_pair(true, i);
  }
};

class ActivaeObject {
public:

  future&lt;pair&lt;bool, int&gt;&gt; enqueueTask(int i) {
    IsPrime isPrime;
    packaged_task&lt;pair&lt;bool, int&gt;(int)&gt; newJob(isPrime);
    auto isPrimeFuture = newJob.get_future();
    auto pair = make_pair(move(newJob), i);
    {
      lock_guard&lt;mutex&gt; lockGuard(activationListMutex);
      activationList.push_back(move(pair));
    }
    return isPrimeFuture;
  }

  void run() {
    thread servant([this] {
      while (!isEmpty()) {
        auto myTask = dequeueTask();
        myTask.first(myTask.second);
      }
      });
    servant.join();
  }

private:

  pair&lt;packaged_task&lt;pair&lt;bool, int&gt;(int)&gt;, int&gt; dequeueTask() {
    lock_guard&lt;mutex&gt; lockGuard(activationListMutex);
    auto myTask = std::move(activationList.front());
    activationList.pop_front();
    return myTask;
  }

  bool isEmpty() {
    lock_guard&lt;mutex&gt; lockGuard(activationListMutex);
    auto empty = activationList.empty();
    return empty;
  }

  deque&lt;pair&lt;packaged_task&lt;pair&lt;bool, int&gt;(int)&gt;, int &gt;&gt; activationList;
  mutex activationListMutex;
};

vector&lt;int&gt; getRandNumber(int number) {
  random_device seed;
  mt19937 engine(seed());
  uniform_int_distribution&lt;&gt; dist(1000000, 1000000000);
  vector&lt;int&gt; numbers;
  for (long long i = 0; i &lt; number; ++i) numbers.push_back(dist(engine));
  return numbers;
}

future&lt;vector&lt;future&lt;pair&lt;bool, int&gt;&gt;&gt;&gt; getFutures(ActivaeObject&amp; activeObject,
  int numberPrimes) {
  return async([&amp;activeObject, numberPrimes] {
    vector&lt;future&lt;pair&lt;bool, int&gt;&gt;&gt; futures;
    auto randNumbers = getRandNumber(numberPrimes);
    for (auto numb : randNumbers) {
      futures.push_back(activeObject.enqueueTask(numb));
    }
    return futures;
    });
}


int main() {

  cout &lt;&lt; boolalpha &lt;&lt; endl;

  ActivaeObject activeObject;

  // a few clients enqueue work concurrently
  auto client1 = getFutures(activeObject, 1998);
  auto client2 = getFutures(activeObject, 2003);
  auto client3 = getFutures(activeObject, 2011);
  auto client4 = getFutures(activeObject, 2014);
  auto client5 = getFutures(activeObject, 2017);

  // give me the futures
  auto futures = client1.get();
  auto futures2 = client2.get();
  auto futures3 = client3.get();
  auto futures4 = client4.get();
  auto futures5 = client5.get();

  // put all futures together
  futures.insert(futures.end(), make_move_iterator(futures2.begin()),
    make_move_iterator(futures2.end()));

  futures.insert(futures.end(), make_move_iterator(futures3.begin()),
    make_move_iterator(futures3.end()));

  futures.insert(futures.end(), make_move_iterator(futures4.begin()),
    make_move_iterator(futures4.end()));

  futures.insert(futures.end(), make_move_iterator(futures5.begin()),
    make_move_iterator(futures5.end()));

  // run the promises
  activeObject.run();

  // get the results from the futures
  vector&lt;pair&lt;bool, int&gt;&gt; futResults;
  futResults.reserve(futResults.size());
  for (auto&amp; fut : futures)futResults.push_back(fut.get());

  sort(futResults.begin(), futResults.end());

  // separate the primes from the non-primes
  auto prIt = find_if(futResults.begin(), futResults.end(),
    [](pair&lt;bool, int&gt;pa) {return pa.first == true; });

  cout &lt;&lt; &quot;Number primes: &quot; &lt;&lt; distance(prIt, futResults.end()) &lt;&lt; endl;
  cout &lt;&lt; &quot;Primes: &quot; &lt;&lt; endl;
  for_each(prIt, futResults.end(), [](auto p) {cout &lt;&lt; p.second &lt;&lt; &quot; &quot;; });

  cout &lt;&lt; &quot;\n\n&quot;;

  cout &lt;&lt; &quot;Number no primes: &quot; &lt;&lt; distance(futResults.begin(), prIt) &lt;&lt; endl;
  cout &lt;&lt; &quot;No primes: &quot; &lt;&lt; endl;
  for_each(futResults.begin(), prIt, [](auto p) {cout &lt;&lt; p.second &lt;&lt; &quot; &quot;; });

  cout &lt;&lt; endl;

}
</code></pre>
<p>示例的基本思想是，客户端可以在激活列表上并发地安排作业。线程的工作是确定哪些数是质数。激活列表是活动对象的一部分，而活动对象在一个单独的线程上进行入队操作，并且客户端可以在激活列表中查询作业的结果。</p>
<p>程序的详情：5个客户端通过<code>getFutures</code>将工作(第121 - 126行)入队到<code>activeObject</code>。<code>numberPrimes</code>中的数字是1000000到1000000000之间(第96行)的随机数，将这些数值放入<code>vector&lt;future&lt;pair&lt;bool, int&gt;&gt; </code>中。<code>future&lt;pair&lt;bool, int&gt;</code>持有一个<code>bool</code>和<code>int</code>对，其中<code>bool</code>表示<code>int</code>值是否是质数。再看看第108行：<code>future .push_back(activeObject.enqueueTask(numb))</code>。此调用将触发新作业进入激活列表的队列，所有对激活列表的调用都必须受到保护，这里激活列表是一个promise队列(第89行)：<code>deque&lt;pair&lt;packaged_task&lt;pair&lt;bool, int&gt;(int)&gt;, int &gt;&gt; </code>。</p>
<p>每个promise在调用执行函数对象<code>IsPrime</code>(第39 - 47行)时，会返回一个<code>bool</code>和<code>int</code>对。现在，工作包已经准备好了，开始计算吧。所有客户端在第129 - 133行中返回关联future的句柄，并把所有的future放在一起(第136 - 146行)，这样会使工作更加容易。第149行中的调用<code>activeObject.run()</code>启动执行。<code>run</code>(第64 - 72行)启动单独的线程，并执行promises(第68行)，直到执行完所有作业(第66行)。<code>isEmpty</code>(第83 - 87行)确定队列是否为空，<code>dequeTask</code>会返回一个新任务。通过在每个<code>future</code>上调用<code>futResults.push_back(fut.get())</code>(第154行)，所有结果都会推送到<code>futResults</code>上。第156行对成对的向量进行排序:<code>vector&lt;pair&lt;bool, int&gt;&gt;</code>。其余代码则是给出了计算结果，第159行中的迭代器<code>prIt</code>将第一个迭代器指向一个素数对。</p>
<p>程序打印素数数量为<code>distance(prIt, futResults.end())</code>(第162行)，并(第164行)逐一显示。</p>
<p><img src="content/Pattrns/Concurrent-Architecture/../../../images/Patterns/Concurrent-Architecture/3.png" alt="" /></p>
<h2 id="拓展阅读"><a class="header" href="#拓展阅读">拓展阅读</a></h2>
<ul>
<li><a href="https://www.dre.vanderbilt.edu/%7Eschmidt/POSA/POSA2/">Pattern-Oriented Software Architecture: Patterns for Concurrent and Networked Objects</a></li>
<li><a href="http://www.drdobbs.com/parallel/prefer-using-active-objects-instead-of-n/225700095">Prefer Using Active Object instead of Naked Thread (Herb Sutter)</a></li>
<li><a href="https://github.com/lightful/syscpp/">Active Object implementation in C++11</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="监控对象"><a class="header" href="#监控对象">监控对象</a></h1>
<p>监控对象模式会同步并发执行，以确保对象只执行一个方法。并且，还允许对象的方法协同调度执行序列。这种模式也称为线程安全的被动对象模式。</p>
<h2 id="模式要求"><a class="header" href="#模式要求">模式要求</a></h2>
<p>多个线程同时访问一个共享对象时，需要满足以下要求：</p>
<ol>
<li>并发访问时，需要保护共享对象不受非同步读写操作的影响，以避免数据争用。</li>
<li>必要的同步是实现的一部分，而不是接口的一部分。</li>
<li>当线程处理完共享对象时，需要发送一个通知，以便下一个线程可以使用共享对象。这种机制有助于避免死锁，并提高系统的整体性能。</li>
<li>方法执行后，共享对象的不变量必须保持不变。</li>
</ol>
<p>客户端(线程)可以访问监控对象的同步方法。因为监控锁在任何时间点上，只能运行一个同步方法。每个监控对象都有一个通知等待客户端的监控条件。</p>
<h2 id="组件-1"><a class="header" href="#组件-1">组件</a></h2>
<p>监控对象由四个组件组成。</p>
<p><img src="content/Pattrns/Concurrent-Architecture/../../../images/Patterns/Concurrent-Architecture/4.png" alt="" /></p>
<ol>
<li>监控对象：支持一个或多个方法。每个客户端必须通过这些方法访问对象，每个方法都必须在客户端线程中运行。</li>
<li>同步方法：监控对象支持同步方法。任何给定的时间点上，只能执行一个方法。线程安全接口有助于区分接口方法(同步方法)和(监控对象的)实现方法。</li>
<li>监控锁：每个监控对象有一个监控锁，锁可以确保在任何时间点上，只有一个客户端可以访问监控对象。</li>
<li>监控条件：允许线程在监控对象上进行调度。当前客户端完成同步方法的调用后，下一个等待的客户端将被唤醒。</li>
</ol>
<p>虽然监控锁可以确保同步方法的独占访问，但是监控条件可以保证客户端的等待时间最少。实质上，监控锁可以避免数据竞争，条件监控可以避免死锁。</p>
<h2 id="运行时行为"><a class="header" href="#运行时行为">运行时行为</a></h2>
<p>监控对象及其组件之间的交互具有不同的阶段。</p>
<ul>
<li>当客户端调用监控对象的同步方法时，必须锁定全局监控锁。如果客户端成功访问，将执行同步方法，并在结束时解锁。如果客户端访问不成功，则阻塞客户端，进入等待状态。</li>
<li>当客户端阻塞时，监控对象会在解锁时，对阻塞的客户端发送通知。通常，等待是资源友好的休眠，而不是忙等。</li>
<li>当客户端收到通知时，会锁定监控锁，并执行同步方法。同步方法结束时解锁，并发送监控条件的通知，以通知下一个客户端去执行。</li>
</ul>
<h2 id="优点和缺点-1"><a class="header" href="#优点和缺点-1">优点和缺点</a></h2>
<p>监控对象的优点和缺点是什么?</p>
<ul>
<li>优点:
<ul>
<li>同步方法会完全封装在实现中，所以客户端不知道监控对象会隐式同步。</li>
<li>同步方法将自动调度监控条件的通知/等待机制，其表现类似一个简单的调度器。</li>
</ul>
</li>
<li>缺点:
<ul>
<li>功能和同步是强耦合的，所以很难改变同步机制。</li>
<li>当同步方法直接或间接调用同一监控对象时，可能会发生死锁。</li>
</ul>
</li>
</ul>
<p>下面的程序段中定义了一个ThreadSafeQueue。</p>
<pre><code class="language-c++">// monitorObject.cpp

#include &lt;condition_variable&gt;
#include &lt;functional&gt;
#include &lt;queue&gt;
#include &lt;iostream&gt;
#include &lt;mutex&gt;
#include &lt;random&gt;
#include &lt;thread&gt;

template &lt;typename T&gt;
class Monitor {
public:
  void lock() const {
    monitMutex.lock();
  }
  void unlock() const {
    monitMutex.unlock();
  }

  void notify_one() const noexcept {
    monitCond.notify_one();
  }
  void wait() const {
    std::unique_lock&lt;std::recursive_mutex&gt; monitLock(monitMutex);
    monitCond.wait(monitLock);
  }

private:
  mutable std::recursive_mutex monitMutex;
  mutable std::condition_variable_any monitCond;
};

template &lt;typename T&gt;
class ThreadSafeQueue : public Monitor&lt;ThreadSafeQueue&lt;T&gt;&gt; {
public:
  void add(T val) {
    derived.lock();
    myQueue.push(val);
    derived.unlock();
    derived.notify_one();
  }

  T get() {
    derived.lock();
    while (myQueue.empty()) derived.wait();
    auto val = myQueue.front();
    myQueue.pop();
    derived.unlock();
    return val;
  }
private:
  std::queue&lt;T&gt; myQueue;
  ThreadSafeQueue&lt;T&gt;&amp; derived = static_cast&lt;ThreadSafeQueue&lt;T&gt;&amp;&gt;(*this);
};

class Dice {
public:
  int operator()() { return rand(); }
private:
  std::function&lt;int()&gt;rand = std::bind(std::uniform_int_distribution&lt;&gt;(1, 6), 
    std::default_random_engine());
};


int main() {

  std::cout &lt;&lt; std::endl;

  constexpr auto NUM = 100;

  ThreadSafeQueue&lt;int&gt; safeQueue;
  auto addLambda = [&amp;safeQueue](int val) {safeQueue.add(val); };
  auto getLambda = [&amp;safeQueue] {std::cout &lt;&lt; safeQueue.get() &lt;&lt; &quot; &quot;
    &lt;&lt; std::this_thread::get_id() &lt;&lt; &quot;;&quot;;
  };

  std::vector&lt;std::thread&gt; addThreads(NUM);
  Dice dice;
  for (auto&amp; thr : addThreads) thr = std::thread(addLambda, dice());

  std::vector&lt;std::thread&gt; getThreads(NUM);
  for (auto&amp; thr : getThreads) thr = std::thread(getLambda);

  for (auto&amp; thr : addThreads) thr.join();
  for (auto&amp; thr : addThreads) thr.join();

  std::cout &lt;&lt; &quot;\n\n&quot;;

}
</code></pre>
<p>该示例的核心思想是，将监控对象封装在一个类中，这样就可以重用。监控类使用<code>std::recursive_mutex</code>作为监控锁，<code>std::condition_variable_any</code>作为监控条件。与<code>std::condition_variable</code>不同，<code>std::condition_variable_any</code>能够接受递归互斥。这两个成员变量都声明为可变，因此可以在常量方法中使用。监控类提供了监控对象的最小支持接口。</p>
<p>第34 - 55行中的<code>ThreadSafeQueue</code>使用线程安全接口扩展了第53行中的<code>std::queue</code>。<code>ThreadSafeQueue</code>继承于监控类，并使用父类的方法来支持同步的方法<code>add</code>和<code>get</code>。方法<code>add</code>和<code>get</code>使用监控锁来保护监控对象，特别是非线程安全的<code>myQueue</code>。当一个新项添加到<code>myQueue</code>时，<code>add</code>会通知等待线程，并且这个通知是线程安全的。当如<code>ThreadSafeQueue</code>这样的模板类，将派生类作为基类的模板参数时，这属于C++的一种习惯性用法，称为CRTP：<code>class ThreadSafeQueue: public Monitor&lt;threadsafequeue&lt;T&gt;&gt;</code>。理解这个习惯的关键是第54行：<code>ThreadSafeQueue&lt;T&gt;&amp; derived = static_cast&lt;threadsafequeue&lt;T&gt;&amp;&gt;(*this)</code>，该表达式将<code>this</code>指针向下转换为派生类。监控对象<code>safeQueue</code>第72行使用(第73行和第74行中的)Lambda函数添加一个数字，或从同步的<code>safeQueue</code>中删除一个数字。<code>ThreadSafeQueue</code>本身是一个模板类，可以保存任意类型的值。程序模拟的是100个客户端向<code>safeQueue</code>添加100个介于1 - 6之间的随机数(第78行)的同时，另外100个客户端从<code>safeQueue</code>中删除这100个数字。程序会显示使用的线程的编号和id。</p>
<p><img src="content/Pattrns/Concurrent-Architecture/../../../images/Patterns/Concurrent-Architecture/5.png" alt="" /></p>
<blockquote>
<p>奇异递归模板模式(CRTP)</p>
<p>奇异递归模板模式，简单地说，CRTP代表C++中的一种习惯用法，在这种用法中，Derived类派生自类模板Base，因此Base作为Derived模板参数。</p>
<pre><code class="language-c++">template&lt;class T&gt;
class Base{
  ....
};

class Derived : public Base&lt;Derived&gt;{
	....
};
</code></pre>
<p>理解CRTP习惯用法的关键是，实例化方法是惰性的，只有在需要时才实例化方法。CRTP有两个主要的用例。</p>
<ul>
<li>静态多态性：静态多态性与动态多态性类似，但与使用虚方法的动态多态性相反，方法调用的分派在编译时进行。</li>
<li>Mixin: Mixin是设计混合代码类时的一个流行概念。<code>ThreadSafeQueue</code>使用Mixin技术来扩展它的接口。通过从<code>Monitor</code>类派生<code>ThreadSafeQueue</code>，派生类<code>ThreadSafeQueue</code>获得类<code>Monitor</code>的所有方法：<code>ThreadSafeQueue: public Monitor&lt;threadsafequeue&lt;T&gt;&gt;</code>类。</li>
</ul>
<p><a href="https://www.modernescpp.com/index.php/c-is-still-lazy">惰性C++：CRTP</a>一文中，有对CRTP习语有更深入地描述。</p>
</blockquote>
<p>活动对象和监控对象在几个重要的方面类似，但也有不同。这两种体系结构模式，会同步对共享对象的访问。活动对象的方法在不同线程中执行，而监控对象的方法则在同一线程中执行。活动对象更好地将其方法调用与执行解耦，因此更容易维护。</p>
<h2 id="扩展阅读"><a class="header" href="#扩展阅读">扩展阅读</a></h2>
<ul>
<li><a href="https://www.dre.vanderbilt.edu/%7Eschmidt/POSA/POSA2/">Pattern-Oriented Software Architecture: Patterns for Concurrent and Networked Objects</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="半同步半异步"><a class="header" href="#半同步半异步">半同步/半异步</a></h1>
<p>半同步/半异步模式会对并发系统中异步和同步服务进行解耦，从而在不过度降低性能的情况下简化编程。该模式引入了两个可以相互通信的层，一个用于异步，另一个用于同步。</p>
<p><img src="content/Pattrns/Concurrent-Architecture/../../../images/Patterns/Concurrent-Architecture/6.png" alt="" /></p>
<p>半同步/半异步模式通常用于服务器的事件循环或图形界面。事件循环的工作流是将事件请求插入队，并在单独的线程中同步处理。异步处理确保了运行效率，而同步处理简化了申请流程。异步服务层和同步服务层分解为两个层，并且在这两个层之间有队列坐标。异步层由较底层的系统服务(如中断)组成，而同步层由较高层的服务(如数据库查询或文件操作)组成。异步层和同步层可以通过队列层相互通信。</p>
<h2 id="优点和缺点-2"><a class="header" href="#优点和缺点-2">优点和缺点</a></h2>
<p>半同步/半异步模式的优点和缺点是什么?</p>
<ul>
<li>优点:
<ul>
<li>异步和同步分界线很明确。底层系统服务在异步层中处理，高层服务在同步层中处理。</li>
<li>对请求队列处理的层，保证了异步层和同步层的解耦。</li>
<li>清晰的分离使软件更容易理解、调试、维护和扩展。</li>
<li>同步服务中的阻塞不会影响异步服务。</li>
</ul>
</li>
<li>缺点:
<ul>
<li>异步层和同步层之间交叉的部分可能会导致开销。通常，因为异步服务通常在内核空间中运行，同步服务在用户空间中运行，所以“边界的部分”会涉及内核空间和用户空间之间的上下文切换。</li>
<li>为了严格分离各层，要求复制数据或数据是不可变的</li>
</ul>
</li>
</ul>
<p>半同步/半异步模式通常用于事件的多路分解和调度框架，如Reactor或Proactor模式。</p>
<h2 id="reactor模式"><a class="header" href="#reactor模式">Reactor模式</a></h2>
<p>Reactor模式也称为调度程序或通知程序。该模式是一个事件驱动的框架，用于将多个服务请求并发地分发到各个服务端。</p>
<p><strong>使用要求</strong></p>
<p>服务器应该并发地处理客户端的请求。每个客户端的请求都有一个唯一标识符，并支持映射到特定的服务端。以下几点是Reactor必备的：</p>
<ul>
<li>不阻塞。</li>
<li>支持最大吞吐量，避免不必要的上下文切换，避免数据的复制或同步。</li>
<li>易于扩展，以支持服务的修改。</li>
<li>不使用复杂的同步机制。</li>
</ul>
<p><strong>解决方案</strong></p>
<p>对于支持的服务类型，实现一个事件处理程序来满足特定客户端的请求。反应器中使用注册的方式，将服务端的事件处理程序进行注册，这里使用了事件解复用器来同步等待所有传入的事件。当一个事件到达时，反应器得到通知，并将相应的事件分派给特定的服务。</p>
<p><strong>组件</strong></p>
<p><img src="content/Pattrns/Concurrent-Architecture/../../../images/Patterns/Concurrent-Architecture/7.png" alt="" /></p>
<ul>
<li>句柄:
<ul>
<li>句柄标识了事件源，如网络连接、打开文件或GUI事件。</li>
<li>事件源生成连接、读或写等事件，这些事件会在句柄上进行排队。</li>
</ul>
</li>
<li>同步事件多路分解器:</li>
<li>同步事件多路分解器会等待一个或多个事件。多路分解器会进行阻塞，直到关联的句柄能够处理该事件为止。</li>
<li>事件处理接口:
<ul>
<li>事件处理程序定义了处理特定事件的接口。</li>
<li>事件处理程序定义了应用程序支持的服务。</li>
</ul>
</li>
<li>特定事件处理程序：
<ul>
<li>特定的事件处理实现，由事件处理接口确定。</li>
</ul>
</li>
<li>反应器:
<ul>
<li>反应器支持接口注册和注销。</li>
<li>反应器使用同步事件多路分解器，例如系统调用<a href="https://en.wikipedia.org/wiki/Select_(Unix)">select</a>, <a href="https://en.wikipedia.org/wiki/Epoll">epoll</a>或<a href="https://docs.microsoft.com/en-us/windows/desktop/api/synchapi/nf-synchapi-waitformultipleobjects">WaitForMultipleObjects</a>来等待特定事件。</li>
<li>反应器将事件映射到具体处理程序上。</li>
<li>反应器会对事件循环的生命周期进行管理。</li>
</ul>
</li>
</ul>
<p>反应器(而不是应用程序)等待特定事件，并进行分解和分派。具体的事件处理在反应器中注册，反应器改变了控制流程。反应器等待特定事件，并调用特定的处理程序。这种控制的倒置，称为<a href="https://en.wikipedia.org/wiki/Inversion_of_control">好莱坞原则</a>。(译者注：“不要给<a href="https://baike.baidu.com/item/%E6%88%91%E4%BB%AC/2751">我们</a>打电话，我们会给你打电话(don‘t call us, we‘ll call you)”这是著名的好莱坞原则。)</p>
<p>下面的代码段显示了C++框架的事件循环——<a href="https://www.dre.vanderbilt.edu/%7Eschmidt/ACE.html">自适应通信环境(ACE)</a>。</p>
<pre><code class="language-c++">// CTRL c
SignalHandler *mutateTimer1 = new SignalHandler(timerId1);

// CTRL z
SignalHandler *mutateTimer2 = new SignalHandler(timerId2);

ACE_Reactor::instance()-&gt;register_handler(SIGINT, mutateTimer1);
ACE_Reactor::instance()-&gt;register_handler(SIGTSTP, mutateTimer2);


// &quot;run&quot; the timer.
Timer::instance()-&gt;wait_fot_event();
</code></pre>
<p>第2行和第5行定义按CTRL+c和CTRL+z的键盘事件的信号处理程序。第7行和第8行记录它们，事件循环从第12行开始。</p>
<p><strong>优点和缺点</strong></p>
<p>反应器模式的优点和缺点是什么呢?</p>
<ul>
<li>优点:
<ul>
<li>框架和应用逻辑解耦。</li>
<li>各种具体处理程序的模块化。</li>
<li>接口和实现的分离，使服务更容易适应或扩展。</li>
<li>整体结构支持并发。</li>
</ul>
</li>
<li>缺点:
<ul>
<li>需要调用事件分解系统。</li>
<li>长时间运行的程序会阻塞反应器。</li>
<li>反转控制使得测试和调试更加困难。</li>
</ul>
</li>
</ul>
<p>半同步/半异步模式通常在反应器模式中，用于在独立线程中对客户端请求的响应。</p>
<p>Proactor模式是反应器模式的异步变体。反应器模式同步地分解和分派事件处理程序，而Proactor模式异步地分派事件处理程序。</p>
<h2 id="proactor模式"><a class="header" href="#proactor模式">Proactor模式</a></h2>
<p>Proactor模式允许事件驱动的应用程序，对异步操作完成时触发的服务请求进行多路的分解和分派。</p>
<p><strong>使用要求</strong></p>
<p>事件驱动程序(如服务器)，其性能可以通过异步处理服务来提高。为了实现这种方式，事件驱动程序必须同步处理多个事件，从而避免昂贵的数据同步或上下文切换。此外，修改后的服务应该很容易集成入系统，应用程序应该避免对多线程和同步方式进行挑战。</p>
<p><strong>解决方案</strong></p>
<p>将服务分为两部分：异步运行的长时间操作和处理操作结果的程序。结果处理程序与反应器模式中的事件处理程序非常相似，不过异步操作通常是操作系统的工作。所以，作为反应器模式，Proactor模式定义了事件循环。</p>
<p>异步操作(如连接请求)是该模式的独特之处，并且在不阻塞调用线程的情况下执行操作。当耗时相当长的操作完成时，它将一个完成事件放入完成事件队列，Proactor通过使用异步事件多路分解器在队列上等待。异步事件多路分解器将从队列中删除完成事件，而Proactor将其分派给特定的处理程序，处理操作的结果。</p>
<p><strong>组件</strong></p>
<p>Proactor模式由九个组件组成。</p>
<p><img src="content/Pattrns/Concurrent-Architecture/../../../images/Patterns/Concurrent-Architecture/8.png" alt="" /></p>
<ul>
<li>句柄:
<ul>
<li>表示操作系统的实体(如套接字)，可以生成完成事件。</li>
</ul>
</li>
<li>异步操作:
<ul>
<li>通常异步执行耗时相当长的操作。可以在套接字上进行读或写操作。</li>
</ul>
</li>
<li>异步操作处理器:
<ul>
<li>执行异步操作，完成后在完成事件队列上注册完成事件。</li>
</ul>
</li>
<li>完成事件接口:</li>
<li>定义处理异步操作结果的接口。</li>
<li>完成事件处理逻辑:
<ul>
<li>用特定的程序处理异步操作的结果。</li>
</ul>
</li>
<li>完成事件队列:
<ul>
<li>作为完成事件的缓冲，直到被异步事件分解器移出队列。</li>
</ul>
</li>
<li>异步事件多路分解器:
<ul>
<li>在完成事件队列上等待完成事件时，可以阻塞程序。</li>
<li>从完成事件队列中删除完成事件。</li>
</ul>
</li>
<li>Proactor:
<ul>
<li>调用异步事件分解器对完成事件进行脱队操作。</li>
<li>分解和分派完成事件，并调用特定的处理程序处理完成事件。</li>
</ul>
</li>
<li>创建者:</li>
<li>调用异步操作。</li>
<li>可与异步操作处理器进行交互。</li>
</ul>
<p><strong>优点和缺点</strong></p>
<p>Proactor模式的优点和缺点是什么呢?</p>
<ul>
<li>优点:
<ul>
<li>应用程序将独立的异步功能进行功能性分离。</li>
<li>Proactor的接口可用于支持不同操作系统上的多种异步事件分解器。</li>
<li>应用程序不需要启动新线程，因为耗时相当长的异步操作会在调用者的线程中运行。</li>
<li>Proactor模式可以避免上下文的切换。</li>
<li>应用程序的逻辑部分不启动任何线程，因此不需要同步。</li>
</ul>
</li>
<li>缺点:
<ul>
<li>为了高效地应用Proactor模式，操作系统需要支持异步操作。</li>
<li>由于操作启动和完成之间在时间和空间上的分离，调试或测试程序相当困难。</li>
<li>异步操作的调用和完成事件的维护需要额外的内存。</li>
</ul>
</li>
</ul>
<blockquote>
<p><strong>Asio，即「异步 IO」(Asynchronous Input/Output)</strong></p>
<p>随着<a href="https://www.boost.org/doc/libs/1_69_0/doc/html/boost_asio.html">Boost.Asio</a>库可能作为网络库成为C++23的一部分，在未来大家可以在C++中轻易实现Proactor模式了。Boost.Asio是由Christopher Kohlhoff的提供，是“一个用于网络和低级I/O编程的跨平台C++库，并使用现代C++为其他开发者提供了一致性异步模型”。</p>
</blockquote>
<h2 id="扩展阅读-1"><a class="header" href="#扩展阅读-1">扩展阅读</a></h2>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Adaptive_Communication_Environment">Adaptive Communication Environment (ACE)</a></li>
<li><a href="https://www.boost.org/doc/libs/1_69_0/doc/html/boost_asio.html">Boost.Asio</a></li>
<li><a href="https://www.dre.vanderbilt.edu/%7Eschmidt/POSA/POSA2/">Pattern-Oriented Software Architecture: Patterns for Concurrent and Networked Objects</a></li>
<li><a href="https://segmentfault.com/a/1190000007225464">基于 Asio 的 C++ 网络编程</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="最佳实践-1"><a class="header" href="#最佳实践-1">最佳实践</a></h1>
<p>本章提供了一组简单的规则，可用于在现代C++中编写良好且快速的并发程序。多线程的并行性和并发性，在C++中算是个比较新的主题，在未来将发现越来越多的最佳实践方式。规则会随着时间推移而发展，所以不要把本章的规则看作一个完整的列表，而是作为一个起点，对于并行STL尤其如此。在更新这本书的时候(2018年12月)，C++17的并行算法只是部分可用，所以现在为它定制最佳实践还为时过早。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="通常情况"><a class="header" href="#通常情况">通常情况</a></h1>
<p>我们先从一些原子操作和线程操作的最佳实践开始。</p>
<h2 id="代码评审"><a class="header" href="#代码评审">代码评审</a></h2>
<p>代码评审应该是专业软件开发过程必备的一部分，尤其是处理并发。并发性本质上非常复杂，需要深思熟虑的分析和经验。</p>
<p>为了使评审更有效，请在评审之前将想要讨论的代码发送给评审人员，并声明代码中哪些地方是不可变的。正式评审开始之前，应该给予评审员足够的时间来分析代码。</p>
<p>不知道怎么做?举个例子。还记得<code>std::shared_lock</code>一章readerWriterLock.cpp中的数据竞争吗?</p>
<pre><code class="language-c++">// readerWriterLock.cpp

#include &lt;iostream&gt;
#include &lt;map&gt;
#include &lt;shared_mutex&gt;
#include &lt;string&gt;
#include &lt;thread&gt;

std::map&lt;std::string, int&gt; teleBook{ {&quot;Dijkstra&quot;, 1972}, {&quot;Scott&quot;, 1976},
                                                          {&quot;Ritchie&quot;, 1983} };

std::shared_timed_mutex teleBookMutex;

void addToTeleBook(const std::string&amp; na, int tele) {
  std::lock_guard&lt;std::shared_timed_mutex&gt; writerLock(teleBookMutex);
  std::cout &lt;&lt; &quot;\nSTARTING UPDATE &quot; &lt;&lt; na;
  std::this_thread::sleep_for(std::chrono::milliseconds(500));
  teleBook[na] = tele;
  std::cout &lt;&lt; &quot; ... ENDING UPDATE &quot; &lt;&lt; na &lt;&lt; std::endl;
}

void printNumber(const std::string&amp; na) {
  std::shared_lock&lt;std::shared_timed_mutex&gt; readerLock(teleBookMutex);
  std::cout &lt;&lt; na &lt;&lt; &quot;: &quot; &lt;&lt; teleBook[na];
}

int main() {

  std::cout &lt;&lt; std::endl;

  std::thread reader1([] {printNumber(&quot;Scott&quot;); });
  std::thread reader2([] {printNumber(&quot;Ritchie&quot;); });
  std::thread w1([] {addToTeleBook(&quot;Scott&quot;,1968); });
  std::thread reader3([] {printNumber(&quot;Dijkstra&quot;); });
  std::thread reader4([] {printNumber(&quot;Scott&quot;); });
  std::thread w2([] {addToTeleBook(&quot;Bjarne&quot;, 1965); });
  std::thread reader5([] {printNumber(&quot;Scott&quot;); });
  std::thread reader6([] {printNumber(&quot;Ritchie&quot;); });
  std::thread reader7([] {printNumber(&quot;Scott&quot;); });
  std::thread reader8([] {printNumber(&quot;Bjarne&quot;); });

  reader1.join();
  reader2.join();
  reader3.join();
  reader4.join();
  reader5.join();
  reader6.join();
  reader7.join();
  reader8.join();
  w1.join();
  w2.join();

  std::cout &lt;&lt; std::endl;

  std::cout &lt;&lt; &quot;\nThe new telephone book&quot; &lt;&lt; std::endl;
  for (auto teleIt : teleBook) {
    std::cout &lt;&lt; teleIt.first &lt;&lt; &quot;: &quot; &lt;&lt; teleIt.second &lt;&lt; std::endl;
  }

  std::cout &lt;&lt; std::endl;

}
</code></pre>
<p>问题在于第24行<code>teleBook[na]</code>，这是一个可以修改的电话簿。可以通过将读取线程<code>reader8</code>放在其他读取线程之前，来触发数据竞争。在我的C++研讨会上，这个程序作为发现数据竞争的一种练习，大约10%的参与者在5分钟内能发现数据竞争。</p>
<h2 id="尽量减少可变数据的共享"><a class="header" href="#尽量减少可变数据的共享">尽量减少可变数据的共享</a></h2>
<p>应该尽量减少可变数据的共享，原因有两个：性能和安全性。安全性主要是关于数据竞争，这里我们来详谈一下性能。</p>
<p>在计算向量和的章节中，我们做了详尽的性能研究。展示了将<code>std::vector</code>的值加起来要花费多少时间。</p>
<p>下面是单线程求和的关键部分。</p>
<pre><code class="language-c++">...
  
constexpr long long size = 100000000;

std::cout &lt;&lt; std::endl;

std::vector&lt;int&gt; randValues;
randValues.reserve(size);

// random values
std::random_device seed;std::mt19937 engine(seed());
std::uniform_int_distribution&lt;&gt; uniformDist(1, 10);

const unsigned long long sum = std::accumulate(randValues.begin(),                                   randValues.end(), 0);

...
</code></pre>
<p>然后，在四个线程上执行求和，并很天真地使用了一个共享的求和变量。</p>
<pre><code class="language-c++">...
void sumUp(unsigned long long&amp; sum, const std::vector&lt;int&gt;&amp; val,
  				  unsigned long long beg, unsigned long long end){
  for (auto it = beg; it &lt; end; ++it){
    std::lock_guard&lt;std::mutex&gt; myLock(myMutex);
    sum += val[it];
  }
}
...
</code></pre>
<p>后来，通过使用原子变量求和。</p>
<pre><code class="language-c++">...
void sumUp(std::atomic&lt;unsigned long long&gt;&amp; sum, const std::vector&lt;int&gt;&amp; val,
						unsigned long long beg, unsigned long long end){
  for (auto it = beg; it &lt; end; ++it){
  	sum.fetch_add(val[it]);
  }
}
...
</code></pre>
<p>最后，通过计算局部和，得到了性能的提升。</p>
<pre><code class="language-c++">...
void sumUp(unsigned long long&amp; sum, const std::vector&lt;int&gt;&amp; val,
						unsigned long long beg, unsigned long long end){
  unsigned long long tmpSum{};
  for (auto i = beg; i &lt; end; ++i){
  	tmpSum += val[i];
  }
  std::lock_guard&lt;std::mutex&gt; lockGuard(myMutex);
  sum += tmpSum;
}
...
</code></pre>
<p>性能数字令人印象深刻，并提供了明确的指示。求和变量共享的部分越少，从多线程中获得性能收益越高。</p>
<table><thead><tr><th align="center">单线程</th><th align="center">std::lock_guard</th><th align="center">原子变量</th><th align="center">本地求和</th></tr></thead><tbody>
<tr><td align="center">0.07 sec</td><td align="center">3.34 sec</td><td align="center">1.34 sec</td><td align="center">0.03 sec</td></tr>
</tbody></table>
<h2 id="减少等待"><a class="header" href="#减少等待">减少等待</a></h2>
<p>你可能听说过<a href="https://en.wikipedia.org/wiki/Amdahl%27s_law">阿姆达尔定律</a>。它预测了使用多个处理器可以获得的理论上的最大加速比。定律很简单，如果p是可以并发运行的代码的比例，则可以获得最大的加速$\frac{1}{1-p}$。因此，如果90%的代码可以并发运行，就可以
得到(最多)10倍的加速$\frac{1}{1-p}==\frac{1}{1-0.9}==\frac{1}{0.1}==10$。</p>
<p>反过来看，如果使用锁导致10%的代码必须串行，那么最多可以获得10倍的加速。当然，这里假设可以访问的处理资源是无限制的。</p>
<p>该图清楚地显示了Amdahl定律的曲线。</p>
<p><img src="content/Pattrns/Best-Practices/../../../images/Patterns/Best-Practices/1.png" alt="" /></p>
<p>By Daniels220 at English Wikipedia, CC BY-SA 3.0, https://commons.wikimedia.org/w/index.php?curid=6678551</p>
<p>核心的最佳数量在很大程度上取决于代码的并行部分。例如：如果有50%的并行代码，那么就可以用16个核芯可达到最高的性能，使用过多的内核会使程序运行速度变慢。如果您有95%的并行代码，那么使用2048个核芯可将性能达到峰值。</p>
<h2 id="不可变数据"><a class="header" href="#不可变数据">不可变数据</a></h2>
<p>数据竞争是指，至少两个线程同时访问一个共享变量的情况，并且至少有一个线程尝试修改该变量。数据竞争的一个必要条件是可变的共享状态，下面的图表清楚地说明了我的观点。</p>
<p><img src="content/Pattrns/Best-Practices/../../../images/Patterns/Best-Practices/2.png" alt="" /></p>
<p>如果没有不可变的数据，则不会发生数据竞争。只需确保不可变数据以线程安全的方式初始化即可。在线程安全初始化的章节中，介绍了四种方法来保证这一点，这里复述一下:</p>
<ul>
<li>线程创建前进行初始化。</li>
<li>常数表达式。</li>
<li><code>std::call_once</code>与<code>std::once_flag</code>的组合。</li>
<li>具有块作用域的静态变量。</li>
</ul>
<p>C++中创建不可变数据的两种方法：<code>const</code>和<code>constexpr</code>。<code>const</code>是一种运行时技术，而<code>constexpr</code>可保证该值在编译时初始化，因此是线程安全的。甚至自定义的类型，也可以在编译时初始化。</p>
<p><strong>自定义的类型</strong></p>
<p>对于用户定义的类型，在编译时创建实例，会有一些限制。</p>
<p><code>constexpr</code>的构造函数的限制:</p>
<ul>
<li>只能用常量表达式。</li>
<li>不能使用异常处理。</li>
<li>必须声明为默认或删除，否则函数体必须为空(C++11)。</li>
</ul>
<p>自定义的<code>constexpr</code>类型的限制：</p>
<ul>
<li>不能有虚拟基类。</li>
<li>要求每个基对象和每个非静态成员必须在构造函数的初始化列表中初始化，或者直接在类体中初始化。因此，使用的构造函数(例如基类的构造函数)必须是<code>constexpr</code>，而且必须使用常量表达式进行初始化。</li>
</ul>
<p><a href="https://en.cppreference.com/w/cpp/language/constexpr">cppreference.com</a>为<code>constexpr</code>自定义类型提供了更多的信息。为了将实践添加到理论中，我定义了<code>MyInt</code>类，<code>MyInt</code>涉及到了刚刚提到的点，还有<code>constexpr</code>方法。</p>
<pre><code class="language-c++">// userdefinedTypes.cpp

#include &lt;iostream&gt;
#include &lt;ostream&gt;

class MyInt {
public:
  constexpr MyInt() = default;
  constexpr MyInt(int fir, int sec) :myVal1(fir), myVal2(sec) {}
  MyInt(int i) {
    myVal1 = i - 2;
    myVal2 = i + 3;
  }

  constexpr int getSum() const { return myVal1 + myVal2; }

  friend std::ostream&amp; operator&lt;&lt;(std::ostream&amp; out, const MyInt&amp; myInt) {
    out &lt;&lt; &quot;(&quot; &lt;&lt; myInt.myVal1 &lt;&lt; &quot;,&quot; &lt;&lt; myInt.myVal2 &lt;&lt; &quot;)&quot;;
    return out;
  }

private:
  int myVal1 = 1998;
  int myVal2 = 2003;

};

int main() {

  std::cout &lt;&lt; std::endl;

  constexpr MyInt myIntConst1;

  constexpr int sec = 2014;
  constexpr MyInt myIntConst2(2011, sec);
  std::cout &lt;&lt; &quot;myIntConst2.getSum(): &quot; &lt;&lt; myIntConst2.getSum() &lt;&lt; std::endl;

  int arr[myIntConst2.getSum()];
  static_assert(myIntConst2.getSum() == 4025, &quot;2011 + 2014 should be 4025&quot;);

  std::cout &lt;&lt; std::endl;

}
</code></pre>
<p><code>MyInt</code>类有两个<code>constexpr</code>构造函数。一个默认构造函数(第8行)和一个接受两个参数的构造函数(第9行)。另外，该类有两个方法，但是只有<code>getSum</code>方法是常量表达式。因为<code>constexpr</code>方法在C++11和C++14是不同的，不会自动进行<code>const</code>修饰，所以方法声明为<code>const</code>。如果在<code>constexpr</code>对象中使用变量<code>myVal1</code>和<code>myVal2</code>(第23行和第24行)，有两种方法可以定义它们。首先，可以在构造函数的初始化列表中初始化它们(第9行)；其次，可以在类体中初始化它们(第23行和第24行)。这里，构造函数的初始化列表中的初始化具有更高的优先级。</p>
<p>第38行和第39行中可以在一个常量表达式中调用<code>constexpr</code>方法。下面是程序的输出。</p>
<p><img src="content/Pattrns/Best-Practices/../../../images/Patterns/Best-Practices/3.png" alt="" /></p>
<p>再次强调：<code>constexpr</code>对象只能使用<code>constexpr</code>方法初始化。</p>
<p>像Haskell这样没有可变数据的函数式编程语言，则非常适合并发编程。</p>
<h2 id="使用纯函数"><a class="header" href="#使用纯函数">使用纯函数</a></h2>
<p>Haskell被称为纯函数语言，纯函数是在给定相同参数时，总是产生相同结果的函数。它没有副作用，因此不能改变程序的状态。</p>
<p>从并发性的角度来看，纯函数具有明显的优势。它们可以重新排序，也可以在另一个线程上自动运行。</p>
<p>C++中的函数默认不是纯函数。以下三个函数都是纯函数，但每个函数都有不同的特征。</p>
<pre><code class="language-c++">int powFunc(int m, int n){
  if (n == 0) return 1;
  return m * powFunc(m, n-1);
}
</code></pre>
<p><code>powFunc</code>是一个普通函数。</p>
<pre><code class="language-c++">template&lt;int m, int n&gt;
struct PowMeta{
	static int const value = m * PowMeta&lt;m, n-1&gt;::value;
};

template&lt;int m&gt;
struct PowMeta&lt;m, 0&gt;{
  static int const value = 1;
};
</code></pre>
<p><code>PowMeta</code>是一个元函数(meta-function)，因为它在编译时运行。</p>
<pre><code class="language-c++">constexpr int powConst(int m, int n){
  int r = 1;
  for(int k = 1; k &lt;= n; ++k) r *= m;
  return r;
}
</code></pre>
<p><code>powCont</code>函数可以在运行时和编译时运行，它是一个常量函数。</p>
<h2 id="寻找正确的抽象概念"><a class="header" href="#寻找正确的抽象概念">寻找正确的抽象概念</a></h2>
<p>多线程环境中，有多种方法可以初始化单例。可以使用标准库中的<code>lock_guard</code>或<code>std::call_once</code>，或使用依赖于核心语言的静态变量，亦或是使用依赖于原子变量的获取-释放语义。显然，使用获取-释放语义最具挑战性。使用者必须执行它，维护它，还要向同事解释它。与这些工作相比，Meyers单例在更容易实现，并且运行速度更快。</p>
<p>可以使用<code>std::reduce</code>，而不是实现一个并行循环进行求和。可以使用二元操作可调用和并行执行策略，对<code>std::reduce</code>进行参数化。</p>
<p>越是追求正确的抽象，工作就会越轻松。</p>
<h2 id="使用静态代码分析工具"><a class="header" href="#使用静态代码分析工具">使用静态代码分析工具</a></h2>
<p>案例分析章节中，我介绍了CppMem。<a href="http://svr-pes20-cppmem.cl.cam.ac.uk/cppmem/">CppMem</a>是一个交互式工具，用于对小代码段的C++内存模型，进行行为研究。CppMem可以提供两个方面的帮助：首先，可以验证代码的正确性；其次，可以更深入地了解内存模型，从而更全面地了解多线程问题。</p>
<h2 id="使用动态执行工具"><a class="header" href="#使用动态执行工具">使用动态执行工具</a></h2>
<p><a href="https://github.com/google/sanitizers/wiki/ThreadSanitizerCppManual">ThreadSanitizer</a>是一个针对C/C++的数据竞争探测器。ThreadSanitizer已经作为Clang 3.2和GCC 4.8的一部分。要使用ThreadSanitizer，必须使用编译标志<code>-fsanitize=thread</code>来编译和链接你的程序。</p>
<p>下面的程序有一个数据竞争。</p>
<pre><code class="language-c++">// dataRace.cpp

#include &lt;thread&gt;

int main() {

  int globalVar{};

  std::thread t1([&amp;globalVar] { ++globalVar; });
  std::thread t2([&amp;globalVar] { ++globalVar; });

  t1.join();
  t2.join();

}
</code></pre>
<p><code>t1</code>和<code>t2</code>同时访问<code>globalVar</code>，两个线程都试图修改<code>globalVar</code>。让我们编译并运行该程序。</p>
<p><code>g++ -std=c++11 dataRace.cpp -fsanitize=thread -pthread -g -o dataRace</code></p>
<p>这个程序的输出相当冗长。</p>
<p><img src="content/Pattrns/Best-Practices/../../../images/Patterns/Best-Practices/4.png" alt="" /></p>
<p>我用红色框突出了屏幕截图的关键段，这段表示在源码第10行有一个数据竞争。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="多线程-2"><a class="header" href="#多线程-2">多线程</a></h1>
<h2 id="线程-1"><a class="header" href="#线程-1">线程</a></h2>
<p>线程是编写并发程序的基础件。</p>
<p><strong>减少线程的创建</strong></p>
<p>一个线程的开销有多大?非常巨大！这就是最佳实践背后的问题。让我们先看看线程的大小，而不是创建它的成本。</p>
<p><strong>线程大小</strong></p>
<p><code>std::thread</code>是对本机操作系统线程的包装，这意味着需要对Windows线程和<a href="https://en.wikipedia.org/wiki/POSIX_Threads">POSIX thread</a>的大小进行了解：</p>
<ul>
<li>Windows：<a href="https://msdn.microsoft.com/en-us/library/windows/desktop/ms686774(v=vs.85).aspx">线程堆栈大小</a>给了我答案：1MB。</li>
<li>POSIX：pthread手册页为我提供了i386和x86_64架构的答案：2MB。下面有支持POSIX架构的线程堆栈大小：</li>
</ul>
<p><img src="content/Pattrns/Best-Practices/../../../images/Patterns/Best-Practices/5.png" alt="" /></p>
<p><strong>创建耗时</strong></p>
<p>我不知道创建一个线程需要多少时间，所以我在Linux和Windows上做了一个简单的性能测试。</p>
<p>我在台式机上使用GCC 6.2.1，在笔记本电脑上使用cl.exe(Visual Studio 2017)进行性能测试。我用最大优化来编译程序，这意味着在Linux上的优化标志为<code>O3</code>和Windows为<code>Ox</code>。</p>
<p>下面是我的程序。</p>
<pre><code class="language-c++">// threadCreationPerformance.cpp

#include &lt;chrono&gt;
#include &lt;iostream&gt;
#include &lt;thread&gt;

static const long long numThreads = 1'000'000;

int main() {
  auto start = std::chrono::system_clock::now();

  for (volatile int i = 0; i &lt; numThreads; ++i) std::thread([] {}).detach();

  std::chrono::duration&lt;double&gt; dur = std::chrono::system_clock::now() - start;
  std::cout &lt;&lt; &quot;time: &quot; &lt;&lt; dur.count() &lt;&lt; &quot; seconds&quot; &lt;&lt; std::endl;
}
</code></pre>
<p>该程序创建了100万个线程，这些线程执行第13行中的空Lambda函数。以下是在Linux和Windows测试的结果:</p>
<p><strong>Linux</strong></p>
<p><img src="content/Pattrns/Best-Practices/../../../images/Patterns/Best-Practices/6.png" alt="" /></p>
<p>这意味着在Linux上创建一个线程大约需要14.5秒/ 1000000 = 14.5微秒。</p>
<p><strong>Windows</strong></p>
<p><img src="content/Pattrns/Best-Practices/../../../images/Patterns/Best-Practices/7.png" alt="" /></p>
<p>在Windows上创建线程大约需要44秒/ 1000000 = 44微秒。</p>
<p>换句话说，在Linux上一秒钟可创建大约69000个线程，在Windows上一秒钟可创建23000个线程。</p>
<p><strong>使用任务而不是线程</strong></p>
<pre><code class="language-c++">// asyncVersusThread.cpp

#include &lt;future&gt;
#include &lt;thread&gt;
#include &lt;iostream&gt;

int main() {

  std::cout &lt;&lt; std::endl;

  int res;
  std::thread t([&amp;] {res = 2000 + 11; });
  t.join();
  std::cout &lt;&lt; &quot;res: &quot; &lt;&lt; res &lt;&lt; std::endl;

  auto fut = std::async([] {return 2000 + 11; });
  std::cout &lt;&lt; &quot;fut.get(): &quot; &lt;&lt; fut.get() &lt;&lt; std::endl;

  std::cout &lt;&lt; std::endl;

}
</code></pre>
<p>有很多原因让我们优先选择任务而不是线程：</p>
<ul>
<li>可以使用一个安全的通信通道来返回结果。如果使用共享变量，则必须同步的对它进行访问。</li>
<li>调用者可以很容易的得到返回值、通知和异常。</li>
</ul>
<p>通过扩展版future，我们可构建future，以及高度复杂的工作流。这些工作流基于<code>continuation then</code>，以及<code>when_any</code>和<code>when_all</code>的组合。</p>
<p><strong>如果要分离线程，一定要非常小心</strong></p>
<p>下面的代码片段需要我们关注一下。</p>
<pre><code class="language-c++">std::string s{&quot;C++11&quot;}

std::thread t([&amp;s]{ std::cout &lt;&lt; s &lt;&lt; std::endl; });
t.detach();
</code></pre>
<p>线程<code>t</code>与它的创建者的生命周期是分离的，所以两个竞态条件会导致未定义行为。</p>
<ol>
<li>线程可能比其创建者的生命周期还长，结果是<code>t</code>引用了一个不存在的<code>std::string</code>。 </li>
<li>因为输出流<code>std::cout</code>的生存期与主线程的生存期绑定在一起，所以程序在线程<code>t</code>开始工作之前，输出流就可能关闭了。</li>
</ol>
<p><strong>考虑使用自动汇入的线程</strong></p>
<p>如果<code>t.join()</code>和<code>t.detach()</code>都没有调用，则具有可调用单元的线程<code>t</code>被称为可汇入的，这时进行销毁的话，析构函数会抛出<code>std::terminate</code>异常。为了不忘记<code>t.join()</code>，可以对<code>std::thread</code>进行包装。这个包装器在构造函数中检查给定线程是否仍然可连接，并将给定线程在析构函数中进行汇入操作。</p>
<p>我们不必自己构建这个包装器，可以使用Anthony Williams的scoped_thread，或是<a href="https://github.com/Microsoft/GSL">核心准则支持的库</a>的<code>gsl::joining_thread</code>。</p>
<h2 id="数据共享"><a class="header" href="#数据共享">数据共享</a></h2>
<p>随着可变数据的数据共享，也就开启了多线程编程的挑战。</p>
<p><strong>通过复制传递数据</strong></p>
<pre><code class="language-c++">std::string s{&quot;C++11&quot;}

std::thread t1([s]{ ... }); // do something with s
t1.join();

std::thread t2([&amp;s]{ ... }); // do something with s
t2.join();

// do something with s
</code></pre>
<p>如果将<code>std::string s</code>之类的数据通过复制传递给线程<code>t1</code>，则创建者线程和创建的线程<code>t1</code>使用独立的数据。线程<code>t2</code>相反，通过引用获取<code>std::string s</code>，这意味着必须同步对创建者线程和已创建线程<code>t2</code>中的<code>s</code>的访问。这里非常容易出错。</p>
<p><strong>使用<code>std::shared_ptr</code>在非关联线程之间共享所有权</strong></p>
<p>试想，有一个在非关联的线程之间共享的对象存在。接下来的问题是，对象的所有者是谁？谁负责这个对象的内存管理？现在，可以在内存泄漏(如果不释放内存)和未定义行为(因为多次调用delete)之间进行选择。大多数情况下，未定义行为会使运行时崩溃。</p>
<p>下面的程序展示了这个看似无解的问题。</p>
<pre><code class="language-c++">// threadSharesOwnership.cpp

#include &lt;iostream&gt;
#include &lt;thread&gt;

using namespace std::literals::chrono_literals;

struct MyInt {
  int val{ 2017 };
  ~MyInt() {
    std::cout &lt;&lt; &quot;Good Bye&quot; &lt;&lt; std::endl;
  }
};

void showNumber(MyInt* myInt) {
  std::cout &lt;&lt; myInt-&gt;val &lt;&lt; std::endl;
}

void threadCreator() {
  MyInt* tmpInt = new MyInt;

  std::thread t1(showNumber, tmpInt);
  std::thread t2(showNumber, tmpInt);

  t1.detach();
  t2.detach();
}

int main() {

  std::cout &lt;&lt; std::endl;

  threadCreator();
  std::this_thread::sleep_for(1s);

  std::cout &lt;&lt; std::endl;

}
</code></pre>
<p>这个例子很简单，主线程休眠1秒钟(第34行)，以确保它比子线程<code>t1</code>和<code>t2</code>的生命周期长。当然，这不是恰当的同步，但帮我阐明了观点。程序的关键是：谁负责删除第20行中的<code>tmpInt</code> ?线程<code>t1</code>(第22行)？还是线程<code>t2</code>(第23行)？或函数本身(主线程)？因为无法预测每个线程运行多长时间，所以这个程序应该会有内存泄漏。因此，第10行中的<code>MyInt</code>的析构函数永远不会被调用:</p>
<p><img src="content/Pattrns/Best-Practices/../../../images/Patterns/Best-Practices/8.png" alt="" /></p>
<p>如果使用<code>std::shared_ptr</code>，则生命周期问题就很容易处理。</p>
<p><img src="content/Pattrns/Best-Practices/../../../images/Patterns/Best-Practices/9.png" alt="" /></p>
<pre><code class="language-c++">// threadSharesOwnershipSharedPtr.cpp

#include &lt;iostream&gt;
#include &lt;memory&gt;
#include &lt;thread&gt;

using namespace std::literals::chrono_literals;

struct MyInt {
  int val{ 2017 };
  ~MyInt() {
    std::cout &lt;&lt; &quot;Good Bye&quot; &lt;&lt; std::endl;
  }
};

void showNumber(std::shared_ptr&lt;MyInt&gt; myInt) {
  std::cout &lt;&lt; myInt-&gt;val &lt;&lt; std::endl;
}

void threadCreator() {
  auto sharedPtr = std::make_shared&lt;MyInt&gt;();

  std::thread t1(showNumber, sharedPtr);
  std::thread t2(showNumber, sharedPtr);

  t1.detach();
  t2.detach();
}

int main() {

  std::cout &lt;&lt; std::endl;

  threadCreator();
  std::this_thread::sleep_for(1s);

  std::cout &lt;&lt; std::endl;

}
</code></pre>
<p>对源代码进行两个小的必要的修改：首先，第21行中的指针变成了<code>std::shared_ptr</code>，然后，第16行中的函数<code>showNumber</code>接受了一个智能指针，而不是普通指针。</p>
<p><strong>尽量减少持有锁的时间</strong>.</p>
<p>如果持有锁，那么只有单个线程可以进入临界区。</p>
<pre><code class="language-c++">void setDataReadyBad(){
  std::lock_guard&lt;std::mutex&gt; lck(mutex_);
  mySharedWork = {1, 0, 3};
  dataReady = true;
  std::cout &lt;&lt; &quot;Data prepared&quot; &lt;&lt; std::endl;
  condVar.notify_one();
} // unlock the mutex

void setDataReadyGood(){
  mySharedWork = {1, 0, 3};
  {
  	std::lock_guard&lt;std::mutex&gt; lck(mutex_);
    dataReady = true;
  } // unlock the mutex
  std::cout &lt;&lt; &quot;Data prepared&quot; &lt;&lt; std::endl;
  condVar.notify_one();
}
</code></pre>
<p>函数<code>setDataReadyBad</code>和<code>setDataReadyGood</code>是条件变量的通知组件。可变的数据是必要的，以防止伪唤醒和未唤醒的发生。由于<code>dataReady</code>是一个非原子变量，因此必须使用锁<code>lck</code>对其进行同步。为了使锁的生命周期尽可能短，可以在函数<code>setDataReadyGood</code>中使用一个范围<code>({…}) </code>。</p>
<p><strong>将互斥量放入锁中</strong></p>
<p>不应该使用没有锁的互斥量。</p>
<pre><code class="language-c++">std::mutex m;
m.lock();
// critical section
m.unlock();
</code></pre>
<p>临界区内可能会发生意外，或者忘记解锁。如果不解锁，则想要获取该互斥锁的另一个线程将被阻塞，最后程序将死锁。</p>
<p>由于锁可以自动处理底层的互斥量，因此死锁的风险大大降低了。根据RAII习惯用法，锁在构造函数中自动绑定互斥量，并在析构函数中释放互斥量。</p>
<pre><code class="language-c++">{
  std::mutex m,
  std::lock_guard&lt;std::mutex&gt; lockGuard(m);
  // critical section
} // unlock the mutex
</code></pre>
<p><code>({…})</code>范围确保锁的生命周期自动结束，所以底层的互斥量会被解锁。</p>
<p><strong>最多锁定一个互斥锁</strong></p>
<p>有时在某个时间点需要多个互斥锁，这种情况下，可能会引发死锁的竞态条件。因此，可能的话，应该尽量避免同时持有多个互斥锁。</p>
<p><strong>给锁起个名字</strong></p>
<p>如果使用没有名称的锁，比如<code>std::lock_guard</code>，那么将立即销毁。</p>
<pre><code class="language-c++">{
  std::mutex m,
  std::lock_guard&lt;std::mutex&gt;{m};
  // critical section
}
</code></pre>
<p>这个看起来无害的代码片段中，<code>std::lock_guard</code>立即被销毁。因此，下面的临界区是不同步执行的。C++标准的锁遵循所有相同的模式，会在构造函数中锁定互斥锁，并在析构函数中解锁，这种模式称为RAII。</p>
<p>下面例子的行为令人惊讶:</p>
<pre><code class="language-c++">// myGuard.cpp

#include &lt;mutex&gt;
#include &lt;iostream&gt;

template &lt;typename T&gt;
class MyGuard {
  T&amp; myMutex;
public:
  MyGuard(T&amp; m) :myMutex(m) {
    myMutex.lock();
    std::cout &lt;&lt; &quot;lock&quot; &lt;&lt; std::endl;
  }
  ~MyGuard() {
    myMutex.unlock();
    std::cout &lt;&lt; &quot;unlock&quot; &lt;&lt; std::endl;
  }
};

int main() {

  std::cout &lt;&lt; std::endl;

  std::mutex m;
  MyGuard&lt;std::mutex&gt; {m};
  std::cout &lt;&lt; &quot;CRITICAL SECTION&quot; &lt;&lt; std::endl;

  std::cout &lt;&lt; std::endl;

}
</code></pre>
<p><code>MyGuard</code>在其构造函数和析构函数中调用<code>lock</code>和<code>unlock</code>。由于临时变量的原因，对构造函数和析构函数的调用发生在第25行。特别是，这意味着析构函数的调用发生在第25行，而不是第31行。因此，第26行中的临界段没有同步执行。</p>
<p>这个程序的截图显示了，解锁的发生在输出CRITICAL SECTION之前。</p>
<p><img src="content/Pattrns/Best-Practices/../../../images/Patterns/Best-Practices/10.png" alt="" /></p>
<p><strong>使用std::lock或std::scoped_lock原子地锁定更多的互斥对象</strong></p>
<p>如果一个线程需要多个互斥对象，那么必须非常小心地将互斥对象以相同的顺序进行锁定。如果不这样，一个糟糕的线程交叉就可能导致死锁。</p>
<pre><code class="language-c++">void deadLock(CriticalData&amp; a, CriticalData&amp; b){
  std::lock_guard&lt;std::mutex&gt; guard1(a.mut);
  // some time passes
  std::lock_guard&lt;std::mutex&gt; guard2(b.mut);
  // do something with a and b
}

...
  
std::thread t1([&amp;]{deadLock(c1,c2);});
std::thread t2([&amp;]{deadLock(c2,c1);});

...
  
</code></pre>
<p>线程<code>t1</code>和<code>t2</code>需要两个<code>CriticalData</code>，而<code>CriticalData</code>用自己的<code>mut</code>来控制同步访问。不幸的是，因为这两个调用参数<code>c1</code>和<code>c2</code>的顺序不同，所以产生了一个竞态，从而会导致死锁。当线程<code>t1</code>可以锁定第一个互斥对象<code>a.mut</code>，而没锁住第二个<code>b.mut </code>，这样线程<code>t2</code>锁住了第二个线程，而阻塞等待<code>a.mut</code>解锁，就会产生出一个死锁的状态。</p>
<p>现在有了<code>std::unique_lock</code>，可以对互斥锁进行延迟锁定。函数<code>std::lock</code>可以原子地对任意数量的互斥锁进行锁定。</p>
<pre><code class="language-c++">void deadLock(CriticalData&amp; a, CriticalData&amp; b){
  unique_lock&lt;mutex&gt; guard1(a.mut,defer_lock);
  // some time passes
  unique_lock&lt;mutex&gt; guard2(b.mut,defer_lock);
  std::lock(guard1,guard2);
  // do something with a and b
}

...
  
std::thread t1([&amp;]{deadLock(c1,c2);});
std::thread t2([&amp;]{deadLock(c2,c1);});

...
  
</code></pre>
<p>C++17有一个新锁<code>std::scoped_lock</code>，它可以获得任意数量的互斥锁并自动锁定它们。这样，工作流变得更加简单了：</p>
<pre><code class="language-c++">void deadLock(CriticalData&amp; a, CriticalData&amp; b){
  std::scoped_lock(a.mut, b.mut);
  // do something with a and b
}

...
  
std::thread t1([&amp;]{deadLock(c1,c2);});
std::thread t2([&amp;]{deadLock(c2,c1);});

...
</code></pre>
<p><strong>不要在持有锁时，调用未知代码</strong></p>
<p>在持有互斥锁的同时，调用<code>unknownFunction</code>会导致未定义行为。</p>
<pre><code class="language-c++">std::mutex m;
{
  std::lock_guard&lt;std::mutex&gt; lockGuard(m);
  sharedVariable= unknownFunction();
}
</code></pre>
<p>我只能对<code>unknownFunction</code>进行推测数。如果<code>unknownFunction</code>：</p>
<ul>
<li>试图锁定互斥量<code>m</code>，这就是未定义行为。大多数情况下，会出现死锁。</li>
<li>启动一个试图锁定互斥锁<code>m</code>的新线程，就会出现死锁。</li>
<li>锁定另一个互斥锁<code>m2</code>可能会陷入死锁，因为需要同时锁定了两个互斥锁<code>m</code>和<code>m2</code>。</li>
<li>不要直接或间接尝试锁住互斥锁，虽然一切可能都没什么问题。“可能”是因为你的同事，可以修改函数或函数是动态链接的，这样就会得到一个与已知版本不同的函数。对于可能发生的事情，所有一切都是可能的。</li>
<li>可能会出现性能问题，因为不知道<code>unknownFunction</code>函数需要多长时间。</li>
</ul>
<p>要解决这些问题，请使用局部变量。</p>
<pre><code class="language-c++">auto tempVar = unknownFunction();
std::mutex m,
{
  std::lock_guard&lt;std::mutex&gt; lockGuard(m);
  sharedVariable = tempVar;
}
</code></pre>
<p>这种方式解决了所有的问题。<code>tempVar</code>是一个局部变量，因此不会成为数据竞争的受害者，所以可以在没有同步机制的情况下调用<code>unknownFunction</code>。此外，将<code>tempVar</code>的值赋给<code>sharedVariable</code>，可以将持有锁的时间降到最低。</p>
<h2 id="条件变量-2"><a class="header" href="#条件变量-2">条件变量</a></h2>
<p>通过通知同步线程是一个简单的概念，但是条件变量使这个任务变得非常具有挑战性。主要原因是条件变量没有状态：</p>
<ul>
<li>如果条件变量得到了通知，则可能是错误的(伪唤醒)。</li>
<li>如果条件变量在准备就绪之前得到通知，则通知丢失(未唤醒)。</li>
</ul>
<p><strong>不要使用没有谓词的条件变量</strong></p>
<p>使用没有谓词的条件变量，通常是竞争条件之一。</p>
<pre><code class="language-c++">// conditionVariableLostWakeup.cpp

#include &lt;condition_variable&gt;
#include &lt;mutex&gt;
#include &lt;thread&gt;

std::mutex mutex_;
std::condition_variable condVar;

void waitingForWork() {
  std::unique_lock&lt;std::mutex&gt; lck(mutex_);
  condVar.wait(lck);
  // do the work
}

void setDataReady() {
  condVar.notify_one();
}

int main() {

  std::thread t1(setDataReady);
  std::thread t2(waitingForWork);

  t1.join();
  t2.join();

}
</code></pre>
<p>如果线程<code>t1</code>在线程<code>t2</code>之前运行，就会出现死锁。<code>t1</code>在<code>t2</code>接收之前发送通知，通知就会丢失。这种情况经常发生，因为线程<code>t1</code>在线程<code>t2</code>之前启动，而线程<code>t1</code>需要执行的工作更少。</p>
<p>在工作流中添加一个布尔变量<code>dataReady</code>可以解决这个问题。<code>dataReady</code>还可以防止伪唤醒，因为等待的线程会检查通知是否来自于正确的线程。</p>
<pre><code class="language-c++">// conditionVarialbleLostWakeupSolved.cpp

#include &lt;condition_variable&gt;
#include &lt;mutex&gt;
#include &lt;thread&gt;

std::mutex mutex_;
std::condition_variable condVar;

bool dataReady{ false };

void waitingForWork() {
  std::unique_lock&lt;std::mutex&gt; lck(mutex_);
  condVar.wait(lck, [] { return dataReady; });
  // do the work
}

void setDataReady() {
  {
    std::lock_guard&lt;std::mutex&gt; lck(mutex_);
    dataReady = true;
  }
  condVar.notify_one();
}

int main() {

  std::thread t1(setDataReady);
  std::thread t2(waitingForWork);

  t1.join();
  t2.join();

}
</code></pre>
<p><strong>使用Promise和Future代替条件变量</strong></p>
<p>对于一次性通知，promise和future则是更好的选择。conditioVarialbleLostWakeupSolved.cpp的工作流程，可以使用promise和future直接实现。</p>
<pre><code class="language-c++">// notificationWithPromiseAndFuture.cpp

#include &lt;future&gt;
#include &lt;utility&gt;

void waitingForWork(std::future&lt;void&gt;&amp;&amp; fut) {
  fut.wait();
  // do the work
}

void setDataReady(std::promise&lt;void&gt;&amp;&amp; prom) {
  prom.set_value();
}

int main() {

  std::promise&lt;void&gt; sendReady;
  auto fut = sendReady.get_future();

  std::thread t1(waitingForWork, std::move(fut));
  std::thread t2(setDataReady, std::move(sendReady));

  t1.join();
  t2.join();

}
</code></pre>
<p>工作流程被简化到极致。promise<code>prom.set_value()</code>会发送future<code>fut.wait()</code>正在等待的通知。因为没有临界区，程序不需要互斥量和锁。因为不可能发生丢失唤醒或虚假唤醒，所以有没有谓词也没有关系。</p>
<p>如果工作流要求多次使用条件变量，那么promise和future就是不二之选。</p>
<h2 id="promise和future"><a class="header" href="#promise和future">Promise和Future</a></h2>
<p>promise和future常被用作线程或条件变量的替代物。</p>
<p><strong>尽可能使用std::async</strong></p>
<p>如果可能，应该使用<code>std::async</code>来执行异步任务。</p>
<pre><code class="language-c++">auto fut = std::async([]{ return 2000 + 11; });
// some time passes
std::cout &lt;&lt; &quot;fut.get(): &quot; &lt;&lt; fut.get() &lt;&lt; std::endl;
</code></pre>
<p>通过调用<code>auto fut = std::async([]{ return 2000 + 11; })</code>，相当于对C++运行时说：“运行这个”。调用者不关心它是否立即执行，以及是运行在同一个线程上，还有是运行在线程池上，或是运行在<a href="https://en.wikipedia.org/wiki/Graphics_processing_unit">GPU</a>上。调用者只对future的结果感兴趣：<code>fut.get()</code>。</p>
<p>从概念上看，线程只是运行作业的实现细节。对于线程而言，使用者应该只指定做什么，而不应该指定如何做。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="内存模型-2"><a class="header" href="#内存模型-2">内存模型</a></h1>
<p>多线程的基础是定义良好的内存模型。对内存有基本的了解，有助于更深入地了解多线程的挑战。</p>
<h2 id="不要使用volatile进行同步"><a class="header" href="#不要使用volatile进行同步">不要使用volatile进行同步</a></h2>
<p>C++与C#或Java相比，<code>volatile</code>关键字没有多线程语义。在C#或Java中，<code>volatile</code>声明了一个原子变量，如<code>std::atomic</code>在C++中声明了一个原子一样，通常用于可以进行更改的对象。由于这一特性，没有优化的存储会发生在缓存中。</p>
<h2 id="不要让程序无锁"><a class="header" href="#不要让程序无锁">不要让程序无锁</a></h2>
<p>这个建议听起来很荒谬，但是这个建议的理由很简单，无锁编程非常容易出错，并且需要在这个领域是专家级别的人，才能保证很少出错。如果需要实现无锁的数据结构，请务必注意ABA问题。</p>
<h2 id="如果使用无锁程序请使用成熟的模式"><a class="header" href="#如果使用无锁程序请使用成熟的模式">如果使用无锁程序，请使用成熟的模式</a></h2>
<p>如果已经确定要使用无锁方案，那么请使用成熟的模式。</p>
<ol>
<li>简单的共享原子布尔值或原子计数器。</li>
<li>使用线程安全，甚至无锁的容器来支持消费者/生产者的场景。如果使用的容器是线程安全的，则可以将值放入容器中或从容器中取出，而不必担心同步的问题。这就将应用程序的挑战转移到基础设施中。</li>
</ol>
<h2 id="不要构建自定义的抽象方式尽量使用当前语言能够保证的方式"><a class="header" href="#不要构建自定义的抽象方式尽量使用当前语言能够保证的方式">不要构建自定义的抽象方式，尽量使用当前语言能够保证的方式</a></h2>
<p>共享变量的线程安全初始化，可以通过多种方式完成。可以依赖于C++运行时的保证，比如：常量表达式、带有块作用域的静态变量，或者使用函数<code>std::call_once</code>与<code>std::once_flag</code>组合使用。这里用C++编程，即使使用非常复杂的获取-发布语义，也可以构建基于原子的抽象。一开始最好不要这样做，除非不得已。这意味着，通过度量关键代码的性能来确定瓶颈时，只有当明确自定义版本比当前语言默认的方式性能更好时，再进行更改。</p>
<h2 id="不要重新发明轮子"><a class="header" href="#不要重新发明轮子">不要重新发明轮子</a></h2>
<p>编写线程安全的数据结构是一项颇具挑战性的工作，这要比编写无锁的数据结构更困难。因此，最好使用现成的库，如<a href="http://www.boost.org/doc/libs/1_66_0/doc/html/lockfree.html">Boost.Lockfree</a>或<a href="http://http://libcds.sourceforge.net/">CDS</a>.</p>
<p><strong>Boost.Lockfree</strong></p>
<p>Boost.Lockfree支持三种不同的数据结构:</p>
<p>Queue：无锁的多生产/多消费者队列</p>
<p>Stack：无锁的多产品/多消费者堆栈</p>
<p>spsc_queue：无等待的单生产者/单消费者队列(通常称为环形缓冲区)</p>
<p><strong>CDS</strong></p>
<p>CDS代表并发数据结构，包含许多侵入式(非拥有)和非侵入式(拥有)容器。因为它们会自动管理元素，所以标准模板库的容器是非侵入的。</p>
<ul>
<li>堆栈(无锁)</li>
<li>队列和带优先级的队列 (无锁)</li>
<li>有序列表</li>
<li>有序的set和map(无锁和有锁)</li>
<li>无序的set和map(无锁和有锁 )</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><p>#有锁结构</p>
<div style="break-before: page; page-break-before: always;"></div><p>#无锁结构</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="挑战-1"><a class="header" href="#挑战-1">挑战</a></h1>
<p>编写并发程序本身就很复杂，即便是使用C++11和C++14的新特性，也是如此。我希望通过用一整章的内容来讨论并发编程的挑战，读者们会更清楚其中的陷阱与挑战。</p>
<h2 id="aba问题"><a class="header" href="#aba问题">ABA问题</a></h2>
<p>ABA表示读取了一个值两次，每次都返回A值。因此，可以得出这样的结论：两次读取之间，相应的变量没有任何变化。然而，在两次读取之间，变量可能有被更新为B的时刻。</p>
<p>用一个简单的场景来比拟这个问题。</p>
<p><strong>一个例子</strong></p>
<p>这个场景里，你坐在车里等待交通灯变绿，绿色代表B，红色代表A。接下来会发生了什么?</p>
<ol>
<li>你看到交通灯，它是红色的(A)。</li>
<li>因为很无聊，你打开手机看新闻，而忘记了时间。</li>
<li>当你再看一次交通灯时。该死！还是红色(A)。</li>
</ol>
<p>当然，交通灯在你两次抬头看之间已经变成绿灯过。对于线程(进程)来说，意味着什么?</p>
<ol>
<li>线程1读取值为A的变量<code>var</code>。</li>
<li>线程1被抢占，线程2运行。</li>
<li>线程2将变量<code>var</code>从A更改为B，再更改为A。</li>
<li>线程1继续运行并检查变量<code>var</code>的值并得到A。因为获取到值A，线程1继续运行。</li>
</ol>
<p>通常这不是一个问题，可以忽略。</p>
<p><strong>非关键的ABA</strong></p>
<pre><code class="language-c++">// fetch_mult.cpp

#include &lt;atomic&gt;
#include &lt;iostream&gt;

template &lt;typename T&gt;
T fetch_mult(std::atomic&lt;T&gt;&amp; shared, T mult) {
  T oldValue = shared.load();
  while (!shared.compare_exchange_strong(oldValue, oldValue * mult));
  return oldValue;
}

int main() {
  std::atomic&lt;int&gt; myInt{ 5 };
  std::cout &lt;&lt; myInt &lt;&lt; std::endl;
  fetch_mult(myInt, 5);
  std::cout &lt;&lt; myInt &lt;&lt; std::endl;
}
</code></pre>
<p><code>compare_exchange_strong</code>和<code>compare_exchange_weak</code>可以在<code>fetch_mult</code>(第6行)中观察到的ABA问题。<code>fetch_mult</code>将<code>std::atomic&lt;t&gt;&amp; shared</code>和<code>mult</code>相乘。</p>
<p>关键是，读取旧值<code>T oldValue = shared.load()</code>第8行和第9行中的新值比较之间有一个小的时间窗口。因此，另一个线程可以介入，将<code>oldValue</code>从更改为另一个值，然后再返回<code>oldValue</code>。旧值是A，另一个线程修改的值是ABA中的B。</p>
<p>通常，当读操作处理相同的、未更改的变量，则没有什么影响。但是，在无锁并发的数据结构中，ABA可能会产生重大影响。</p>
<p><strong>无锁数据结构</strong></p>
<p>这里不会详细介绍无锁数据结构，仅用单链表实现的无锁堆栈，堆栈只支持两个操作：</p>
<ol>
<li>pop：弹出顶部对象，并返回指向它的指针。</li>
<li>push：将指定的对象推入堆栈。</li>
</ol>
<p>这里使用伪代码描述pop操作，以便了解ABA问题。pop操作执行以下步骤：</p>
<ol>
<li>获取头节点:head</li>
<li>获取后续节点:headNext</li>
<li>如果head仍然是堆栈的头节点，则将headNext作为新的头结点。</li>
</ol>
<p>下面是堆栈的前两个节点:</p>
<p><code>Stack: TOP -&gt; head -&gt; headNext -&gt; ...</code></p>
<p>现在，来构造ABA问题的情景。</p>
<p><strong>构造ABA</strong></p>
<p>我们从下面的堆栈开始:</p>
<p><code>Stack: TOP -&gt; A -&gt; B -&gt; C</code></p>
<p>线程1处于活动状态，希望弹出堆栈的头节点。</p>
<ul>
<li>
<p>Thread 1操作时</p>
<p>head = A</p>
<p>headNext = B</p>
</li>
</ul>
<p>线程1完成pop前，线程2开始工作。</p>
<ul>
<li>
<p>Thread 2 pop A</p>
<p><code>Stack: TOP -&gt; B -&gt; C</code></p>
</li>
<li>
<p>Thread 2 pop B 并且删除B</p>
<p><code>Stack: TOP -&gt; C</code></p>
</li>
<li>
<p>Thread 2把A推回去</p>
<p><code>Stack: TOP -&gt; A -&gt; C</code></p>
</li>
</ul>
<p>线程1重新调度，并检查<code>A == head</code>，因为当前<code>A == head</code>，那么<code>headNext</code>应该是B，但B已经被删除了。因此，程序具有未定义行为。</p>
<p>用什么来拯救ABA问题呢？接下来就介绍，ABA问题的一些补救措施。</p>
<p><strong>补救措施</strong></p>
<p>ABA的概念问题很容易理解，解决方案是消除节点过早的删除。以下是一些补救措施：</p>
<p><strong>标记参考状态</strong></p>
<p>可以使用地址的低位向每个节点添加标记，以表示节点成功修改的频率。尽管检查返回true，但比较-交换(CAS)会失败。这个想法并不能解决问题，因为标记位可能最终会交换。</p>
<p>引用标记状态通常用于事务内存中。</p>
<p>接下来的三种技术是基于延迟回收的思想。</p>
<p><strong>垃圾收集</strong></p>
<p>垃圾收集只保证在不再需要时删除变量。这听起来很有希望解决ABA问题，但有一个明显的缺点。大多数垃圾收集器不是无锁的，即使有一个无锁的数据结构，整个系统也不是无锁的。</p>
<p><strong>风险指针</strong></p>
<p>维基页面： <a href="https://en.wikipedia.org/wiki/Hazard_pointer">Hazard Pointers</a></p>
<p>风险指针系统中，每个线程都保存一个风险指针列表，指示线程当前正在访问哪些节点(许多系统中，这个“列表”可能仅限于一两个元素)。风险指针列表中的节点不能被任何其他线程修改或释放。当一个线程想要删除一个节点时，它会将其放在一个节点列表中，进行“稍后释放”，直到没有其他线程的危险列表包含该指针时，才释放该节点的内存。一个专门的垃圾收集线程可以手工进行垃圾收集(如果“稍后释放”的列表由所有线程共享)；或者，清理“被释放”列表可以由每个工作线程，作为“pop”等操作的一部分。</p>
<p><strong>RCU 读取-复制-更新</strong></p>
<p>RCU是Read Copy Update的缩写，是一种用于只读数据结构的同步技术。RCU是由Paul McKenney创建的，自2002年以来一直在Linux内核中使用。</p>
<p>思想很简单，就跟缩写一样，要修改数据，要复制数据。反之，所有的读取都使用原始数据。如果没有读取操作，那么可以安全地将数据进行修改。</p>
<p>要了解更多关于RCU的细节，请阅读Paul McKenney的这篇文章:<a href="https://lwn.net/Articles/262464/">What is RCU, Fundamentally?</a> </p>
<blockquote>
<p>两个新的提案</p>
<p>作为并发工具包的一部分，有两个关于未来C++标准的提案。关于风险指针的提案是<a href="http://www.modernescpp.com/open-std.org/JTC1/SC22/WG21/docs/papers/2016/p0233r0.pdf">P0233R0</a>，关于RCU的提案是<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0461r0.pdf">P0461R0</a> 。</p>
</blockquote>
<h2 id="阻塞问题"><a class="header" href="#阻塞问题">阻塞问题</a></h2>
<p>为了说明我的观点，需要将条件变量与谓词结合。不这样做的话，程序可能会出现伪唤醒或未唤醒的情况。</p>
<p>如果使用没有谓词的条件变量，则通知线程可能在等待线程等待之前发送通知，等待线程将永远等待，这种现象被称为“未唤醒“。</p>
<p>程序如下。</p>
<pre><code class="language-c++">// conditionVariableBlock.cpp

#include &lt;iostream&gt;
#include &lt;condition_variable&gt;
#include &lt;mutex&gt;
#include &lt;thread&gt;

std::mutex mutex_;
std::condition_variable condVar;

bool dataReady;


void waitingForWork() {

  std::cout &lt;&lt; &quot;Worker: Waiting for work.&quot; &lt;&lt; std::endl;

  std::unique_lock&lt;std::mutex&gt; lck(mutex_);
  condVar.wait(lck);
  // do the work
  std::cout &lt;&lt; &quot;Work done.&quot; &lt;&lt; std::endl;

}

void setDataReady() {

  std::cout &lt;&lt; &quot;Sender: Data is ready.&quot; &lt;&lt; std::endl;
  condVar.notify_one();

}

int main() {

  std::cout &lt;&lt; std::endl;

  std::thread t1(setDataReady);
  std::thread t2(waitingForWork);

  t1.join();
  t2.join();

  std::cout &lt;&lt; std::endl;
}
</code></pre>
<p>程序的第一次工作得很好，第二次锁定的原因是<code>notify</code>(第28行)发生在线程<code>t2</code>(第37行)等待之前(第19行)。</p>
<p><img src="content/Further-Information/../../images/Further-Information/Challenges/1.png" alt="" /></p>
<p>当然，死锁和活锁是条件竞争的副产物。死锁通常取决于线程的交错，有时会发生，有时不会。活锁与死锁类似，当死锁阻塞时，活锁“似乎''没有阻塞程序。</p>
<h2 id="破坏程序的不变量"><a class="header" href="#破坏程序的不变量">破坏程序的不变量</a></h2>
<p>程序不变量，应该在程序的整个生命周期中”保持不变“。</p>
<p>恶性条件竞争破坏程序的不变量。下面程序的不变量是所有余额的总和，例子中是200欧元，因为每个账户起步都是100欧元(第9行)。</p>
<pre><code class="language-c++">// breakingInvariant.cpp

#include &lt;atomic&gt;
#include &lt;functional&gt;
#include &lt;iostream&gt;
#include &lt;thread&gt;

struct Account {
  std::atomic&lt;int&gt; balance{ 100 };
};

void transferMoney(int amount, Account&amp; from, Account&amp; to) {
  using namespace std::chrono_literals;
  if (from.balance &gt;= amount) {
    from.balance -= amount;
    std::this_thread::sleep_for(1ns);
    to.balance += amount;
  }
}

void printSum(Account&amp; a1, Account&amp; a2) {
  std::cout &lt;&lt; (a1.balance + a2.balance) &lt;&lt; std::endl;
}

int main() {

  std::cout &lt;&lt; std::endl;

  Account acc1;
  Account acc2;

  std::cout &lt;&lt; &quot;Initial sum: &quot;;
  printSum(acc1, acc2);

  std::thread thr1(transferMoney, 5, std::ref(acc1), std::ref(acc2));
  std::thread thr2(transferMoney, 13, std::ref(acc2), std::ref(acc1));
  std::cout &lt;&lt; &quot;Intermediate sum: &quot;;
  std::thread thr3(printSum, std::ref(acc1), std::ref(acc2));

  thr1.join();
  thr2.join();
  thr3.join();

  std::cout &lt;&lt; &quot;  acc1.balance: &quot; &lt;&lt; acc1.balance &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;  acc2.balance: &quot; &lt;&lt; acc2.balance &lt;&lt; std::endl;

  std::cout &lt;&lt; &quot;Final sum: &quot;;
  printSum(acc1, acc2);

  std::cout &lt;&lt; std::endl;

}
</code></pre>
<p>开始时，账户的总数是200欧元。第33行，通过使用第21 - 23行中的<code>printSum</code>函数来显示金额和。第38行使不变量可见。因为第16行有<code>1ns</code>的短睡眠，所以中间的金额是182欧元。最后，每个账户的余额都是正确的(第44行和第45行)，金额是200欧元(第48行)。</p>
<p>下面是程序的输出。</p>
<p><img src="content/Further-Information/../../images/Further-Information/Challenges/2.png" alt="" /></p>
<h2 id="数据竞争"><a class="header" href="#数据竞争">数据竞争</a></h2>
<p>数据竞争是指至少两个线程同时访问一个共享变量的情况，并且至少有一个线程尝试修改该变量。</p>
<p>程序有数据竞争，则会出现未定义行为，结果是不可预期的。</p>
<p>来看一个数据竞争的程序。</p>
<pre><code class="language-c++">// addMoney.cpp

#include &lt;functional&gt;
#include &lt;iostream&gt;
#include &lt;thread&gt;
#include &lt;vector&gt;

struct Account {
  int balance{ 100 };
};

void addMoney(Account&amp; to, int amount) {
    to.balance += amount;
}

int main() {

  std::cout &lt;&lt; std::endl;

  Account account;

  std::vector&lt;std::thread&gt; vecThreads(100);


  for (auto&amp; thr : vecThreads) thr = std::thread(addMoney, std::ref(account), 50);

  for (auto&amp; thr : vecThreads) thr.join();


  std::cout &lt;&lt; &quot;account.balance: &quot; &lt;&lt; account.balance &lt;&lt; std::endl;

  std::cout &lt;&lt; std::endl;

}
</code></pre>
<p>100个线程<code>addMoney</code>函数将向相同的帐户(第20行)添加50欧元(第25行)。关键的，对账户的写入是不同步的，这里有一个数据竞争，因为是未定义行为，所以结果无效。最后的余额(第30行)会在5000欧元和5100欧元之间。</p>
<p><img src="content/Further-Information/../../images/Further-Information/Challenges/3.png" alt="" /></p>
<h2 id="死锁"><a class="header" href="#死锁">死锁</a></h2>
<p>死锁是一种状态，因为要等待没有得到的资源的释放，所以至少有一个线程会永久阻塞。</p>
<p>造成死锁的主要原因有两个:</p>
<ol>
<li>互斥锁未解锁。</li>
<li>以不同的顺序锁定互斥锁。</li>
</ol>
<p>为了避免第二个问题，在经典C++中使用了诸如<a href="http://collaboration.cmc.ec.gc.ca/science/rpn/biblio/ddj/Website/articles/DDJ/2008/0801/071201hs01/071201hs01.html">层次锁</a>之类的技术。</p>
<p>有关死锁，以及如何用现代C++克服死锁的详细信息，请参阅互斥量和锁的章节内容。</p>
<blockquote>
<p><strong>多次锁定非递归互斥锁</strong></p>
<p>多次锁定非递归互斥锁会导致未定义行为。</p>
<pre><code class="language-c++">// lockTwice.cpp

#include &lt;iostream&gt;
#include &lt;mutex&gt;

int main() {

    std::mutex mut;

    std::cout &lt;&lt; std::endl;

    std::cout &lt;&lt; &quot;first lock call&quot; &lt;&lt; std::endl;

    mut.lock();

    std::cout &lt;&lt; &quot;second lock call&quot; &lt;&lt; std::endl;

    mut.lock();

    std::cout &lt;&lt; &quot;third lock call&quot; &lt;&lt; std::endl;
}
</code></pre>
<p>通常会死锁。</p>
<p><img src="content/Further-Information/../../images/Further-Information/Challenges/4.png" alt="" /></p>
</blockquote>
<h2 id="伪共享"><a class="header" href="#伪共享">伪共享</a></h2>
<p>当处理器从主存中读取一个变量(如int)时，从内存中读取的数据要大于int的大小。处理器会从缓存中读取整个高速缓存行(通常为64字节)。</p>
<p>如果两个线程，同时读取位于同一高速缓存行上的不同变量a和b，则会发生伪共享。虽然a和b在逻辑上是分开的，但在物理地址上是相连的。由于a和b共享同一条高速缓存线行，因此有必要在高速缓存行上进行硬件同步。得到了正确的结果，但是并发的性能下降了。正是这种现象发生在下面的程序中：</p>
<pre><code class="language-c++">// falseSharing.cpp

#include &lt;algorithm&gt;
#include &lt;chrono&gt;
#include &lt;iostream&gt;
#include &lt;random&gt;
#include &lt;thread&gt;
#include &lt;vector&gt;

constexpr long long size{ 100'000'000 };

struct Sum {
  long long a{ 0 };
  long long b{ 0 };
};

int main() {

  std::cout &lt;&lt; std::endl;

  Sum sum;

  std::cout &lt;&lt; &amp;sum.a &lt;&lt; std::endl;
  std::cout &lt;&lt; &amp;sum.b &lt;&lt; std::endl;

  std::cout &lt;&lt; std::endl;

  std::vector&lt;int&gt; randValues, randValues2;
  randValues.reserve(size);
  randValues2.reserve(size);

  std::mt19937 engine;
  std::uniform_int_distribution&lt;&gt; uniformDist(1, 10);

  int randValue;
  for (long long i = 0; i &lt; size; ++i) {
    randValue = uniformDist(engine);
    randValues.push_back(randValue);
    randValues2.push_back(randValue);
  }

  auto sta = std::chrono::steady_clock::now();

  std::thread t1([&amp;sum, &amp;randValues] {
    for (auto val : randValues) sum.a += val;
    });

  std::thread t2([&amp;sum, &amp;randValues2] {
    for (auto val : randValues2)sum.b += val;
    });

  t1.join(), t2.join();

  std::chrono::duration&lt;double&gt; dur = std::chrono::steady_clock::now() - sta;
  std::cout &lt;&lt; &quot;Time for addition &quot; &lt;&lt; dur.count()
    &lt;&lt; &quot; seconds&quot; &lt;&lt; std::endl;

  std::cout &lt;&lt; &quot;sum.a: &quot; &lt;&lt; sum.a &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;sum.b: &quot; &lt;&lt; sum.b &lt;&lt; std::endl;

  std::cout &lt;&lt; std::endl;
  
}
</code></pre>
<p>第13行和第14行中的变量<code>a</code>和<code>b</code>共享同个缓存行。线程<code>t1(</code>第44行)和线程<code>t2</code>同时使用两个变量，对向量<code>randValues</code>和<code>randValues2</code>中的元素进行求和。两个向量在1到10之间都有1亿个整数。程序的输出显示了一些有趣的事情，<code>a</code>和<code>b</code>在8字节边界上对齐，因为我的操作系统中的<code>long long int</code>是8字节对齐的。</p>
<p><img src="content/Further-Information/../../images/Further-Information/Challenges/5.png" alt="" /></p>
<p>如果将<code>a</code>和<code>b</code>的对齐方式改为64字节会发生什么?64字节是我系统上的高速缓存行的大小。我要对结构做点小改动，这次不用种子来生成随机数，所以每次都得到的随机数相同。</p>
<pre><code class="language-c++">struct Sum{
  alignas(64) long long a{0};
  alignas(64) long long b{0};
};
</code></pre>
<p><img src="content/Further-Information/../../images/Further-Information/Challenges/6.png" alt="" /></p>
<p>现在，<code>a</code>和<code>b</code>在64字节边界处对齐，程序速度提高了6倍多。原因是<code>a</code>和<code>b</code>现在不在同一高速缓存行上。</p>
<blockquote>
<p><strong>用优化器检测伪共享</strong></p>
<p>如果我用最大的优化选项编译的程序，优化器会检测到伪共享并消除它。这意味着，我得到了相同的性能数据与真共享，这也适用于Windows。以下是优化后的性能数字。</p>
<p><img src="content/Further-Information/../../images/Further-Information/Challenges/7.png" alt="" /></p>
</blockquote>
<blockquote>
<p><strong>C++17中的<code>std:: hardware_destructive_interference_size</code>和与<code>std:: hardware_constructive_interference_size</code></strong></p>
<p><code>std::hardware_destructive_interference_size</code>和<code>std::hardware_constructive_interference_size</code>允许以一种可移植的方式处理高速缓存行的大小。<code>std::hardware_destructive_interference_size</code>返回两个对象之间的最小偏移量，以避免伪共享；<code>std::hardware_constructive_interference_size</code>返回相邻内存的最大大小，以满足真共享。</p>
<p>在C++17中，Sum可以以一种平台无关的方式编写。</p>
<pre><code class="language-c++">struct Sum{
 alignas(std::hardware_destructive_interference_size) long long a{0};
 alignas(std::hardware_destructive_interference_size) long long b{0};
};
</code></pre>
</blockquote>
<h2 id="变量的生命周期问题"><a class="header" href="#变量的生命周期问题">变量的生命周期问题</a></h2>
<p>写一个具有生命周期相关问题的C++示例非常容易。让创建的线程<code>t</code>在后台运行(也就是说，它通过调用<code>t.detach()</code>来分离)，并且让它只完成一半的工作。这里，创建者线程不会等待子线程完成。在这种情况下，必须非常小心，最好不要在子线程中使用属于创建线程的任何东西。</p>
<pre><code class="language-c++">// lifetimeIssues.cpp

#include &lt;iostream&gt;
#include &lt;string&gt;
#include &lt;thread&gt;

int main() {

  std::cout &lt;&lt; &quot;Begin: &quot; &lt;&lt; std::endl;

  std::string mess{ &quot;Child thread&quot; };

  std::thread t([&amp;mess] {std::cout &lt;&lt; mess &lt;&lt; std::endl; });
  t.detach();

  std::cout &lt;&lt; &quot;End:&quot; &lt;&lt; std::endl;

}
</code></pre>
<p>这程序太简单了。线程<code>t</code>使用<code>std::cout</code>和变量<code>mess</code>，它们都属于主线程。结果是，在第二次运行时，我看不到子线程的输出。只有“Begin:”(第9行)和“End:”(第16行)打印了出来。</p>
<p><img src="content/Further-Information/../../images/Further-Information/Challenges/8.png" alt="" /></p>
<h2 id="移动线程"><a class="header" href="#移动线程">移动线程</a></h2>
<p>移动线程会使线程的生命周期问题变得更加复杂。</p>
<p>线程支持移动语义，但不支持复制语义。原因是<code>std::thread</code>的复制构造函数被设置为<code>delete</code>：<code>thread (const thread&amp;) = delete;</code>。试想，如果线程在持有锁的情况下能进行复制，会发生什么。</p>
<p>让我们移动一个线程。</p>
<p>错误地移动线程</p>
<pre><code class="language-c++">// threadMoved.cpp

#include &lt;iostream&gt;
#include &lt;thread&gt;
#include &lt;utility&gt;

int main(){
  
  std::thread t([]{std::cout &lt;&lt; std::this_thread::get_id();});
  std::thread t2([]{std::cout &lt;&lt; std::this_thread::get_id();});
  
  t = std::move(t2);
  t.join();
  t2.join();
}
</code></pre>
<p>线程<code>t</code>和<code>t2</code>应该完成它们的工作：打印它们的id。除此之外，线程<code>t2</code>的所有权移动到<code>t</code>(第12行)。最后，主线程处理它的子线程并汇入它们。等一下，结果与我的预期大不相同:</p>
<p><img src="content/Further-Information/../../images/Further-Information/Challenges/9.png" alt="" /></p>
<p>出了什么问题?这里有两个问题:</p>
<ol>
<li>通过移动线程<code>t2</code>, <code>t</code>获得一个新的可调用单元，并调用它的析构函数。结果，<code>t</code>的析构函数调用<code>std::terminate</code>，原始的<code>t</code>线程仍然是可汇入的。</li>
<li>线程<code>t2</code>没有相关的可调用单元，在没有可调用单元的线程上调用<code>join</code>会导致异常<code>std::system_error</code>。</li>
</ol>
<p>了解了这一点，修复工作就很简单了。</p>
<pre><code class="language-c++">// threadMovedFixed.cpp

#include &lt;iostream&gt;
#include &lt;thread&gt;
#include &lt;utility&gt;

int main(){
  
  std::thread t([]{std::cout &lt;&lt; std::this_thread::get_id();});
  std::thread t2([]{std::cout &lt;&lt; std::this_thread::get_id();});
  
  t.join();
  t = std::move(t2);
  t2.join();
  
  std::cout &lt;&lt; &quot;\n&quot;;
  std::cout &lt;&lt; std::boolalpha &lt;&lt; &quot;t2.joinable(): &quot; &lt;&lt; t2.joinable() &lt;&lt; std::endl;
  
}
</code></pre>
<p>结果是线程<code>t2</code>不可汇入。</p>
<p><img src="content/Further-Information/../../images/Further-Information/Challenges/10.png" alt="" /></p>
<h2 id="竞态条件"><a class="header" href="#竞态条件">竞态条件</a></h2>
<p>竞态条件是一种情况，其中操作的结果取决于某些操作的交错。</p>
<p>竞态条件很难发现。由于其取决于线程是否交错出现，也就是内核的数量、系统的利用率或可执行文件的优化级别，都可能是导致出现竞态条件的原因。</p>
<p>竞态条件本身并没什么。但线程以不同的方式交织在一起后，常常会导致严重的问题。这种情况下，称其为<strong>恶性竞争条件</strong>。恶意竞争条件的典型症状表现：数据竞争、破坏程序不变量、阻塞线程，或变量有生存周期问题等。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="时间库"><a class="header" href="#时间库">时间库</a></h1>
<p>如果不写一些关于时间库的内容，那么使用现代C++处理并发性的书就显得不那么完整。时间库由三个部分组成：时间点、时间段和时钟。</p>
<h2 id="时间点时间段和时钟"><a class="header" href="#时间点时间段和时钟">时间点、时间段和时钟</a></h2>
<p>时间点：由它的起始点(所谓的纪元<a href="https://en.wikipedia.org/wiki/Epoch_(reference_date)">epoch</a>)和从纪元起经过的时间(表示为时间段)来表示。</p>
<p>时间段：是两个时间点之间的差值，它用时间刻度的数量来衡量。</p>
<p>时钟：由一个起点和一个时间刻度组成，此信息可以计算当前时间。</p>
<p>可以比较时间点。将时间段添加到某个时间点时，可以得到一个新的时间点。时钟周期是测量时间时钟的准确性。耶稣的出生在我的文明中作为一个开始的时间点，一年是一个典型的时间周期。</p>
<p><a href="https://en.wikipedia.org/wiki/Dennis_Ritchie">Dennis Ritchie</a>，C语言的创造者于2011年去世，我用他的一生来说明这三个概念。为了简单起见，这里只使用年份。</p>
<p>这是他的一生。</p>
<p><img src="content/Further-Information/../../images/Further-Information/The-Time-Library/1.png" alt="" /></p>
<p>耶稣的诞生是我们时代的起点，也就是纪元元年。1941年和2011年的时间是由纪元源时间点和时间段来定义的。从2011年减去1941年，得到的是时间段。所以，Dennis Ritchie去世时，享年70岁。</p>
<p>我们继续研究时间库的组件。</p>
<h2 id="时间点"><a class="header" href="#时间点">时间点</a></h2>
<p>时间点<code>std::chrono::time_point</code>由起始点(<code>epoch</code>)和附加的时间段定义。类模板由两个组件：时钟和时间段。默认情况下，时间段是从时钟类派生出来的。</p>
<p><code>std::chrono::time_point</code>类模板</p>
<pre><code class="language-c++">template&lt;
  class Clock,
  class Duration= typename Clock::duration
&gt;
class time_point;
</code></pre>
<p>对于时钟来说，有以下四个特殊的时间点:</p>
<ul>
<li>epoch: 时钟的起点。</li>
<li>now: 当前时间。</li>
<li>min: 时钟可以统计的最小时间点。</li>
<li>max: 时钟可以拥有的最大时间点。</li>
</ul>
<p>最小和最大时间点的准确性取决于使用的时钟：<code>std::system::system_clock</code>, <code>std::chrono::steady_clock</code>或<code>std::chrono::high_resolution_clock</code>。</p>
<p>C++不保证时钟的准确性、起始点，还有有效时间范围。<code>std::chrono::system_clock</code>的起始时间通常是1970年1月1日，也就是所谓的<a href="https://en.wikipedia.org/wiki/Unix_time">UNIX元年</a>，而<code>std::chrono::high_resolution_clock</code>具有最高的统计精度。</p>
<h3 id="从时间点到日历时间"><a class="header" href="#从时间点到日历时间">从时间点到日历时间</a></h3>
<p>通过<code>std::chrono::system_clock::to_time_t</code>可以将一个内部使用<code>std::chrono::system_clock</code>的时间点，转换成一个类型为<code>std::time_t</code>的对象。通过函数<a href="http://en.cppreference.com/w/cpp/chrono/c/gmtime"><code>std::gmtime</code></a>对<code>std::time_t</code>对象进行进一步转换，可以得到以<a href="https://en.wikipedia.org/wiki/Coordinated_Universal_Time">世界统一时间</a>(UTC)表示的日历时间。最后，可以使用这个日历时间作为函数<a href="http://en.cppreference.com/w/cpp/chrono/c/asctime"><code>std::asctime</code></a>的输入，以获得日历时间的文本表示。</p>
<p>显示日历时间</p>
<pre><code class="language-c++">// timepoint.cpp

#include &lt;chrono&gt;
#include &lt;ctime&gt;
#include &lt;iostream&gt;
#include &lt;string&gt;

int main() {

  std::cout &lt;&lt; std::endl;

  std::chrono::time_point&lt;std::chrono::system_clock&gt; sysTimePoint;
  std::time_t tp = std::chrono::system_clock::to_time_t(sysTimePoint);
  std::string sTp = std::asctime(std::gmtime(&amp;tp));
  std::cout &lt;&lt; &quot;Epoch: &quot; &lt;&lt; sTp &lt;&lt; std::endl;

  tp = std::chrono::system_clock::to_time_t(sysTimePoint.min());
  sTp = std::asctime(std::gmtime(&amp;tp));
  std::cout &lt;&lt; &quot;Time min: &quot; &lt;&lt; sTp &lt;&lt; std::endl;

  tp = std::chrono::system_clock::to_time_t(sysTimePoint.max());
  sTp = std::asctime(std::gmtime(&amp;tp));
  std::cout &lt;&lt; &quot;Time max: &quot; &lt;&lt; sTp &lt;&lt; std::endl;

  sysTimePoint = std::chrono::system_clock::now();
  tp = std::chrono::system_clock::to_time_t(sysTimePoint);
  sTp = std::asctime(std::gmtime(&amp;tp));
  std::cout &lt;&lt; &quot;Time now: &quot; &lt;&lt; sTp &lt;&lt; std::endl;

}
</code></pre>
<p>程序会显示<code>std::chrono::system_clock</code>的有效范围。我的Linux PC上，<code>std::chrono::system_clock</code>以UNIX元年作为起始点，时间点可以在1677年到2262年之间。</p>
<p><img src="content/Further-Information/../../images/Further-Information/The-Time-Library/2.png" alt="" /></p>
<p>可以将时间段添加到时间点上，以获得新的时间点。在有效时间范围之外添加时间段，是未定义行为。</p>
<h3 id="跨越有效的时间范围"><a class="header" href="#跨越有效的时间范围">跨越有效的时间范围</a></h3>
<p>下面的示例使用当前时间并加减1000年。为了简单起见，我忽略闰年，假设一年有365天。</p>
<pre><code class="language-c++">// timepointAddition.cpp

#include &lt;chrono&gt;
#include &lt;ctime&gt;
#include &lt;iostream&gt;
#include &lt;string&gt;

using namespace std::chrono;
using namespace std;

string timePointAsString(const time_point&lt;system_clock&gt;&amp; timePoint) {
  time_t tp = system_clock::to_time_t(timePoint);
  return asctime(gmtime(&amp;tp));
}

int main() {

  cout &lt;&lt; endl;

  time_point&lt;system_clock&gt; nowTimePoint = system_clock::now();

  cout &lt;&lt; &quot;Now: &quot; &lt;&lt; timePointAsString(nowTimePoint) &lt;&lt; endl;

  const auto thousandYears = hours(24 * 365 * 1000);
  time_point&lt;system_clock&gt; historyTimePoint = nowTimePoint - thousandYears;
  cout &lt;&lt; &quot;Now - 1000 years: &quot; &lt;&lt; timePointAsString(historyTimePoint) &lt;&lt; endl;

  time_point&lt;system_clock&gt; futureTimePoint = nowTimePoint + thousandYears;
  cout &lt;&lt; &quot;Now + 1000 years: &quot; &lt;&lt; timePointAsString(futureTimePoint) &lt;&lt; endl;

}
</code></pre>
<p>程序的输出显示，第25行和第28行中时间点的溢出，将导致错误的结果。从现在的时间点减去1000年，获得了将来的时间点；在当前时间点上加上1000年，得到了过去的时间点。</p>
<p><img src="content/Further-Information/../../images/Further-Information/The-Time-Library/3.png" alt="" /></p>
<p>两个时间点之间的差值是时间段。时间段支持基本的算法，可以在不同的时间刻度下进行显示。</p>
<h2 id="时间段"><a class="header" href="#时间段">时间段</a></h2>
<p><code>std::chrono::duration</code>是一个类模板， <code>Rep</code>类型的计次数和计次周期组成。</p>
<p><code>std::chrono::duration</code>类模板</p>
<pre><code class="language-c++">template&lt;
  class Rep,
  class Period = std::ratio&lt;1&gt;
&gt; class duration;
</code></pre>
<p>计次周期默认长度为<code>std::ratio&lt;1&gt;</code>。<code>std::ratio&lt;1&gt;</code>表示1秒，也可以写成<code>std::ratio&lt; 1,1 &gt;</code>，以此类推，<code>std::ratio&lt;60&gt;</code>是一分钟，<code>std::ratio&lt;1,1000&gt; </code>是1毫秒。当<code>Rep</code>类型是浮点数时，可以使用它来保存时间刻度的分数形式。</p>
<p>C++11预定义了几个重要的时间单位:</p>
<pre><code class="language-c++">typedef duration&lt;signed int, nano&gt; nanoseconds;
typedef duration&lt;signed int, micro&gt; microseconds;
typedef duration&lt;signed int, milli&gt; milliseconds;
typedef duration&lt;signed int&gt; seconds;
typedef duration&lt;signed int, ratio&lt; 60&gt;&gt; minutes;
typedef duration&lt;signed int, ratio&lt;3600&gt;&gt; hours;
</code></pre>
<p>从UNIX元年(1970年1月1日)到现在有多少时间了?通过不同时间的类型别名，我可以很容易地回答这个问题。下面的例子中，继续忽略闰年，假设一年有365天。</p>
<pre><code class="language-c++">// timeSinceEpoch.cpp

#include &lt;chrono&gt;
#include &lt;iostream&gt;

using namespace std;

int main() {

  cout &lt;&lt; fixed &lt;&lt; endl;

  cout &lt;&lt; &quot;Time since 1.1.1970:\n&quot; &lt;&lt; endl;

  const auto timeNow = chrono::system_clock::now();
  const auto duration = timeNow.time_since_epoch();
  cout &lt;&lt; duration.count() &lt;&lt; &quot; nanoseconds &quot; &lt;&lt; endl;

  typedef chrono::duration&lt;long double, ratio&lt;1, 1000000&gt;&gt; MyMicroSecondTick;
  MyMicroSecondTick micro(duration);
  cout &lt;&lt; micro.count() &lt;&lt; &quot; microseconds&quot; &lt;&lt; endl;

  typedef chrono::duration&lt;long double, ratio&lt;1, 1000&gt;&gt; MyMilliSecondTick;
  MyMilliSecondTick milli(duration);
  cout &lt;&lt; milli.count() &lt;&lt; &quot; milliseconds&quot; &lt;&lt; endl;

  typedef chrono::duration&lt;long double&gt; MySecondTick;
  MySecondTick sec(duration);
  cout &lt;&lt; sec.count() &lt;&lt; &quot; seconds &quot; &lt;&lt; endl;

  typedef chrono::duration&lt;double, ratio&lt;60&gt;&gt; MyMinuteTick;
  MyMinuteTick myMinute(duration);
  cout &lt;&lt; myMinute.count() &lt;&lt; &quot; minutes&quot; &lt;&lt; endl;

  typedef chrono::duration&lt;double, ratio&lt;60 * 60&gt;&gt; MyHourTick;
  MyHourTick myHour(duration);
  cout &lt;&lt; myHour.count() &lt;&lt; &quot; hours&quot; &lt;&lt; endl;

  typedef chrono::duration&lt;double, ratio&lt;60 * 60 * 24 * 365&gt;&gt; MyYearTick;
  MyYearTick myYear(duration);
  cout &lt;&lt; myYear.count() &lt;&lt; &quot; years&quot; &lt;&lt; endl;

  typedef chrono::duration&lt;double, ratio&lt;60 * 45&gt;&gt; MyLessonTick;
  MyLessonTick myLesson(duration);
  cout &lt;&lt; myLesson.count() &lt;&lt; &quot; lessons&quot; &lt;&lt; endl;

  cout &lt;&lt; endl;

}
</code></pre>
<p>时间长度是微秒(第18行)、毫秒(第22行)、秒(第26行)、分钟(第30行)、小时(第34行)和年(第38行)。另外，我在第42行定义了德国学校单节课的时长(45分钟)。</p>
<p><img src="content/Further-Information/../../images/Further-Information/The-Time-Library/4.png" alt="" /></p>
<h2 id="计算时间"><a class="header" href="#计算时间">计算时间</a></h2>
<p>时间单位表示的时间支持基本的算术运算，可以用一个数字乘以或除以一个时间段。当然，也可以比较时间单位表示的时间，所有这些计算和比较都是基于时间单位的。</p>
<p>在C++14标准中，更加方便。C++14标准支持时间段的文字表示。</p>
<table><thead><tr><th align="center">类型</th><th align="center">后缀</th><th align="center">示例</th></tr></thead><tbody>
<tr><td align="center">std::chrono::hours</td><td align="center">h</td><td align="center">5h</td></tr>
<tr><td align="center">std::chrono::minutes</td><td align="center">min</td><td align="center">5min</td></tr>
<tr><td align="center">std::chrono::seconds</td><td align="center">s</td><td align="center">5s</td></tr>
<tr><td align="center">std::chrono::milliseconds</td><td align="center">ms</td><td align="center">5min</td></tr>
<tr><td align="center">std::chrono::microseconds</td><td align="center">us</td><td align="center">5us</td></tr>
<tr><td align="center">std::chrono::nanoseconds</td><td align="center">ns</td><td align="center">5ns</td></tr>
</tbody></table>
<p>我17岁的儿子Marius，在学校的一天中要花多少时间?我在下面的示例中，回答了这个问题，并以不同的时间段格式显示结果。</p>
<pre><code class="language-c++">// schoolDay.cpp

#include &lt;iostream&gt;
#include &lt;chrono&gt;

using namespace std::literals::chrono_literals;
using namespace std::chrono;
using namespace std;

int main() {

  cout &lt;&lt; endl;

  constexpr auto schoolHour = 45min;

  constexpr auto shortBreak = 300s;
  constexpr auto longBreak = 0.25h;

  constexpr auto schoolWay = 15min;
  constexpr auto homework = 2h;

  constexpr auto schoolDaySec = 2 * schoolWay + 6 * schoolHour + 4 * shortBreak +
    longBreak + homework;

  cout &lt;&lt; &quot;School day in seconds: &quot; &lt;&lt; schoolDaySec.count() &lt;&lt; endl;

  constexpr duration&lt;double, ratio&lt;3600&gt;&gt; schoolDayHour = schoolDaySec;
  constexpr duration&lt;double, ratio&lt;60&gt;&gt; schoolDayMin = schoolDaySec;
  constexpr duration&lt;double, ratio&lt;1, 1000&gt;&gt; schoolDayMilli = schoolDaySec;

  cout &lt;&lt; &quot;School day in hours: &quot; &lt;&lt; schoolDayHour.count() &lt;&lt; endl;
  cout &lt;&lt; &quot;School day in minutes: &quot; &lt;&lt; schoolDayMin.count() &lt;&lt; endl;
  cout &lt;&lt; &quot;School day in milliseconds: &quot; &lt;&lt; schoolDayMilli.count() &lt;&lt; endl;

  cout &lt;&lt; endl;

}
</code></pre>
<p>有一节德语课的时间(第14行)，一个短暂的休息(第16行)，一个长时间的休息(第17行)，Marius去学校的路(第19行)上花费的时间，以及做家庭作业(第20行)的时间。计算结果<code>schoolDaysInSeconds</code>(第22行)在编译时可用。</p>
<p><img src="content/Further-Information/../../images/Further-Information/The-Time-Library/5.png" alt="" /></p>
<blockquote>
<p><strong>编译时的计算</strong></p>
<p>时间常量(第14 - 20行)、第22行中的<code>schoolDaySec</code>和各种时间段(第28 - 30行)都是常量表达式(<code>constexpr</code>)。因此，所有值都可在编译时获得，只有输出是在运行时执行。</p>
</blockquote>
<p>报时的准确性取决于所用的时钟。C++中，有三种时钟<code>std::chrono::system_clock</code>, <code>std::chrono::steady_clock</code>和<code>std::chrono::high_resolution_clock</code>。</p>
<h2 id="时钟"><a class="header" href="#时钟">时钟</a></h2>
<p>三种不同类型的时钟之间有什么区别?</p>
<ul>
<li><code>std::chrono::sytem_clock</code>: 是系统范围内的实时时钟(<a href="https://en.wikipedia.org/wiki/Wall-clock_time">挂壁钟</a>)。该时钟具有<code>to_time_t</code>和<code>from_time_t</code>的辅助功能，可以将时间点转换为日历时间。</li>
<li><code>std::chrono::steady_clock</code>: 是唯一提供保证的时钟，并且不能调整它。因此，<code>std::chrono::steady_clock</code>是测量时间间隔的首选时钟。</li>
<li><code>std::chrono::high_resolution_clock</code>：是精度最高的时钟，但它可以只是时钟<code>std::chrono::system_clock</code>或<code>std::chrono::steady_clock</code>的别名。</li>
</ul>
<blockquote>
<p><strong>无保证的准确性、起始点和有效的时间范围</strong></p>
<p>C++标准不保证时钟的精度、起始点和有效时间范围。通常，<code>std::chrono:system_clock</code>的起始点是1970年1月1日，也就是所谓的UNIX元年，而<code>std::chrono::steady_clock</code>的起始点则是PC的启动时间。</p>
</blockquote>
<h3 id="准确性和稳定性"><a class="header" href="#准确性和稳定性">准确性和稳定性</a></h3>
<p>知道哪些时钟是稳定的，以及它们提供的精度是很有趣的事情。稳定意味着时钟不能调整，可以直接从时钟中得到答案。</p>
<p>三个时钟的准确性和稳定性</p>
<pre><code class="language-c++">// clockProperties.cpp

#include &lt;chrono&gt;
#include &lt;iomanip&gt;
#include &lt;iostream&gt;

using namespace std::chrono;
using namespace std;

template &lt; typename T&gt;
void printRatio() {
  cout &lt;&lt; &quot; precision: &quot; &lt;&lt; T::num &lt;&lt; &quot;/&quot; &lt;&lt; T::den &lt;&lt; &quot; second &quot; &lt;&lt; endl;
  typedef typename ratio_multiply&lt;T, kilo&gt;::type MillSec;
  typedef typename ratio_multiply&lt;T, mega&gt;::type MicroSec;
  cout &lt;&lt; fixed;
  cout &lt;&lt; &quot; &quot; &lt;&lt; static_cast&lt;double&gt;(MillSec::num) / MillSec::den
    &lt;&lt; &quot; milliseconds &quot; &lt;&lt; endl;
  cout &lt;&lt; &quot; &quot; &lt;&lt; static_cast&lt;double&gt;(MicroSec::num) / MicroSec::den
    &lt;&lt; &quot; microseconds &quot; &lt;&lt; endl;
}

int main() {

  cout &lt;&lt; boolalpha &lt;&lt; endl;

  cout &lt;&lt; &quot;std::chrono::system_clock: &quot; &lt;&lt; endl;
  cout &lt;&lt; &quot; is steady: &quot; &lt;&lt; system_clock::is_steady &lt;&lt; endl;
  printRatio&lt;chrono::system_clock::period&gt;();

  cout &lt;&lt; endl;

  cout &lt;&lt; &quot;std::chrono::steady_clock: &quot; &lt;&lt; endl;
  cout &lt;&lt; &quot; is steady: &quot; &lt;&lt; chrono::steady_clock::is_steady &lt;&lt; endl;
  printRatio&lt;chrono::steady_clock::period&gt;();

  cout &lt;&lt; endl;

  cout &lt;&lt; &quot;std::chrono::high_resolution_clock: &quot; &lt;&lt; endl;
  cout &lt;&lt; &quot; is steady: &quot; &lt;&lt; chrono::high_resolution_clock::is_steady
    &lt;&lt; endl;
  printRatio&lt;chrono::high_resolution_clock::period&gt;();

  cout &lt;&lt; endl;

}
</code></pre>
<p>在第27行、第33行和第39行显示每个时钟是否稳定。函数<code>printRatio</code>(第10 -20行)比较难懂。首先，以秒为单位显示时钟的精度。此外，使用函数模板<code>std::ratio_multiply</code>，以及常量<code>std::kilo</code>和<code>std::mega</code>来将单位调整为以浮点数显示的毫秒和微秒。您可以通过<a href="http://en.cppreference.com/w/cpp/numeric/ratio">cppreference.com</a>获得计算时间在编译时的更多详细信息。</p>
<p>Linux上的输出与Windows上的不同。Linux上，<code>std::chrono::system_clock</code>要精确得多；Windows上，<code>std::chrono::high_resultion_clock</code>是稳定的。</p>
<p><img src="content/Further-Information/../../images/Further-Information/The-Time-Library/6.png" alt="" /></p>
<p><img src="content/Further-Information/../../images/Further-Information/The-Time-Library/7.png" alt="" /></p>
<p>虽然C++标准没有指定时钟的纪元，但是可以通过计算得到。</p>
<h3 id="纪元元年"><a class="header" href="#纪元元年">纪元元年</a></h3>
<p>由于辅助函数<a href="http://en.cppreference.com/w/cpp/chrono/time_point/time_since_epoch">time_since_epoch</a>，每个时钟返回显示自元年以来已经过了很多时间。</p>
<p>计算每个时钟的元年</p>
<pre><code class="language-c++">// now.cpp

#include &lt;chrono&gt;
#include &lt;iomanip&gt;
#include &lt;iostream&gt;

using namespace std::chrono;

template &lt; typename T&gt;
void durationSinceEpoch(const T dur) {
  std::cout &lt;&lt; &quot; Counts since epoch: &quot; &lt;&lt; dur.count() &lt;&lt; std::endl;
  typedef duration&lt;double, std::ratio&lt;60&gt;&gt; MyMinuteTick;
  const MyMinuteTick myMinute(dur);
  std::cout &lt;&lt; std::fixed;
  std::cout &lt;&lt; &quot; Minutes since epoch: &quot; &lt;&lt; myMinute.count() &lt;&lt; std::endl;
  typedef duration&lt;double, std::ratio&lt;60 * 60 * 24 * 365&gt;&gt; MyYearTick;
  const MyYearTick myYear(dur);
  std::cout &lt;&lt; &quot; Years since epoch: &quot; &lt;&lt; myYear.count() &lt;&lt; std::endl;

}

int main() {

  std::cout &lt;&lt; std::endl;

  system_clock::time_point timeNowSysClock = system_clock::now();
  system_clock::duration timeDurSysClock = timeNowSysClock.time_since_epoch();
  std::cout &lt;&lt; &quot;system_clock: &quot; &lt;&lt; std::endl;
  durationSinceEpoch(timeDurSysClock);

  std::cout &lt;&lt; std::endl;

  const auto timeNowStClock = steady_clock::now();
  const auto timeDurStClock = timeNowStClock.time_since_epoch();
  std::cout &lt;&lt; &quot;steady_clock: &quot; &lt;&lt; std::endl;
  durationSinceEpoch(timeDurStClock);
  std::cout &lt;&lt; std::endl;

  const auto timeNowHiRes = high_resolution_clock::now();
  const auto timeDurHiResClock = timeNowHiRes.time_since_epoch();
  std::cout &lt;&lt; &quot;high_resolution_clock: &quot; &lt;&lt; std::endl;
  durationSinceEpoch(timeDurHiResClock);

  std::cout &lt;&lt; std::endl;

}
</code></pre>
<p>变量<code>timeDurSysClock</code>(第26行)、<code>timeDurStClock</code>(第33行)和<code>timeDurHiResClock</code>(第40行)包含从对应时钟的起始点经过的时间。如果不使用<code>auto</code>自动类型推断，则写入时间点和时间段的确切类型将非常冗长。函数<code>durationSinceEpoch</code>(第9 - 19行)中，以不同的分辨率显示时间持续时间。首先，显示时间刻度的数量(第11行)，然后显示分钟的数量(第15行)，最后显示自<code>epoch</code>以来的年份(第18行)。所有值都依赖于所使用的时钟。为了简单起见，忽略闰年，假设一年有365天。</p>
<p>同样，Linux和Windows上的结果也是不同的。</p>
<p><img src="content/Further-Information/../../images/Further-Information/The-Time-Library/8.png" alt="" /></p>
<p><img src="content/Further-Information/../../images/Further-Information/The-Time-Library/9.png" alt="" /></p>
<p>为了得出正确的结论，我得提一下，Linux PC已经运行了大约5小时(305分钟)，而Windows PC已经运行了超过6小时(391分钟)。</p>
<p>我的Linux PC上，<code>std::chrono::system_clock</code>和<code>std::chrono::high_resolution_clock</code>以UNIX元年作为起始点。<code>std::chrono::steady_clock</code>的起始点是我电脑的启动时间。虽然<code>std::high_resolution_clock</code>是Linux上的<code>std::system_clock</code>的别名，但<code>std::high_resolution_clock</code>似乎是Windows上的<code>std::steady_clock</code>的别名，这一结论与前一小节的精度和稳定性结果相一致。</p>
<p>有了时间库，可以限制让线程进入睡眠状态的时限。休眠和等待函数的参数，可以是时间点或是时间段。</p>
<h2 id="休眠和等待"><a class="header" href="#休眠和等待">休眠和等待</a></h2>
<p>时间概念是多线程组件(如线程、锁、条件变量和future)的一个重要特性。</p>
<p><strong>惯例</strong></p>
<p>多线程中处理时间的方法遵循一个简单的惯例。以<code>_for</code>结尾的方法必须按时间长度进行参数化；以<code>_until</code>结尾的方法，指定一个时间点。下面简要概述了处理睡眠、阻塞和等待的方法。</p>
<table><thead><tr><th align="center">多线程组件</th><th align="center">_until</th><th align="center">_for</th></tr></thead><tbody>
<tr><td align="center">std::thread th</td><td align="center">th.sleep_until(in2min)</td><td align="center">th.sleep_for(2s)</td></tr>
<tr><td align="center">std::unique_lock lk</td><td align="center">lk.try_lock_until(in2min)</td><td align="center">lk.try_lock(2s)</td></tr>
<tr><td align="center">std::condition_variable cv</td><td align="center">cv.wait_until(in2min)</td><td align="center">cv.wait_for(2s)</td></tr>
<tr><td align="center">std::future fu</td><td align="center">fu.wait_until(in2min)</td><td align="center">fu.wait_for(2s)</td></tr>
<tr><td align="center">std::shared_future shFu</td><td align="center">shFu.wait(in2min)</td><td align="center">shFu.wait_for(2s)</td></tr>
</tbody></table>
<p><code>in2min</code>表示未来2分钟的时间，<code>2s</code>是时间段2秒。虽然使用自动初始化的时间点<code> in2min</code>，以下的表达式仍然冗长:</p>
<p>定义一个时间点</p>
<pre><code class="language-c++">auto in2min= std::chrono::steady_clock::now() + std::chrono::minutes(2);
</code></pre>
<p>当使用时间单位时，C++14的时间文字可以帮助我们：2s就代表2秒。</p>
<p>接下来，让我们看看不同的等待策略。</p>
<p><strong>各种等待策略</strong></p>
<p>以下程序的主要思想是，promise提供四种共享future的结果。因为多个<code>shared_future</code>可以等待相同的promise通知，所以没问题。每个future都有不同的等待策略，并且promise和future在不同的线程中执行。为了简单起见，本小节中只讨论一个正在等待的线程。</p>
<p>下面是四个等待线程的策略:</p>
<ul>
<li>consumeThread1: 为promise的结果等待4秒。</li>
<li>consumeThread2: 为promise的结果等待20秒。</li>
<li>consumeThread3: 查询promise的结果，并返回休眠700毫秒。</li>
<li>consumeThread4: 向对方询问结果，然后继续休眠。它的休眠时间从1毫秒开始，每次翻倍。</li>
</ul>
<p>程序如下。</p>
<p>各种等待策略</p>
<pre><code class="language-c++">// sleepAndWait.cpp

#include &lt;utility&gt;
#include &lt;iostream&gt;
#include &lt;future&gt;
#include &lt;thread&gt;
#include &lt;utility&gt;

using namespace std;
using namespace std::chrono;

mutex coutMutex;

long double getDifference(const steady_clock::time_point&amp; tp1,
  const steady_clock::time_point&amp; tp2) {
  const auto diff = tp2 - tp1;
  const auto res = duration &lt;long double, milli&gt;(diff).count();
  return res;
}

void producer(promise&lt;int&gt;&amp;&amp; prom) {
  cout &lt;&lt; &quot;PRODUCING THE VALUE 2011\n\n&quot;;
  this_thread::sleep_for(seconds(5));
  prom.set_value(2011);
}

void consumer(shared_future&lt;int&gt; fut,
  steady_clock::duration dur) {
  const auto start = steady_clock::now();
  future_status status = fut.wait_until(steady_clock::now() + dur);
  if (status == future_status::ready) {
    lock_guard&lt;mutex&gt; lockCout(coutMutex);
    cout &lt;&lt; this_thread::get_id() &lt;&lt; &quot; ready =&gt; Result: &quot; &lt;&lt; fut.get()
      &lt;&lt; endl;
  }
  else {
    lock_guard&lt;mutex&gt; lockCout(coutMutex);
    cout &lt;&lt; this_thread::get_id() &lt;&lt; &quot; stopped waiting.&quot; &lt;&lt; endl;
  }
  const auto end = steady_clock::now();
  lock_guard&lt;mutex&gt; lockCout(coutMutex);
  cout &lt;&lt; this_thread::get_id() &lt;&lt; &quot; waiting time: &quot;
    &lt;&lt; getDifference(start, end) &lt;&lt; &quot; ms&quot; &lt;&lt; endl;
}

void consumePeriodically(shared_future&lt;int&gt; fut) {
  const auto start = steady_clock::now();
  future_status status;
  do {
    this_thread::sleep_for(milliseconds(700));
    status = fut.wait_for(seconds(0));
    if (status == future_status::timeout) {
      lock_guard&lt;mutex&gt; lockCout(coutMutex);
      cout &lt;&lt; &quot; &quot; &lt;&lt; this_thread::get_id()
        &lt;&lt; &quot; still waiting.&quot; &lt;&lt; endl;
    }
    if (status == future_status::ready) {
      lock_guard&lt;mutex&gt; lockCout(coutMutex);
      cout &lt;&lt; &quot; &quot; &lt;&lt; this_thread::get_id()
        &lt;&lt; &quot; waiting done =&gt; Result: &quot; &lt;&lt; fut.get() &lt;&lt; endl;
    }
  } while (status != future_status::ready);
  const auto end = steady_clock::now();
  lock_guard&lt;mutex&gt; lockCout(coutMutex);
  cout &lt;&lt; &quot; &quot; &lt;&lt; this_thread::get_id() &lt;&lt; &quot; waiting time: &quot;
    &lt;&lt; getDifference(start, end) &lt;&lt; &quot; ms&quot; &lt;&lt; endl;
}

void consumeWithBackoff(shared_future&lt;int&gt; fut) {
  const auto start = steady_clock::now();
  future_status status;
  auto dur = milliseconds(1);
  do {
    this_thread::sleep_for(dur);
    status = fut.wait_for(seconds(0));
    dur *= 2;
    if (status == future_status::timeout) {
      lock_guard&lt;mutex&gt; lockCout(coutMutex);
      cout &lt;&lt; &quot; &quot; &lt;&lt; this_thread::get_id()
        &lt;&lt; &quot; still waiting.&quot; &lt;&lt; endl;
    }
    if (status == future_status::ready) {
      lock_guard&lt;mutex&gt; lockCout(coutMutex);
      cout &lt;&lt; &quot; &quot; &lt;&lt; this_thread::get_id()
        &lt;&lt; &quot; waiting done =&gt; Result: &quot; &lt;&lt; fut.get() &lt;&lt; endl;
    }
  } while (status != future_status::ready);
  const auto end = steady_clock::now();
  lock_guard&lt;mutex&gt; lockCout(coutMutex);
  cout &lt;&lt; &quot; &quot; &lt;&lt; this_thread::get_id()
    &lt;&lt; &quot; waiting time: &quot; &lt;&lt; getDifference(start, end) &lt;&lt; &quot; ms&quot; &lt;&lt; endl;
}

int main() {

  cout &lt;&lt; endl;

  promise&lt;int&gt; prom;
  shared_future&lt;int&gt; future = prom.get_future();
  thread producerThread(producer, move(prom));

  thread consumerThread1(consumer, future, seconds(4));
  thread consumerThread2(consumer, future, seconds(20));
  thread consumerThread3(consumePeriodically, future);
  thread consumerThread4(consumeWithBackoff, future);

  consumerThread1.join();
  consumerThread2.join();
  consumerThread3.join();
  consumerThread4.join();
  producerThread.join();

  cout &lt;&lt; endl;

}
</code></pre>
<p>我在主函数中创建promise(第98行)，使用promise创建关联的future(第99行)，并将promise移动到一个单独的线程(第100行)。因为promise不支持复制语义，必须将其移动到线程中。这对于共享future来说是不必要的(第102 - 105行)，它们支持复制语义，因此可以复制。</p>
<p>讨论线程的工作包之前，简单介绍一下辅助函数<code>getDifference</code>(第14 - 19行)。该函数接受两个时间点，并以毫秒为单位返回这两个时间点之间的时间段。</p>
<p>那创建的五个线程呢?</p>
<ul>
<li>producerThread: 执行函数生成器(第21 - 25行)，并在5秒休眠后发布其结果2011。这是future正在等待的结果。</li>
<li>consumerThread1: 执行函数<code>consumer</code>函数(第27 - 44行)。线程最多等待4秒(第30行)才继续工作。这段等待的时间不够长，无法从promise中得到结果。</li>
<li>consumerThread2: 执行<code>consumer</code>函数(第27 - 44行)。线程在继续工作之前最多等待20秒。</li>
<li>consumerThread3: 定期执行<code>consume</code>函数(第46 - 67行)。休眠700毫秒(第50行)，并请求promise的结果(第60行)。因为第51行<code>std::chrono::seconds(0)</code>，所以不需要等待。如果计算结果可用，将第60行在显示。</li>
<li>consumerThread4: 执行<code>consumeWithBackoff</code>函数(第69 - 92行)。在第一个迭代1秒内休眠，并在每个迭代中将休眠时间加倍。否则，它的策略就与consumerThread3的策略差不多了。</li>
</ul>
<p>现在来同步程序。确定当前时间的时钟和<code>std::cout</code>都是共享变量，但不需要同步。首先，调用<code>std::chrono::steady_clock::now()</code>是线程安全的(第30行和第40行)；其次，C++运行时保证这些字符被写入<code>std::cout</code>是线程安全的。这里，只使用了<code>std::lock_guard</code>来保护<code>std::cout</code>(在第32、37和41行)。</p>
<p>尽管线程逐个地向<code>std::cout</code>写入数据，但是输出并不容易理解。</p>
<p><img src="content/Further-Information/../../images/Further-Information/The-Time-Library/10.png" alt="" /></p>
<p>第一个输出来自于promise。左边的输出来自future。首先，consumerThread4询问结果，8个字符缩进输出，consumerThread4也显示它的id，consumerThread3紧跟其后，4个字符缩进它的输出，consumerThread1和consumerThread2的输出没有缩进。</p>
<ul>
<li>consumeThread1: 等待4000.18ms，但是没有得到结果。</li>
<li>consumeThread2: 在等待5000.3ms后获取结果，但其等待时间最长可达20秒。</li>
<li>consumeThread3: 在等待5601.76ms后获取结果。也就是5600ms= 8 * 700ms。</li>
<li>consumeThread4: 在等待8193.81ms后的获取结果。换句话说，它等待的时间达到了3s之久。</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="cppmem-概述"><a class="header" href="#cppmem-概述">CppMem-概述</a></h1>
<p><a href="http://svr-pes20-cppmem.cl.cam.ac.uk/cppmem/">CppMem</a>是一个交互式工具，用于对C++小代码段的内存模型行为进行研究。它应该是每个认真处理内存模型程序员的必备工具。</p>
<p>CppMem的网上版本(也可以把它安装在你的个人电脑上)以两种方式提供服务:</p>
<ol>
<li>CppMem验证小代码段的行为，基于选择的C++内存模型，该工具考虑所有可能的线程交错，将每个线程可视化到一个图中，并用附加的细节对这些图进行注释。</li>
<li>CppMem的精确分析，可以更加深入了解C++内存模型。简言之，CppMem是一个帮助理解内存模型的工具。</li>
</ol>
<p>当然，必须跨过一些门槛，这通常是强大工具的共性。CppMem的本质是提供与这个极具挑战性的主题相关的非常详细的分析，并且是高度可配置的。因此，我才打算介绍该工具的各种组件。</p>
<h2 id="简单概述"><a class="header" href="#简单概述">简单概述</a></h2>
<p>我对CppMem的简单概述是基于默认配置的。这篇概述只是提供了进一步的实验基础，应该有助于理解我正在进行的优化过程。</p>
<p><img src="content/Further-Information/../../images/Further-Information/CppMem/1.png" alt="" /></p>
<p>简单起见，我引用了屏幕截图中的红色数字。</p>
<h3 id="1-model模型"><a class="header" href="#1-model模型">1. Model模型</a></h3>
<ul>
<li>指定C++内存模型。首选是C++11内存模型的一个(简化)等价的变体。</li>
</ul>
<h3 id="2-program-程序"><a class="header" href="#2-program-程序">2. Program 程序</a></h3>
<ul>
<li>包含可执行程序，其语法类似于简化的C++11。确切地说，不能直接将C或C++代码程序复制到CppMem中。</li>
<li>可以在许多典型多线程场景之间进行切换。要获得这些程序的详细信息，请阅读这篇写得非常好的文章，该文章将<a href="http://www.cl.cam.ac.uk/%7Epes20/cpp/popl085ap-sewell.pdf">C++并发性数学化</a>。当然，也可以运行自己的代码。</li>
<li>CppMem是关于多线程的，所以可以使用多线程的快捷方式。
<ul>
<li>可以使用表达式<code>{ { {…|||…} } }</code>。三个点<code>(…)</code>表示每个线程的工作包。</li>
<li>如果使用表达式<code>x.readvalue(1)</code>，则CppMem会计算线程交错的情况，其中线程会为<code>x</code>赋值1。</li>
</ul>
</li>
</ul>
<h3 id="3-display-relations-关系显示"><a class="header" href="#3-display-relations-关系显示">3. Display Relations 关系显示</a></h3>
<ul>
<li>描述原子操作、栅栏和锁上的读、写和读写改之间的关系。</li>
<li>可以使用复选框显式地启用带注释的图中的关系。</li>
<li>有三种关系，最有趣的是原始关系和派生关系之间的粗略区别。这里使用的是默认值。
<ul>
<li>渊源关系:
<ul>
<li>sb: sequenced-before 序前</li>
<li>rf: read from 读取</li>
<li>mo: modification order 修改顺序</li>
<li>sc: sequentially consistent 按顺序一致</li>
<li>lo: lock order 锁定顺序</li>
</ul>
</li>
<li>派生关系:
<ul>
<li>sw: synchronises-with 与...同步</li>
<li>dob: dependency-ordered-before 序前依赖</li>
<li>unsequenced_races: 单线程中的竞争</li>
<li>data_races: 线程内的数据竞争</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="4-display-layout-布局显示"><a class="header" href="#4-display-layout-布局显示">4. Display Layout 布局显示</a></h3>
<ul>
<li>可以选择使用哪个<a href="https://sourceforge.net/projects/doxygraph/">Doxygraph</a>图形。</li>
</ul>
<h3 id="5-model-predicates-模型谓词"><a class="header" href="#5-model-predicates-模型谓词">5. Model Predicates 模型谓词</a></h3>
<ul>
<li>使用此按钮，可以为所选模型设置谓词，这会导致不一致(非无数据争用)的执行，所以当执行不一致，就会看到不一致执行的原因。我在这本书里不使用这个按钮。</li>
</ul>
<p>有关更多细节，请参阅<a href="http://svr-pes20-cppmem.cl.cam.ac.uk/cppmem/help.html">文档</a>。</p>
<p>作为对CppMem的入门，这就足够了。现在，是时候尝试一下CppMem了。</p>
<p>CppMem提供了许多示例。</p>
<h3 id="示例"><a class="header" href="#示例">示例</a></h3>
<p>这些示例展示了使用并发代码，特别是使用无锁代码时的典型用例。可以将这些例子，分成几类。</p>
<p><strong>论文</strong></p>
<p>示例/论文类别为您提供了一些示例，这些示例在本文中对<a href="https://www.cl.cam.ac.uk/%7Epes20/cpp/popl085ap-sewell.pdf">C++并发性的数学化</a>进行了深入的讨论。</p>
<ul>
<li>data_race.c : x上的数据竞争</li>
<li>partial_sb.c : 单线程中计算的序前</li>
<li>unsequenced_race.c : 根据评价顺序，对x上未排序的竞争进行评价</li>
<li>sc_atomics.c : 正确的使用原子变量</li>
<li>thread_create_and_asw.c : 额外的同步——与适当的线程创建同步</li>
</ul>
<p>让我们从第一个示例开始。</p>
<p><strong>测试运行</strong></p>
<p>从CppMem样本中选择data_race.c程序。run之后，立即显示有一个数据竞争。</p>
<p><img src="content/Further-Information/../../images/Further-Information/CppMem/2.png" alt="" /></p>
<p>简单起见，只解释示例中的红色数字。</p>
<ol>
<li>很容易观察到的数据竞争。一个线程写<code>x (x==3)</code>，另一个线程不同步读<code>x (x==3)</code>。</li>
<li>由于C++内存模型，两个线程可能交织在一起运行，其中只有一个与所选模型一致。如果在表达式<code>x==3</code>中的<code>x</code>，在主函数中进行赋值<code>int x= 2</code>，则会出现这种情况。图中在用<code>rf</code>和<code>sw</code>标注的边缘显示了这种关系。</li>
<li>不同的线程交错之间切换显得非常有趣。</li>
<li>该图显示关系中启用的所有关系。
<ul>
<li><code>a:Wna x=2</code>在图表中是第<code>a</code>中表述，它是非原子性的。<code>Wna</code>表示“非原子写入”。</li>
<li>图中的关键是<code>x (b:Wna)</code>的写和<code>x (C:Rna)</code>的读之间的连线。这也就是<code>x</code>上的数据竞争。</li>
</ul>
</li>
</ol>
<p><strong>进一步分类</strong></p>
<p>进一步的分类会关注于无锁编程的方面。每个类别的示例都有不同的形式，每个表单使用不同的内存顺序。有关类别的更多讨论，请阅读前面提到的<a href="https://www.cl.cam.ac.uk/%7Epes20/cpp/popl085ap-sewell.pdf">将C++并发性数学化</a>的文章。如果可能的话，我会用顺序一致性来表示程序。</p>
<p><strong>存储缓冲(示例/SB_store_buffering)</strong></p>
<p>两个线程分别写入不同的位置，然后从另一个位置读取。</p>
<p>SB+sc_sc+sc_sc+sc.c</p>
<pre><code class="language-c++">// SB+sc_sc+sc_sc
// Store Buffering (or Dekker's), with all four accesses SC atomics
// Question: can the two reads both see 0 in the same execution?
int main() {
  atomic_int x=0; atomic_int y=0;
  {{{ { y.store(1,memory_order_seq_cst);
  	r1=x.load(memory_order_seq_cst); }
  ||| { x.store(1,memory_order_seq_cst);
  	r2=y.load(memory_order_seq_cst); } }}}
  return 0;
}
</code></pre>
<p><strong>消息传递(示例/MP_message_passing)</strong></p>
<p>一个线程写入数据(非原子变量)并设置一个原子标志，而另一个线程等待读取数据标志(非原子变量)。</p>
<p>MP+na_sc+sc_na.c</p>
<pre><code class="language-c++">// MP+na_sc+sc_na
// Message Passing, of data held in non-atomic x,
// with sc atomic stores and loads on y giving release/acquire synchronisation
// Question: is the read of x required to see the new data value 1
// rather than the initial state value 0?
int main() {
	int x=0; atomic_int y=0;
  {{{ { x=1;
  	y.store(1,memory_order_seq_cst); }
  ||| { r1=y.load(memory_order_seq_cst).readsvalue(1);
  	r2=x; } }}}
  return 0;
}
</code></pre>
<p><strong>读取缓冲(例子/LB_load_buffering)</strong></p>
<p>两个读操作可以看到之后的其他线程的写操作吗?</p>
<p>Lb+sc_sc+sc_sc.c</p>
<pre><code class="language-c++">// LB+sc_sc+sc_sc
// Load Buffering, with all four accesses sequentially consistent atomics
// Question: can the two reads both see 1 in the same execution?
int main() {
  atomic_int x=0; atomic_int y=0;
  {{{ { r1=x.load(memory_order_seq_cst);
  	y.store(1,memory_order_seq_cst); }
  ||| { r2=y.load(memory_order_seq_cst);
  	x.store(1,memory_order_seq_cst); } }}}
  return 0;
}
</code></pre>
<p><strong>从写到读的因果关系(例子/WRC)</strong></p>
<p>第三个线程是否看到第一个线程的写操作?</p>
<ul>
<li>第一个线程写x。</li>
<li>第二个线程从中读取数据并写入到y。</li>
<li>第三个线程读取x。</li>
</ul>
<p>WRC+rel+acq_rel+acq_rlx.c</p>
<pre><code class="language-c++">// WRC
// the question is whether the final read is required to see 1
// With two release/acquire pairs, it is
int main() {
  atomic_int x = 0;
  atomic_int y = 0;
  {{{ x.store(1,mo_release);
  ||| { r1=x.load(mo_acquire).readsvalue(1);
  	y.store(1,mo_release); }
  ||| { r2=y.load(mo_acquire).readsvalue(1);
  	r3=x.load(mo_relaxed); }
  }}}
  return 0;
}
</code></pre>
<p><strong>独立读-独立写(示例\IRIW)</strong></p>
<p>两个线程写入不同的位置，第二个线程能以不同的顺序看到写操作吗?</p>
<p>IRIW+rel+rel+acq_acq+acq_acq.c</p>
<pre><code class="language-c++">// IRIW with release/acquire
// the question is whether the reading threads have
// to see the writes to x and y in the same order.
// With release/acquire, they do not.
int main() {
  atomic_int x = 0; atomic_int y = 0;
  {{{ x.store(1, memory_order_release);
  ||| y.store(1, memory_order_release);
  ||| { r1=x.load(memory_order_acquire).readsvalue(1);
  	r2=y.load(memory_order_acquire).readsvalue(0); }
  ||| { r3=y.load(memory_order_acquire).readsvalue(1);
  	r4=x.load(memory_order_acquire).readsvalue(0); }
  }}};
  return 0;
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="术语表-1"><a class="header" href="#术语表-1">术语表</a></h1>
<p>本术语表只为基本术语提供参考。</p>
<h2 id="acid-1"><a class="header" href="#acid-1">ACID</a></h2>
<p>事务具有原子性、一致性、隔离性和持久性(ACID)属性的操作。在C++中，除了持久性之外，事务性内存的所有属性都保持不变。</p>
<ul>
<li>原子性：执行或不执行块的所有语句。</li>
<li>一致性：系统始终处于一致的状态，所有事务构建顺序一致。</li>
<li>独立性：每个事务在完全隔离的情况下运行。</li>
<li>会对事务的持久性进行记录。</li>
</ul>
<h2 id="cas"><a class="header" href="#cas">CAS</a></h2>
<p>CAS表示compare-and-swap，是一个原子操作。它将内存位置与给定值进行比较，如果内存位置与给定值相同，则修改内存位置的值。在C++中，CAS操作有<code>std::compare_exchange_strong</code>和<code>std::compare_exchange_weak</code>。</p>
<h2 id="可调用单元"><a class="header" href="#可调用单元">可调用单元</a></h2>
<p>可调用单元的行为类似于函数。不仅是函数，还有函数对象和Lambda函数。如果一个可调用单元接受一个参数，它就被称为一元可调用单元；如果有两个参数，就是二元可调用单元。</p>
<p>谓词是返回布尔值的特殊可调用项。</p>
<h2 id="并发性"><a class="header" href="#并发性">并发性</a></h2>
<p>并发性意味着多个任务的重叠执行。而且，并发是并行的超集。</p>
<h2 id="临界区"><a class="header" href="#临界区">临界区</a></h2>
<p>临界区是一段代码，最多只有一个线程可以访问。</p>
<h2 id="立即求值"><a class="header" href="#立即求值">立即求值</a></h2>
<p>如果立即求值，则立即求出表达式的值，则该策略与延迟求值正交。立即求值通常也称为贪婪求值。</p>
<h2 id="executor"><a class="header" href="#executor">Executor</a></h2>
<p>执行者是与特定执行上下文相关联的对象。它提供一个或多个执行函数，用于为可调用的函数对象创建执行代理。</p>
<h2 id="函数对象"><a class="header" href="#函数对象">函数对象</a></h2>
<p>首先，不要叫它们<a href="https://en.wikipedia.org/wiki/Functor">函子</a>。这是一个明确的数学术语，叫做<a href="https://en.wikipedia.org/wiki/Category_theory">范畴理论</a>。</p>
<p>函数对象是行为类似于函数，通过实现函数调用操作符来实现这一点。由于函数对象是对象，因此可以有属性和状态。</p>
<pre><code class="language-c++">struct Square{
	void operator()(int&amp; i){i= i*i;}
};

std::vector&lt;int&gt; myVec{1, 2, 3, 4, 5, 6, 7, 8, 9, 10};

std::for_each(myVec.begin(), myVec.end(), Square());

for (auto v: myVec) std::cout &lt;&lt; v &lt;&lt; &quot; &quot;; // 1 4 9 16 25 36 49 64 81 100
</code></pre>
<blockquote>
<p><strong>实例化函数对象</strong></p>
<p>常见的错误是在算法中使用函数对象(<code>Square</code>)的名称，而不是函数对象(<code>Square()</code>)本身的实例，比如：<code>std::for_each(myVec.begin()， myVec.end()， Square)</code>，应该使用：<code>std::for_each(myVec.begin()， myVec.end()， Square())</code>。</p>
</blockquote>
<h2 id="lambda函数"><a class="header" href="#lambda函数">Lambda函数</a></h2>
<p>Lambda函数可以就地提供需要的功能，编译器当场就能得到相应的信息，因此具有极佳的优化潜力。Lambda函数可以通过值或引用来接收它们的参数，还可以通过值或引用捕获已定义的变量。</p>
<pre><code class="language-c++">std::vector&lt;int&gt; myVec{1, 2, 3, 4, 5, 6, 7, 8, 9, 10};
std::for_each(myVec.begin(), myVec.end(), [](int&amp; i){ i= i*i; });
// 1 4 9 16 25 36 49 64 81 100
</code></pre>
<blockquote>
<p><strong>应该首选Lambda函数</strong></p>
<p>如果可调用的功能是简短和可以自解释的，使用Lambda函数最好不过。Lambda函数通常比函数或函数对象更快，而且更容易理解。</p>
</blockquote>
<h2 id="延迟求值"><a class="header" href="#延迟求值">延迟求值</a></h2>
<p><a href="https://en.wikipedia.org/wiki/Lazy_evaluation">延迟求值</a>的情况下，仅在需要时才对表达式求值。该策略与立即求值策略正交。延迟求值通常称为按需调用。</p>
<h2 id="无锁"><a class="header" href="#无锁">无锁</a></h2>
<p>如果保证了系统范围内的进程无影响，那么非阻塞算法就是无锁的。</p>
<p>##未唤醒</p>
<p>未唤醒是指，线程由于竞争条件而丢失唤醒通知的情况。</p>
<p>如果使用没有使用谓词，可能会发生这种情况。</p>
<h2 id="数学规律"><a class="header" href="#数学规律">数学规律</a></h2>
<p>某个集合X上的一个二进制操作(*)：</p>
<ul>
<li>结合律，满足x, y, z中的所有x, y, z的结合律：(x * y) * z = x * (y * z)</li>
<li>交换律，满足所有x和y的交换律x * y = y * x</li>
</ul>
<h2 id="内存位置"><a class="header" href="#内存位置">内存位置</a></h2>
<p>内存位置的详解可以参考<a href="http://en.cppreference.com/w/cpp/language/memory_model">cppreference.com</a></p>
<ul>
<li>标量类型的对象(算术类型、指针类型、枚举类型或<code>std::nullptr_t</code>。</li>
<li>非零长度的最大连续序列。</li>
</ul>
<h2 id="内存模型-3"><a class="header" href="#内存模型-3">内存模型</a></h2>
<p>内存模型定义了对象和内存位置之间的关系，特别是处理了以下问题：如果两个线程访问相同的内存位置，会发生什么情况。</p>
<p>##修改顺序</p>
<p>对特定原子对象M的所有修改，都以特定的顺序进行，这个顺序称为M的修改顺序。因此，线程读取原子对象时，不会看到比线程已经观察到的值更“旧”的值。</p>
<h2 id="monad单子"><a class="header" href="#monad单子">Monad(单子)</a></h2>
<p>Haskell作为一种纯函数语言，只有纯函数。这些纯函数的一个关键特性，当给定相同的参数时，总是返回相同的结果。有了这个<a href="https://en.wikipedia.org/wiki/Referential_transparency">透明参照</a>的属性，Haskell函数才不会有副作用。因此，Haskell有一个概念上的问题。到处都是有副作用的计算，这些计算可能会失败，可能返回未知数量的结果，或者依赖于环境。为了解决这个概念上的问题，Haskell使用单子并将它们嵌入到纯函数语言中。</p>
<p>经典的单子封装：</p>
<ul>
<li>I/O单子：计算输入和输出的结果。</li>
<li>可能性单子：可能会返回计算结果的单子。</li>
<li>错误单子：计算可能失败。</li>
<li>列表单子：计算可以有任意数量的结果。</li>
<li>状态单子：基于状态的计算。</li>
<li>读者单子：基于环境的计算。</li>
</ul>
<p>单子的概念来自数学中的<a href="https://en.wikipedia.org/wiki/Category_theory">范畴理论</a>，其处理对象之间的映射。单子是抽象的数据类型，将简单的类型转换为丰富的类型。这些丰富类型的值称为一元值。当进入单子，一个值只能由一个函数组合转换成另一个一元值。</p>
<p>这种组合尊重了单子的独特结构。因此，当发生错误，错误单子中断它的计算，或重新构建状态单子的状态。</p>
<p>一个单子包括三个部分:</p>
<ul>
<li>类型构造函数：定义简单数据类型，如何成为一元数据类型。</li>
<li>函数:
<ul>
<li>恒等函数：在单子中引入一个简单的值。</li>
<li>绑定操作符：定义如何将函数应用于一元值，以获得新的一元值。</li>
</ul>
</li>
<li>功能规则:</li>
<li>恒等函数的左右必须是恒等元素。</li>
<li>函数的复合必须遵循结合律。</li>
</ul>
<p>要使错误单子成为类型类单子的实例，错误单子必须支持恒等函数和绑定操作符，这两个函数定义了错误单子应该如何处理计算中的错误。如果使用错误单子，错误处理会在后台完成。</p>
<p>单子由两个控制流组成：用于计算结果的显式控制和用于处理特定副作用的隐式控制流。</p>
<p>当然，也可以用更少的词来定义单子：“单子只是内函子类中的一个独异点(monoid)。”</p>
<p>单子在C++中变得越来越重要。在C++ 17中，添加了<a href="http://en.cppreference.com/w/cpp/utility/optional"><code>std::optional</code></a> ，这是一种可能性单子。在C++20/23中，可能会从Eric Niebler那里得到扩展future和<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4128.html">范围库</a>，二者也都是单子。</p>
<h2 id="无阻塞"><a class="header" href="#无阻塞">无阻塞</a></h2>
<p>如果任何线程的失败或挂起，不会导致另一个线程的失败或挂起，则称为非阻塞。这个定义来自于<a href="http://jcip.net/">《Java并发实践》</a>。</p>
<h2 id="并行性"><a class="header" href="#并行性">并行性</a></h2>
<p>并行性意味着同时执行多个任务。并行性是并发性的一个子集。</p>
<h2 id="谓词-1"><a class="header" href="#谓词-1">谓词</a></h2>
<p>谓词是返回布尔值的可调用单元。如果一个谓词有一个参数，它就称为一元谓词。如果一个谓词有两个参数，就称为二元谓词。</p>
<h2 id="模式"><a class="header" href="#模式">模式</a></h2>
<p>“每个模式规则都是一个由三部分组成，表明了特定上下文、问题和解决方案之间的关系。“ —— <a href="https://en.wikipedia.org/wiki/Christopher_Alexander">Christopher Alexander</a></p>
<h2 id="raii"><a class="header" href="#raii">RAII</a></h2>
<p>资源获取是初始化(RAII)，代表C++中的一种流行技术，在这种技术中，资源的获取和释放与对象的生命周期绑定在一起。这意味着对于锁，互斥锁将被锁定在构造函数中，并在析构函数中解锁。这种RAII实现，也称为范围锁定。</p>
<p>C++中的典型用例有：管理互斥锁生命周期的锁、管理资源(内存)生命周期的智能指针，或者管理元素生命周期的<a href="https://en.cppreference.com/w/cpp/container">标准模板库容器</a>。</p>
<h2 id="释放序列"><a class="header" href="#释放序列">释放序列</a></h2>
<p>原子对象M的释放序列，以释放操作A为首，是M修改顺序中最大的连续子序列，其中第一个操作为A，每个后续操作为:</p>
<ul>
<li>由执行A操作的线程进行的操作</li>
<li>原子的读-改-写操作。</li>
</ul>
<h2 id="顺序一致的存储模型"><a class="header" href="#顺序一致的存储模型">顺序一致的存储模型</a></h2>
<p>顺序一致有两个基本特征:</p>
<ol>
<li>程序的指令是按源代码顺序执行的。</li>
<li>所有线程上的所有操作都遵循全局顺序。</li>
</ol>
<h2 id="序列点"><a class="header" href="#序列点">序列点</a></h2>
<p>序列点定义了程序执行过程中的任何一个结点。在这个点上，可以保证先前评估的所有执行效果，而不影响后续评估的 执行效果。</p>
<h2 id="伪唤醒"><a class="header" href="#伪唤醒">伪唤醒</a></h2>
<p>伪唤醒是一种条件变量的现象。可能发生的情况是，条件变量的等待组件错误地获取了一个通知。</p>
<h2 id="线程-2"><a class="header" href="#线程-2">线程</a></h2>
<p>计算机科学中，执行线程是可由调度器独立管理的最小程序指令序列，调度器通常是操作系统的一部分。线程和进程的实现在不同的操作系统之间是不同的，但是在大多数情况下，线程是进程的一个组件。多个线程可以存放在于一个进程中，并发执行并共享内存等资源，而不同的进程不共享这些资源。特别是，进程中的线程在任何给定时间，共享其可执行代码和变量。想要了解更多信息，可以阅读维基百科关于<a href="https://en.wikipedia.org/wiki/Thread_(computing)">线程</a>的文章。</p>
<h2 id="全序关系"><a class="header" href="#全序关系">全序关系</a></h2>
<p>总序是一个二元关系(&lt;=)在某个集合X上表现，其有反对称性、传递性，完全性。</p>
<ul>
<li>反对称性：如果a &lt;= b并且b &lt;= a，则a == b</li>
<li>传递性：如果a &lt;= b, b &lt;= c，则a &lt;= c</li>
<li>完全性：a &lt;= b或b &lt;= a</li>
</ul>
<h2 id="volatile"><a class="header" href="#volatile">volatile</a></h2>
<p>volatile通常用于表示可以独立于常规程序流进行更改的对象。例如，这些对象在嵌入式编程中表示一个外部设备(内存映射I/O)。由于这些对象可以独立于常规程序流进行更改，并且其值可以直接写入主内存，因此不会在缓存中进行优化存储。</p>
<h2 id="无等待"><a class="header" href="#无等待">无等待</a></h2>
<p>当有每个线程都有进程保证不会互相影响时，那么一个非阻塞算法是无等待的。</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        
                        
                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                
                            </nav>

        </div>

        
        
        
                <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        
        
                <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        
        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        
                        <script type="text/javascript">
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>
                
    </body>
</html>
